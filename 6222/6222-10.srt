1
00:00:00,000 --> 00:00:02,000
 you

2
00:00:30,000 --> 00:00:32,000
 you

3
00:01:00,000 --> 00:01:02,000
 you

4
00:01:30,000 --> 00:01:32,000
 you

5
00:02:00,000 --> 00:02:02,000
 you

6
00:02:30,000 --> 00:02:40,000
 you

7
00:02:40,000 --> 00:02:42,000
 you

8
00:02:48,000 --> 00:02:50,000
 Okay, good evening. So I

9
00:02:52,000 --> 00:02:58,000
 think I from the list I this class should have you over 400 students, right? So, so

10
00:03:00,000 --> 00:03:05,000
 so I just confirm I so you guys are many students maybe look at the video recordings, right?

11
00:03:07,000 --> 00:03:17,000
 Okay, so you are lucky in the time when I am here. So when I'm here, there's no video recordings. You must be here. So if you're not here, they may attend sign the

12
00:03:17,000 --> 00:03:30,000
 attendance list. If in the ups and for many lectures, you will fear the cost. Okay, but this is not what we are doing now. So I think that until it's protected students are very well. So

13
00:03:30,000 --> 00:03:56,000
 so first I want to introduce myself. So my name is Chen Jun. So and I actually graduated from Chiba years ago and and I my super is at school. I think he's here with the school. So and at that time I my

14
00:03:57,000 --> 00:04:14,000
 my PhD area is more on image processing and I do have many friends who who work on video signal processing and I happen to teach video signal processing for last year. I think and but this year the

15
00:04:14,000 --> 00:04:35,000
 professor John approach me say want to this course right so it has something related with 3D and something with with machine vision based on video and so so he happened to read my slides is a video signal processing. So he told me they this class may also

16
00:04:35,000 --> 00:05:04,000
 require similar technologies causes or content. So and I'm currently doing research in the in a start recording. There's one I call Institute for infocom research and my own research actually cover quite a lot actually I used to be work a lot on medical image computing or medical image analysis and from that right so

17
00:05:06,000 --> 00:05:22,000
 and at the time I started to work on medical image right so there are a lot of people working on machine computer vision and but for medical imaging at the very beginning right is not really computer vision is different from computer vision. Yeah, but the reason is that

18
00:05:23,000 --> 00:05:46,000
 the main difference is that in computer vision my daughter work are dealing with natural images but here is more medical images so but with the AI or especially deep learning coming become popular that the research method in medical image computing and the computer vision is become very very small now.

19
00:05:47,000 --> 00:06:12,000
 So I also work on robotics focus on the robotics perception and vision so that's the machine vision part computer vision part and actually right so that for deep learning people right so you are you are in the past I think turn or turn actually from 2015 right to to to now so it's actually the machine

20
00:06:12,000 --> 00:06:38,000
 learning people is killing the area of computer vision and the medical imaging or you're not the word right if you are not touched machine learning your method in computer vision or in medical imaging will be look like a bit not that novel or in other words if you

21
00:06:43,000 --> 00:06:55,000
 Hello you may apply the machine learning technology in computer vision tasks and then in my medical image tasks and doing very good results so if we want to

22
00:06:56,000 --> 00:07:03,000
 defeat those steps called a state of arts in computer vision you must be familiar with machine learning.

23
00:07:03,000 --> 00:07:32,000
 So and currently I'm also working on several projects one project is quietly read with the the part of the course here is 3D vision deep learning for 3D vision is while the quite fundamental research and the the second is more medical images is also related with 3D but it's for 3D reconstruction and the last one is

24
00:07:33,000 --> 00:07:42,000
 just finished this earlier this year and it's actually also a 3D but it's a it's a special 3D reconstruction.

25
00:07:42,000 --> 00:07:53,000
 Okay so this.

26
00:07:53,000 --> 00:08:04,000
 Yeah.

27
00:08:04,000 --> 00:08:22,000
 I work on and this is just to show you that the size I get is may come from lectures from other courses and I and some papers and also content from public papers so.

28
00:08:34,000 --> 00:08:52,000
 So I will be with you for for lectures so today I will be focused on so there's two parts one part is video one part is 3D so it's machine vision for video and machine vision for 3D but for video part right so.

29
00:08:53,000 --> 00:09:12,000
 I look at the current trend of the research I will think about what should I share with you on video part so I decided to share more on the generation of the videos right you may have now you actually can see the some of the fact the video from.

30
00:09:13,000 --> 00:09:15,000
 Popular media like.

31
00:09:16,000 --> 00:09:20,000
 Like a tick tock I believe you should be able to find some.

32
00:09:21,000 --> 00:09:28,000
 So, so I want to make sure you can understand how the video generation now is.

33
00:09:28,000 --> 00:09:32,000
 Effect by using the recent technology.

34
00:09:33,000 --> 00:09:43,000
 And of course I also need to share on for videos how how the people do the analysis and how to do the some enhancement.

35
00:09:44,000 --> 00:09:45,000
 Another course video system assessing.

36
00:09:45,000 --> 00:09:50,000
 So the use for focus a lot on video coding so.

37
00:09:51,000 --> 00:09:59,000
 But the video coding is where I teach that course right so I hope to add more content on the AI part instead of video coding part.

38
00:10:00,000 --> 00:10:08,000
 The reason is the code is the is kind of mature very mature now so it's commercially use very well so they for the researcher right so.

39
00:10:09,000 --> 00:10:10,000
 Once this thing is.

40
00:10:11,000 --> 00:10:22,000
 And mature we are we are not it's very difficult for you to find additional know what to do what kind of value can create to to put more effort on or video coding.

41
00:10:23,000 --> 00:10:33,000
 Of course, yeah, people will call it but I understand this course right so many students are taking master degree and many some maybe go for PhD right so.

42
00:10:33,000 --> 00:10:42,000
 So, while my focus is I will try to choose more concept or more domain areas to you.

43
00:10:43,000 --> 00:10:50,000
 And and this also relates how the examination will be going for for my part of the work.

44
00:10:51,000 --> 00:10:54,000
 So the second part is more on the treaty.

45
00:10:55,000 --> 00:10:59,000
 And I will more focus on the of course there are many many treaties.

46
00:10:59,000 --> 00:11:12,000
 So many many different approach for for the treaties so I will focus on the part I fear is more important or quite popular in industry and also in academic research.

47
00:11:13,000 --> 00:11:21,000
 So here I will for the treaty I will share the how the key points are detected and used to.

48
00:11:22,000 --> 00:11:30,000
 For the treaty and how the stretch for motion is applied and also I will share on the stereo matching.

49
00:11:31,000 --> 00:11:32,000
 Which is while the.

50
00:11:34,000 --> 00:11:37,000
 May focus in the in my research actually now.

51
00:11:37,000 --> 00:11:51,000
 Okay, so now let's talk about video generation.

52
00:11:51,000 --> 00:11:56,000
 We first watch a video.

53
00:12:21,000 --> 00:12:26,000
 My full time employees.

54
00:12:27,000 --> 00:12:43,000
 My full time employees and their ability to survive on $8 an hour in New York City and foremost in all of our minds has been the loss and the grief felt by the people of Orlando.

55
00:12:44,000 --> 00:12:50,000
 Most of us don't get our health care through the marketplace through our job or through Medicare or Medicare.

56
00:12:51,000 --> 00:12:56,000
 What you should know is that thanks to the Affordable Care Act your coverage is better today than it was before.

57
00:12:57,000 --> 00:12:58,000
 Women can get free checkups.

58
00:12:59,000 --> 00:13:07,000
 Can get charged more just for being one to give his employees together to pass a commoner's bill that would boost America's very very hard times.

59
00:13:08,000 --> 00:13:11,000
 Some progress at least within the small confines of the legal community.

60
00:13:12,000 --> 00:13:13,000
 I think it's real important.

61
00:13:14,000 --> 00:13:15,000
 Here we go.

62
00:13:15,000 --> 00:13:20,000
 When you giving a speech.

63
00:13:23,000 --> 00:13:25,000
 You use a lot of pauses.

64
00:13:26,000 --> 00:13:32,000
 America's businesses have created 14.5 million new jobs over 75 straight months.

65
00:13:33,000 --> 00:13:34,000
 We're developing technology.

66
00:13:35,000 --> 00:13:37,000
 Every technology can be used in some negative way.

67
00:13:38,000 --> 00:13:41,000
 And so we all should work towards making sure that it's not going to happen.

68
00:13:41,000 --> 00:13:48,000
 And even one of the interesting directions is that once you know how to create something you know how to reverse engineer it.

69
00:13:49,000 --> 00:13:58,000
 And so you can and so one could create methods for identifying edited videos versus real videos.

70
00:14:00,000 --> 00:14:01,000
 Okay. So this is just a video.

71
00:14:02,000 --> 00:14:10,000
 Actually this video where we show one of the video is two Obama speak and one is a fact one.

72
00:14:11,000 --> 00:14:17,000
 And but this video fact video actually is is not based on the recent AI technology.

73
00:14:18,000 --> 00:14:21,000
 It's actually is this many time many years ago.

74
00:14:22,000 --> 00:14:29,000
 But that doesn't mean there are people already starting to to make a video a few years ago already.

75
00:14:30,000 --> 00:14:35,000
 But the recent like a solar and those things right so they can make much better video.

76
00:14:35,000 --> 00:14:36,000
 Fact video.

77
00:14:40,000 --> 00:14:48,000
 And in Singapore I understand I know there's one case someone put a fake video or previous PM.

78
00:14:56,000 --> 00:15:01,000
 So in order to understand right how the the fact the video is.

79
00:15:02,000 --> 00:15:07,000
 So I will share the links to all this video links to you.

80
00:15:09,000 --> 00:15:11,000
 Since the sound is not quite good now just now.

81
00:15:12,000 --> 00:15:22,000
 So in order to understand how the video is generated or fact right so we first to to know why was a concept called auto encoder.

82
00:15:23,000 --> 00:15:33,000
 And and this is actually where the AI actually starts from one of the technologies for AI to start from.

83
00:15:34,000 --> 00:15:39,000
 So for auto encoder right so we basically have a original image.

84
00:15:40,000 --> 00:15:44,000
 So we go through we call it a neural network encoder.

85
00:15:45,000 --> 00:15:48,000
 So encoder this if you take the video coding right.

86
00:15:48,000 --> 00:15:52,000
 So it's like something a compressed video.

87
00:15:53,000 --> 00:15:56,000
 But here with the video not knowing how you encoder right.

88
00:15:57,000 --> 00:16:02,000
 This neural can be many many layers and if you convert this image right to a code this code right.

89
00:16:03,000 --> 00:16:08,000
 Can be visually right can be look like a random noise.

90
00:16:09,000 --> 00:16:13,000
 Or a vector with a random noise.

91
00:16:13,000 --> 00:16:21,000
 Or a vector with for example 16 bits better or 8 8 bit vectors.

92
00:16:22,000 --> 00:16:37,000
 So from this code right you look at it is not it does not show anything about this images is not a down some of the images is you can say is this can convert to become a random code.

93
00:16:38,000 --> 00:16:45,000
 So and then we also have a neural network decoder to recover an image.

94
00:16:46,000 --> 00:16:49,000
 Where the auto encoder I will try to.

95
00:16:50,000 --> 00:17:04,000
 Change this network such that reconstructed images here is be close to the original input image as much as possible.

96
00:17:04,000 --> 00:17:19,000
 So after changing right after changing we take the decoder out.

97
00:17:20,000 --> 00:17:23,000
 We take we make use decoder right will give this decoder.

98
00:17:23,000 --> 00:17:35,000
 An input code this code that not have to be set by this one.

99
00:17:36,000 --> 00:17:42,000
 Yeah but of course if if it's very close to this one right if you will be able to recover image like this right.

100
00:17:42,000 --> 00:17:56,000
 So that means after this change right this can be used to change a code here to become an image.

101
00:17:57,000 --> 00:17:59,000
 Similar to the training input.

102
00:17:59,000 --> 00:18:06,000
 So.

103
00:18:07,000 --> 00:18:12,000
 I'm sure how many of you have been.

104
00:18:13,000 --> 00:18:16,000
 Have the knowledge of AI already.

105
00:18:16,000 --> 00:18:19,000
 I was convolutional neural network.

106
00:18:20,000 --> 00:18:22,000
 Anybody know neural network.

107
00:18:24,000 --> 00:18:29,000
 Neural network just you have read the neural network so we just structure like this.

108
00:18:34,000 --> 00:18:35,000
 Hit.

109
00:18:39,000 --> 00:18:41,000
 Okay okay I got it.

110
00:18:41,000 --> 00:18:56,000
 So since you have learned the thing in the first part right so you just imagine those are different things in the networks and from the input x right you reduce the dimension to become zero so and the Z could be a random noise.

111
00:19:03,000 --> 00:19:06,000
 Okay this one is just so.

112
00:19:06,000 --> 00:19:07,000
 So.

113
00:19:09,000 --> 00:19:20,000
 Let's hear where I'm teaching the video coding so I just find that you really coding right this is a diagram from a video coding so you actually have the similar things.

114
00:19:21,000 --> 00:19:28,000
 You have the video input you have the encoder and the end you trust what you trust both of the.

115
00:19:29,000 --> 00:19:42,000
 Compressed data through a channel to the other part and then you recover it right so this process is like encoding and decoding right so it's it's very similar to auto encoder.

116
00:19:43,000 --> 00:19:50,000
 Of course they are like and that's they are quite a lot of difference because how they design this part how they design the part is totally different.

117
00:19:50,000 --> 00:19:58,000
 But based on concept you realize that our video come from here is go through an encoding process.

118
00:19:59,000 --> 00:20:07,000
 And here I got the coding processor and our auto encoder is is also encoder and decoder.

119
00:20:12,000 --> 00:20:13,000
 So.

120
00:20:16,000 --> 00:20:17,000
 A quick test.

121
00:20:18,000 --> 00:20:20,000
 So when we change encoder.

122
00:20:21,000 --> 00:20:27,000
 And decoder to reconstruct the original training image as close as possible.

123
00:20:29,000 --> 00:20:30,000
 Why why this one.

124
00:20:32,000 --> 00:20:33,000
 Can be.

125
00:20:33,000 --> 00:20:39,000
 It's like this neural net decoder is it to restore the some of the information here.

126
00:20:40,000 --> 00:20:45,000
 But based on the code but as I mentioned just now right this code can be a random.

127
00:20:45,000 --> 00:20:51,000
 Can be looked like a random noise so why you can recover an image from a random noise.

128
00:20:52,000 --> 00:20:56,000
 So here the potential reason so why is.

129
00:20:57,000 --> 00:21:04,000
 This image itself have a lot of redundancy right so we actually know right if you.

130
00:21:05,000 --> 00:21:14,000
 Have ever learned image processing so image have a lot of redundancy because neighboring pixels tend to be very similar intensity.

131
00:21:16,000 --> 00:21:28,000
 So this is the first reason the second reason is that when we change this neural network right this decoder may contain some of the domain knowledge of the training image here.

132
00:21:29,000 --> 00:21:32,000
 So my question is how many things.

133
00:21:34,000 --> 00:21:39,000
 The reason is a maybe raise your hands how many things.

134
00:21:42,000 --> 00:21:44,000
 I try to be interactive.

135
00:21:45,000 --> 00:21:47,000
 Nobody thinks is a is correct.

136
00:21:49,000 --> 00:21:51,000
 Okay here for some students a is correct.

137
00:21:52,000 --> 00:21:53,000
 No else a.

138
00:21:55,000 --> 00:21:56,000
 Okay.

139
00:21:56,000 --> 00:22:01,000
 Okay a few students a correct how many say B is correct is the reason.

140
00:22:07,000 --> 00:22:09,000
 How many things both and be accurate.

141
00:22:13,000 --> 00:22:19,000
 So the rest of students say now the correct.

142
00:22:20,000 --> 00:22:27,000
 Okay so the answer is this this is a question I think so I believe both are the reasons here.

143
00:22:28,000 --> 00:22:35,000
 So I understand right if my input image here is a random.

144
00:22:36,000 --> 00:22:40,000
 That means every picture is value could be a random noise.

145
00:22:42,000 --> 00:22:44,000
 You will not be able to recover this.

146
00:22:45,000 --> 00:22:52,000
 Okay that's why you can easily get this result from based on information theory.

147
00:22:54,000 --> 00:23:01,000
 If every beat is a random right so the information from here is dependent by the number of beats.

148
00:23:02,000 --> 00:23:07,000
 Let's say we have let's say is a 200 times 200 image here for example right.

149
00:23:07,000 --> 00:23:17,000
 That means I have 40,000 pixels or 40,000 beat and each beat is random so that means 40,000 random.

150
00:23:19,000 --> 00:23:29,000
 This here and the information actually is is the maximum at that time and after encoder your code is become smaller right.

151
00:23:30,000 --> 00:23:32,000
 So your information here will be definitely smaller than this.

152
00:23:33,000 --> 00:23:36,000
 So that means you will not be able to recover this one.

153
00:23:37,000 --> 00:23:41,000
 So if you don't understand you will try to look for the information theory.

154
00:23:42,000 --> 00:23:46,000
 I think you should have learned that on undergraduate.

155
00:23:48,000 --> 00:24:01,000
 And the B is also correct because when we are changing the decoder we are learning how the code here are linked with that.

156
00:24:02,000 --> 00:24:03,000
 So you can see the image here.

157
00:24:06,000 --> 00:24:10,000
 So if you really find this very difficult to understand you can just imagine right.

158
00:24:11,000 --> 00:24:23,000
 So I may have a box with many cards inside each card may have some article but each card may have ID right 1234 right.

159
00:24:23,000 --> 00:24:35,000
 So when I draw from a box to find the car the right car so each car will show the corresponding text article here right.

160
00:24:36,000 --> 00:24:44,000
 So that's that's how the model decoder here is try to learn the information from the training images.

161
00:24:45,000 --> 00:24:50,000
 Of course this is because the training image itself has has redundancy.

162
00:24:53,000 --> 00:24:55,000
 So I'm going to show you how to do this.

163
00:25:04,000 --> 00:25:11,000
 Now so MBA knows what's the what's the limitation of autoencoder.

164
00:25:16,000 --> 00:25:22,000
 What is the limitation so when we train autoencoder right we are training we have an input image.

165
00:25:23,000 --> 00:25:33,000
 And to train become a code and decoder it and we get the output right.

166
00:25:34,000 --> 00:25:39,000
 So let's say we our training image is an image of the number seven right.

167
00:25:40,000 --> 00:25:44,000
 We want this output to be as close as this as possible.

168
00:25:45,000 --> 00:25:51,000
 And very often how do I measure these two are close.

169
00:25:59,000 --> 00:26:03,000
 So for example very often we use the mean square error.

170
00:26:04,000 --> 00:26:08,000
 So just compare these two how many are equal how many are different for you know right.

171
00:26:09,000 --> 00:26:20,000
 And of course there are many other options but in autoencoder based on the difference.

172
00:26:20,000 --> 00:26:40,000
 So this actually the way we calculate the how close it is is a lot in training this decoder.

173
00:26:41,000 --> 00:26:50,000
 So we may have one third be connected to this the end of the seven right stroke.

174
00:26:51,000 --> 00:26:59,000
 We can also have a thought maybe anybody anywhere in the space in the wide space right.

175
00:27:02,000 --> 00:27:06,000
 So of course we here we put it a different color.

176
00:27:07,000 --> 00:27:14,000
 But if you look at this one right so it still looks like a seven right because all the seven like this.

177
00:27:15,000 --> 00:27:22,000
 But if you look at this one you may say this is seven plus a dot right.

178
00:27:23,000 --> 00:27:29,000
 So visually if you are careful enough you say there's a dot right.

179
00:27:30,000 --> 00:27:34,000
 This is dot means the end of the sentence or mean something else right.

180
00:27:34,000 --> 00:27:43,000
 If you are working with a bank right so I'm going to have a financial number right.

181
00:27:44,000 --> 00:27:46,000
 Many many number and seven many number right.

182
00:27:47,000 --> 00:27:49,000
 Here you have many many number and seven and they have a dot.

183
00:27:50,000 --> 00:27:53,000
 That means it may seven point one or seven point two right.

184
00:27:54,000 --> 00:27:59,000
 So it will change significantly in the actual meaning.

185
00:27:59,000 --> 00:28:08,000
 So if we are doing machine vision for example try to recognize what's the number here.

186
00:28:09,000 --> 00:28:12,000
 So we will say this is a really seven right.

187
00:28:13,000 --> 00:28:20,000
 But this look like a fake one because a true number of seven should not have a dot here.

188
00:28:21,000 --> 00:28:23,000
 We said them right a seven like that.

189
00:28:23,000 --> 00:28:33,000
 So that means my difference between the output and the input training image right.

190
00:28:34,000 --> 00:28:38,000
 Where the difference is it matters right.

191
00:28:39,000 --> 00:28:45,000
 But auto-encoder because they are just computer difference and computer mean square error.

192
00:28:46,000 --> 00:28:48,000
 It doesn't care about this.

193
00:28:48,000 --> 00:29:05,000
 Of course there are many other approaches to for example I may change how I calculate the distance like I may compute a structure measurement like a structure similarity if you ever hear about it.

194
00:29:05,000 --> 00:29:26,000
 So it may change a bit but the main cause main message is that we know different location of the dot or difference affects your result.

195
00:29:27,000 --> 00:29:39,000
 So therefore people think of the adversarial learning.

196
00:29:40,000 --> 00:29:46,000
 So in adversarial learning right.

197
00:29:46,000 --> 00:29:53,000
 So similar this we have a we call it a general model.

198
00:29:54,000 --> 00:29:59,000
 You can consider this is a generative model is a decoder model we just now.

199
00:30:00,000 --> 00:30:06,000
 So we want this decoder model I can generate for example an image of a face.

200
00:30:07,000 --> 00:30:08,000
 A facial image right.

201
00:30:09,000 --> 00:30:14,000
 And compare with the auto-encoder just now right.

202
00:30:14,000 --> 00:30:20,000
 So we also have some training images of the real world face images.

203
00:30:21,000 --> 00:30:25,000
 And instead of we try to reconstruct this one.

204
00:30:26,000 --> 00:30:32,000
 The general image to be as close as to this one as possible.

205
00:30:33,000 --> 00:30:37,000
 We change a different model a discriminative model.

206
00:30:38,000 --> 00:30:40,000
 This is like a classifier.

207
00:30:40,000 --> 00:30:49,000
 So that means we are training one generative model and one discriminative model or one classifier.

208
00:30:50,000 --> 00:31:03,000
 So this one is try to generate something this one is to do classification classifier what so classifying between the image here and the training image or real world images.

209
00:31:04,000 --> 00:31:07,000
 So in another word right so what do I do.

210
00:31:07,000 --> 00:31:21,000
 I'm trying to generate an image such that from the discriminator point of view these two if I cannot tell the difference or easily tell the difference.

211
00:31:22,000 --> 00:31:27,000
 There I may say this generation is quite good right.

212
00:31:28,000 --> 00:31:32,000
 So I'm trying to generate an image that make you feel this is a real image.

213
00:31:32,000 --> 00:31:42,000
 So that means we have be considered potential clues.

214
00:31:43,000 --> 00:31:50,000
 When you generate this one you may generate it with some clues that are very easy to tell.

215
00:31:51,000 --> 00:31:54,000
 This is not a real risk facial images.

216
00:31:54,000 --> 00:32:04,000
 So you come back to the auto encoder.

217
00:32:05,000 --> 00:32:12,000
 So we are here we are trying to use the encoder to generate a set if the realist image like this right.

218
00:32:13,000 --> 00:32:17,000
 If I generate an image with a dot besides the seven.

219
00:32:18,000 --> 00:32:21,000
 So why we can easily tell this is a fake one.

220
00:32:21,000 --> 00:32:26,000
 It's because this pool visually looks quite different.

221
00:32:27,000 --> 00:32:34,000
 If I put the dot at the end of the choke right you may not notice it right because you.

222
00:32:35,000 --> 00:32:42,000
 You're naturally this the where the end of the stroke ends is they have some variations.

223
00:32:43,000 --> 00:32:49,000
 So this is within the reasonable variation right so let's say from here to here maybe 10 pixel.

224
00:32:49,000 --> 00:32:54,000
 Or someone is 10 pixel or someone is 11 pixel some is 9 pixel.

225
00:32:55,000 --> 00:33:01,000
 So you add one dot here you really don't know whether you just actual dot.

226
00:33:02,000 --> 00:33:09,000
 But you know scary should be white and you add one dot here visually very different.

227
00:33:20,000 --> 00:33:21,000
 So.

228
00:33:25,000 --> 00:33:27,000
 So this because this.

229
00:33:28,000 --> 00:33:32,000
 Generative as an anniversary or.

230
00:33:37,000 --> 00:33:41,000
 How to learn a generative model.

231
00:33:42,000 --> 00:33:46,000
 And just now we mentioned that there's also discriminator right.

232
00:33:46,000 --> 00:33:53,000
 So there's a generative model there's a discriminator and these two are trained as a versus we way.

233
00:33:54,000 --> 00:33:59,000
 And both the generative model discriminator are based on.

234
00:34:00,000 --> 00:34:01,000
 Deep neural network.

235
00:34:07,000 --> 00:34:08,000
 So.

236
00:34:10,000 --> 00:34:13,000
 So let's look at the structure of the.

237
00:34:14,000 --> 00:34:15,000
 Generative work.

238
00:34:16,000 --> 00:34:22,000
 And with this one maybe you can understand this better.

239
00:34:24,000 --> 00:34:25,000
 So.

240
00:34:26,000 --> 00:34:27,000
 This part right we have.

241
00:34:30,000 --> 00:34:32,000
 Random vector input.

242
00:34:33,000 --> 00:34:40,000
 They write so these are the equivalent to the coder with a code in the open.

243
00:34:41,000 --> 00:34:42,000
 And.

244
00:34:50,000 --> 00:34:54,000
 The generator is trying to convert the.

245
00:34:57,000 --> 00:34:58,000
 Input.

246
00:34:59,000 --> 00:35:00,000
 To an output.

247
00:35:01,000 --> 00:35:05,000
 Of course it's output let's just use the image as an example it can be image.

248
00:35:05,000 --> 00:35:08,000
 But it also can be a video or anything else.

249
00:35:09,000 --> 00:35:11,000
 Or speech or whatever.

250
00:35:12,000 --> 00:35:15,000
 So and the best of now is almost can generate anything.

251
00:35:16,000 --> 00:35:19,000
 But here we just use image as an example for easy understanding.

252
00:35:21,000 --> 00:35:25,000
 And we have a training images which is the images you are.

253
00:35:26,000 --> 00:35:29,000
 You are used to training it can be facial images it can be.

254
00:35:29,000 --> 00:35:30,000
 An image of.

255
00:35:31,000 --> 00:35:35,000
 Our buildings or and it depends on how you want to train this one.

256
00:35:36,000 --> 00:35:37,000
 What's your objective of the.

257
00:35:39,000 --> 00:35:40,000
 Generating.

258
00:35:41,000 --> 00:35:42,000
 Generative network.

259
00:35:43,000 --> 00:35:44,000
 The.

260
00:35:46,000 --> 00:35:49,000
 We can give this many many different random.

261
00:35:50,000 --> 00:35:51,000
 And the.

262
00:35:52,000 --> 00:35:54,000
 Here it will be different samples.

263
00:35:59,000 --> 00:36:00,000
 Hello.

264
00:36:01,000 --> 00:36:04,000
 And we will have some samples right.

265
00:36:05,000 --> 00:36:06,000
 So.

266
00:36:07,000 --> 00:36:08,000
 For for.

267
00:36:09,000 --> 00:36:11,000
 Generator as a network right.

268
00:36:12,000 --> 00:36:13,000
 I am what I hope.

269
00:36:14,000 --> 00:36:15,000
 So.

270
00:36:15,000 --> 00:36:16,000
 For for.

271
00:36:17,000 --> 00:36:19,000
 Generator as a network right.

272
00:36:20,000 --> 00:36:24,000
 I hope this can generate something sample here.

273
00:36:25,000 --> 00:36:27,000
 GZ right and the X.

274
00:36:29,000 --> 00:36:30,000
 Cannot be.

275
00:36:31,000 --> 00:36:32,000
 Easily differentiated.

276
00:36:33,000 --> 00:36:34,000
 So.

277
00:36:35,000 --> 00:36:37,000
 It's like for example I want to do some.

278
00:36:38,000 --> 00:36:39,000
 I lose older than you right.

279
00:36:40,000 --> 00:36:43,000
 But if I can do some makeup make me looks younger right.

280
00:36:44,000 --> 00:36:46,000
 I may sit here say I'm a student though.

281
00:36:48,000 --> 00:36:49,000
 2024 class right.

282
00:36:50,000 --> 00:36:54,000
 So this is a generator doing so try to get a sample sample.

283
00:36:55,000 --> 00:36:57,000
 That can be look like a real.

284
00:36:58,000 --> 00:36:59,000
 Here.

285
00:37:08,000 --> 00:37:11,000
 Disseminator try to be the enemy of the generator.

286
00:37:12,000 --> 00:37:13,000
 Try to.

287
00:37:14,000 --> 00:37:15,000
 Share a class file here.

288
00:37:16,000 --> 00:37:19,000
 That can differentiate whether the data is from X.

289
00:37:20,000 --> 00:37:21,000
 Or is from the GZ.

290
00:37:23,000 --> 00:37:24,000
 So it's like.

291
00:37:25,000 --> 00:37:27,000
 I'm sitting one of the here right.

292
00:37:28,000 --> 00:37:29,000
 There's one disc.

293
00:37:30,000 --> 00:37:32,000
 I'm not in the age of yours right.

294
00:37:33,000 --> 00:37:35,000
 So try to see who is the one.

295
00:37:36,000 --> 00:37:38,000
 Not really from this class but sitting here.

296
00:37:42,000 --> 00:37:47,000
 So now you see right to our task is.

297
00:37:48,000 --> 00:37:51,000
 We were going to train both the generator and the discriminator.

298
00:37:52,000 --> 00:37:53,000
 We change the generator.

299
00:37:54,000 --> 00:37:57,000
 To produce samples that cannot be differentiated by.

300
00:37:58,000 --> 00:37:59,000
 The discriminator.

301
00:38:00,000 --> 00:38:01,000
 And we change the discriminator.

302
00:38:03,000 --> 00:38:05,000
 Such that I can always.

303
00:38:06,000 --> 00:38:07,000
 The sample.

304
00:38:12,000 --> 00:38:13,000
 Perfect images.

305
00:38:15,000 --> 00:38:16,000
 Right so.

306
00:38:23,000 --> 00:38:25,000
 And of course based on this right.

307
00:38:26,000 --> 00:38:29,000
 It's all discriminator we can have some and generate we have some loss.

308
00:38:30,000 --> 00:38:31,000
 And.

309
00:38:32,000 --> 00:38:33,000
 Here that.

310
00:38:34,000 --> 00:38:37,000
 We require this discriminator and this is generator to be.

311
00:38:38,000 --> 00:38:39,000
 Differentiable module.

312
00:38:39,000 --> 00:38:40,000
 Differentiable module.

313
00:38:41,000 --> 00:38:43,000
 So I know what's the meaning of different.

314
00:38:46,000 --> 00:38:48,000
 You learn the thing right in the first part.

315
00:38:49,000 --> 00:38:50,000
 Of course.

316
00:38:51,000 --> 00:38:52,000
 Okay.

317
00:38:53,000 --> 00:38:54,000
 I know.

318
00:38:55,000 --> 00:38:56,000
 I know why with this one.

319
00:38:57,000 --> 00:38:58,000
 What does it mean.

320
00:38:59,000 --> 00:39:00,000
 Differentiable module.

321
00:39:01,000 --> 00:39:02,000
 I know.

322
00:39:03,000 --> 00:39:04,000
 Okay.

323
00:39:05,000 --> 00:39:06,000
 Yeah.

324
00:39:07,000 --> 00:39:08,000
 Short word.

325
00:39:09,000 --> 00:39:11,000
 It means these two parts can be trained.

326
00:39:12,000 --> 00:39:13,000
 Well we can.

327
00:39:20,000 --> 00:39:21,000
 Gradient descent right.

328
00:39:22,000 --> 00:39:24,000
 Use a great decent algorithm to train right.

329
00:39:25,000 --> 00:39:26,000
 But.

330
00:39:27,000 --> 00:39:28,000
 Not every.

331
00:39:33,000 --> 00:39:34,000
 So.

332
00:39:36,000 --> 00:39:39,000
 So that we will I will show you why.

333
00:39:40,000 --> 00:39:41,000
 Why why we say this.

334
00:39:42,000 --> 00:39:43,000
 Yeah so.

335
00:39:44,000 --> 00:39:45,000
 So that means that if you're actually.

336
00:40:03,000 --> 00:40:04,000
 So.

337
00:40:06,000 --> 00:40:07,000
 We have.

338
00:40:08,000 --> 00:40:10,000
 One generator we have one to some a letter.

339
00:40:11,000 --> 00:40:13,000
 Right so and why is try to.

340
00:40:15,000 --> 00:40:19,000
 Produce fixed down samples why is try to tear whether it's true or not.

341
00:40:20,000 --> 00:40:21,000
 So these two.

342
00:40:22,000 --> 00:40:23,000
 I should have.

343
00:40:24,000 --> 00:40:25,000
 Two.

344
00:40:26,000 --> 00:40:28,000
 Objectives right why is.

345
00:40:28,000 --> 00:40:29,000
 Why is.

346
00:40:30,000 --> 00:40:33,000
 Where where there is true true or not why is try to make it.

347
00:40:34,000 --> 00:40:35,000
 Looks like true.

348
00:40:37,000 --> 00:40:40,000
 So how do we change this overall.

349
00:40:41,000 --> 00:40:42,000
 System.

350
00:40:43,000 --> 00:40:44,000
 That works.

351
00:40:50,000 --> 00:40:53,000
 For example we can change that this matter first.

352
00:40:54,000 --> 00:40:57,000
 Then change that this letter generator.

353
00:40:58,000 --> 00:41:01,000
 And after generally trained then we change this matter again.

354
00:41:02,000 --> 00:41:03,000
 Then.

355
00:41:04,000 --> 00:41:05,000
 Generator again.

356
00:41:06,000 --> 00:41:09,000
 Keep this iteration until we find convergence.

357
00:41:12,000 --> 00:41:14,000
 So how do we change right so just now we mentioned is.

358
00:41:15,000 --> 00:41:17,000
 We need to make sure that this matter is.

359
00:41:18,000 --> 00:41:19,000
 Differentiable.

360
00:41:20,000 --> 00:41:21,000
 That means it can be trained.

361
00:41:22,000 --> 00:41:23,000
 So.

362
00:41:24,000 --> 00:41:26,000
 We have some random variable we get some.

363
00:41:27,000 --> 00:41:28,000
 Generate some data based on.

364
00:41:29,000 --> 00:41:32,000
 Here with the generator will be keep frozen here.

365
00:41:33,000 --> 00:41:34,000
 Where we can.

366
00:41:35,000 --> 00:41:39,000
 We get some examples because some random some from the real world image here.

367
00:41:40,000 --> 00:41:41,000
 And we will try to.

368
00:41:42,000 --> 00:41:44,000
 Compute the difference based on the.

369
00:41:45,000 --> 00:41:50,000
 Or the score the loss right and based on this loss we do a buck propagation.

370
00:41:50,000 --> 00:41:53,000
 To update the way of the.

371
00:41:54,000 --> 00:41:55,000
 That's.

372
00:41:56,000 --> 00:41:57,000
 The loss it can.

373
00:42:10,000 --> 00:42:11,000
 So after.

374
00:42:13,000 --> 00:42:14,000
 After the disseminated chain.

375
00:42:16,000 --> 00:42:17,000
 We will.

376
00:42:18,000 --> 00:42:19,000
 For the.

377
00:42:20,000 --> 00:42:22,000
 The way of the two metal now we change the.

378
00:42:23,000 --> 00:42:24,000
 Generator.

379
00:42:25,000 --> 00:42:29,000
 Because we require the generation of differential module right so it also can be.

380
00:42:30,000 --> 00:42:32,000
 And we do the same buck propagation.

381
00:42:33,000 --> 00:42:34,000
 To update the way inside here.

382
00:42:36,000 --> 00:42:37,000
 And then keep this.

383
00:42:44,000 --> 00:42:45,000
 So.

384
00:42:48,000 --> 00:42:49,000
 The.

385
00:42:50,000 --> 00:42:53,000
 Here is the mass emitter formulation of.

386
00:42:54,000 --> 00:42:55,000
 The gas training objective.

387
00:42:56,000 --> 00:42:59,000
 So let's say we have a reward.

388
00:43:18,000 --> 00:43:19,000
 Hello.

389
00:43:23,000 --> 00:43:24,000
 The discriminator try to.

390
00:43:26,000 --> 00:43:27,000
 Differentiate the.

391
00:43:28,000 --> 00:43:30,000
 True sample and the fake sample right.

392
00:43:31,000 --> 00:43:32,000
 So it is trying to.

393
00:43:33,000 --> 00:43:34,000
 Maximize the.

394
00:43:35,000 --> 00:43:36,000
 The loss.

395
00:43:37,000 --> 00:43:38,000
 Right.

396
00:43:38,000 --> 00:43:39,000
 On the other side.

397
00:43:39,000 --> 00:43:41,000
 The generator is trying to.

398
00:43:42,000 --> 00:43:43,000
 Make the difference.

399
00:43:43,000 --> 00:43:44,000
 Or the.

400
00:43:45,000 --> 00:43:46,000
 That.

401
00:43:47,000 --> 00:43:48,000
 Discmented reward.

402
00:43:49,000 --> 00:43:50,000
 Smaller.

403
00:43:51,000 --> 00:43:52,000
 So it is trying to minimize this.

404
00:43:53,000 --> 00:43:54,000
 So that's why this is the formulation is.

405
00:43:55,000 --> 00:43:56,000
 Is a mean max of the.

406
00:43:57,000 --> 00:43:58,000
 Of the reward function.

407
00:44:13,000 --> 00:44:14,000
 So.

408
00:44:15,000 --> 00:44:16,000
 This.

409
00:44:17,000 --> 00:44:18,000
 This is.

410
00:44:19,000 --> 00:44:20,000
 Assume the.

411
00:44:21,000 --> 00:44:22,000
 Input X.

412
00:44:23,000 --> 00:44:24,000
 And the.

413
00:44:25,000 --> 00:44:26,000
 The D.

414
00:44:27,000 --> 00:44:29,000
 The input training data is have a.

415
00:44:30,000 --> 00:44:31,000
 Distribution of X and with the.

416
00:44:32,000 --> 00:44:33,000
 Discmentor they are.

417
00:44:34,000 --> 00:44:36,000
 We call their entropy actually is.

418
00:44:37,000 --> 00:44:38,000
 The input.

419
00:44:39,000 --> 00:44:40,000
 The input.

420
00:44:40,000 --> 00:44:41,000
 Yeah.

421
00:44:42,000 --> 00:44:43,000
 Entropy actually is.

422
00:44:44,000 --> 00:44:46,000
 Information theory will be like this.

423
00:44:47,000 --> 00:44:48,000
 And.

424
00:44:49,000 --> 00:44:50,000
 The.

425
00:44:52,000 --> 00:44:53,000
 So we have one.

426
00:44:54,000 --> 00:44:55,000
 Triton maximum reward on one.

427
00:44:56,000 --> 00:44:57,000
 Minimize the reward.

428
00:44:57,000 --> 00:44:59,000
 So when we do the minimizer reward.

429
00:44:59,000 --> 00:45:00,000
 We should be.

430
00:45:01,000 --> 00:45:02,000
 And.

431
00:45:07,000 --> 00:45:08,000
 Those are.

432
00:45:08,000 --> 00:45:09,000
 Gam.

433
00:45:12,000 --> 00:45:13,000
 So.

434
00:45:14,000 --> 00:45:16,000
 This is actually.

435
00:45:17,000 --> 00:45:18,000
 Based on the Nash.

436
00:45:19,000 --> 00:45:20,000
 Euclid.

437
00:45:20,000 --> 00:45:21,000
 And.

438
00:45:22,000 --> 00:45:24,000
 So now I have a question right.

439
00:45:25,000 --> 00:45:26,000
 Assuming this.

440
00:45:26,000 --> 00:45:28,000
 Guy network is fully trained.

441
00:45:29,000 --> 00:45:30,000
 And it's converged.

442
00:45:32,000 --> 00:45:33,000
 What are we going to be the.

443
00:45:34,000 --> 00:45:35,000
 Output of the discriminator.

444
00:45:39,000 --> 00:45:40,000
 What's the value.

445
00:45:46,000 --> 00:45:47,000
 Actually.

446
00:45:48,000 --> 00:45:49,000
 I see this one was.

447
00:45:50,000 --> 00:45:51,000
 One was a question exam questions.

448
00:45:52,000 --> 00:45:54,000
 In the last year's video signal processing.

449
00:45:55,000 --> 00:45:56,000
 The.

450
00:45:56,000 --> 00:45:57,000
 Will not appear again in this course.

451
00:45:58,000 --> 00:45:59,000
 Is.

452
00:46:00,000 --> 00:46:01,000
 Here is.

453
00:46:03,000 --> 00:46:04,000
 Assumption that.

454
00:46:04,000 --> 00:46:05,000
 Of course.

455
00:46:06,000 --> 00:46:07,000
 Assumption that.

456
00:46:09,000 --> 00:46:10,000
 That you have an output of.

457
00:46:11,000 --> 00:46:12,000
 Zero to one zero means.

458
00:46:13,000 --> 00:46:14,000
 Is fact.

459
00:46:14,000 --> 00:46:15,000
 One means is true.

460
00:46:16,000 --> 00:46:19,000
 And when the network is fully trained right.

461
00:46:21,000 --> 00:46:24,000
 I will hope this generator can generate image.

462
00:46:25,000 --> 00:46:26,000
 That can.

463
00:46:27,000 --> 00:46:28,000
 Create.

464
00:46:29,000 --> 00:46:31,000
 That looks like a real risk image right.

465
00:46:32,000 --> 00:46:33,000
 Because these two images are.

466
00:46:34,000 --> 00:46:36,000
 The general image and the real world image.

467
00:46:37,000 --> 00:46:38,000
 Close to each other.

468
00:46:39,000 --> 00:46:40,000
 Disimulator.

469
00:46:41,000 --> 00:46:42,000
 No.

470
00:46:43,000 --> 00:46:44,000
 So.

471
00:46:45,000 --> 00:46:46,000
 When you cannot.

472
00:46:47,000 --> 00:46:48,000
 What that means.

473
00:46:49,000 --> 00:46:50,000
 Your output.

474
00:46:51,000 --> 00:46:52,000
 Between zero and one.

475
00:46:53,000 --> 00:46:54,000
 Right.

476
00:46:55,000 --> 00:46:56,000
 Ideally.

477
00:46:57,000 --> 00:46:58,000
 Point five.

478
00:47:00,000 --> 00:47:01,000
 This.

479
00:47:01,000 --> 00:47:02,000
 Is.

480
00:47:03,000 --> 00:47:04,000
 The training data.

481
00:47:05,000 --> 00:47:06,000
 And the general data.

482
00:47:07,000 --> 00:47:08,000
 Of the same distribution.

483
00:47:09,000 --> 00:47:10,000
 Right.

484
00:47:11,000 --> 00:47:12,000
 Otherwise it's not.

485
00:47:13,000 --> 00:47:14,000
 Only when.

486
00:47:15,000 --> 00:47:16,000
 Equal.

487
00:47:17,000 --> 00:47:18,000
 Generator.

488
00:47:19,000 --> 00:47:20,000
 Converged.

489
00:47:21,000 --> 00:47:22,000
 Of course if you try.

490
00:47:23,000 --> 00:47:24,000
 Encourage you every one.

491
00:47:25,000 --> 00:47:26,000
 You.

492
00:47:31,000 --> 00:47:32,000
 Can network.

493
00:47:33,000 --> 00:47:34,000
 To see.

494
00:47:35,000 --> 00:47:36,000
 How the.

495
00:47:37,000 --> 00:47:38,000
 Loss.

496
00:47:38,000 --> 00:47:39,000
 Changes.

497
00:47:40,000 --> 00:47:41,000
 Training.

498
00:47:42,000 --> 00:47:43,000
 Training of the.

499
00:47:44,000 --> 00:47:46,000
 Is it much different.

500
00:47:47,000 --> 00:47:48,000
 Compared with the training of the.

501
00:47:49,000 --> 00:47:50,000
 Simple.

502
00:47:51,000 --> 00:47:52,000
 Network.

503
00:47:53,000 --> 00:47:54,000
 Art.

504
00:47:55,000 --> 00:47:59,000
 So if you don't have experience you may not be able to change it very well.

505
00:48:02,000 --> 00:48:03,000
 So.

506
00:48:03,000 --> 00:48:04,000
 You just.

507
00:48:04,000 --> 00:48:05,000
 Take this as a.

508
00:48:07,000 --> 00:48:08,000
 Optional homework.

509
00:48:10,000 --> 00:48:11,000
 Yeah.

510
00:48:11,000 --> 00:48:12,000
 So.

511
00:48:12,000 --> 00:48:13,000
 I want.

512
00:48:17,000 --> 00:48:18,000
 Because.

513
00:48:19,000 --> 00:48:21,000
 I believe this is really very good.

514
00:48:21,000 --> 00:48:22,000
 So.

515
00:48:23,000 --> 00:48:24,000
 This is just.

516
00:48:25,000 --> 00:48:26,000
 The detailed.

517
00:48:27,000 --> 00:48:28,000
 So do I have to change this.

518
00:48:29,000 --> 00:48:30,000
 So.

519
00:48:31,000 --> 00:48:32,000
 Every time when we change the.

520
00:48:33,000 --> 00:48:34,000
 Model I we just get a.

521
00:48:35,000 --> 00:48:36,000
 Mini batch of the samples.

522
00:48:38,000 --> 00:48:39,000
 And to change.

523
00:48:40,000 --> 00:48:41,000
 The.

524
00:48:42,000 --> 00:48:43,000
 Dictator first.

525
00:48:44,000 --> 00:48:45,000
 And.

526
00:48:46,000 --> 00:48:47,000
 And.

527
00:48:47,000 --> 00:48:48,000
 Of course.

528
00:48:48,000 --> 00:48:50,000
 Change all that you can make text steps.

529
00:48:51,000 --> 00:48:52,000
 And after this.

530
00:48:52,000 --> 00:48:53,000
 Change.

531
00:48:53,000 --> 00:48:54,000
 We change the generator.

532
00:48:55,000 --> 00:48:56,000
 And these two are.

533
00:48:56,000 --> 00:48:57,000
 Keep.

534
00:48:57,000 --> 00:48:58,000
 It.

535
00:48:58,000 --> 00:48:59,000
 Ration.

536
00:49:17,000 --> 00:49:18,000
 So.

537
00:49:18,000 --> 00:49:19,000
 An artist.

538
00:49:31,000 --> 00:49:32,000
 And we see.

539
00:49:32,000 --> 00:49:34,000
 The left one is a real one.

540
00:49:39,000 --> 00:49:41,000
 Or the left one is the fake one.

541
00:49:44,000 --> 00:49:45,000
 How do you know.

542
00:49:46,000 --> 00:49:48,000
 I'm making one and tell yourself.

543
00:49:48,000 --> 00:49:50,000
 Tell me the answer.

544
00:49:51,000 --> 00:49:52,000
 Yeah.

545
00:49:55,000 --> 00:49:56,000
 Okay.

546
00:49:58,000 --> 00:49:59,000
 Okay.

547
00:49:59,000 --> 00:50:01,000
 So this actually is.

548
00:50:08,000 --> 00:50:10,000
 And each each.

549
00:50:11,000 --> 00:50:12,000
 It actually is.

550
00:50:12,000 --> 00:50:13,000
 It should not be the.

551
00:50:14,000 --> 00:50:16,000
 Limitation of the gun theory.

552
00:50:16,000 --> 00:50:18,000
 But it's actually because of the.

553
00:50:19,000 --> 00:50:20,000
 Implementation of the actual.

554
00:50:24,000 --> 00:50:25,000
 So.

555
00:50:33,000 --> 00:50:34,000
 So.

556
00:50:34,000 --> 00:50:35,000
 Why is this one.

557
00:50:36,000 --> 00:50:37,000
 Why is this happens.

558
00:50:38,000 --> 00:50:40,000
 It's actually because of the generator.

559
00:50:40,000 --> 00:50:41,000
 So.

560
00:50:41,000 --> 00:50:43,000
 The generator can be used now.

561
00:50:45,000 --> 00:50:47,000
 Very often we use.

562
00:50:47,000 --> 00:50:49,000
 So called encoder decoder.

563
00:50:49,000 --> 00:50:51,000
 Or, or unit kind of structures.

564
00:50:52,000 --> 00:50:53,000
 And these are structures.

565
00:50:53,000 --> 00:50:54,000
 Right.

566
00:50:54,000 --> 00:50:55,000
 So.

567
00:50:55,000 --> 00:50:58,000
 They cannot maintain some of the high frequency information.

568
00:50:59,000 --> 00:51:00,000
 So.

569
00:51:01,000 --> 00:51:02,000
 Although it.

570
00:51:03,000 --> 00:51:04,000
 Maintain maturity of information.

571
00:51:04,000 --> 00:51:05,000
 It's not.

572
00:51:05,000 --> 00:51:08,000
 Some of the high frequency vision is lost.

573
00:51:08,000 --> 00:51:09,000
 That's the details you are.

574
00:51:10,000 --> 00:51:11,000
 Cannot be seen now.

575
00:51:30,000 --> 00:51:31,000
 I should have been.

576
00:51:32,000 --> 00:51:33,000
 I thought some.

577
00:51:33,000 --> 00:51:34,000
 Some.

578
00:51:34,000 --> 00:51:38,000
 Several years experiencing in one of the companies.

579
00:51:39,000 --> 00:51:42,000
 And at that time we once developed some.

580
00:51:43,000 --> 00:51:44,000
 Some.

581
00:51:47,000 --> 00:51:49,000
 Arquisms to teach.

582
00:51:50,000 --> 00:51:52,000
 Or teach the younger students.

583
00:51:54,000 --> 00:51:55,000
 So what do we do?

584
00:51:55,000 --> 00:51:56,000
 We.

585
00:51:56,000 --> 00:51:57,000
 We actually.

586
00:51:58,000 --> 00:51:59,000
 Give a whiteboard.

587
00:51:59,000 --> 00:52:01,000
 And let the student the child to.

588
00:52:02,000 --> 00:52:03,000
 Joe something on the board.

589
00:52:04,000 --> 00:52:05,000
 And then we will generate.

590
00:52:07,000 --> 00:52:08,000
 An image that.

591
00:52:09,000 --> 00:52:12,000
 Partially controlled by how they generate.

592
00:52:13,000 --> 00:52:14,000
 Joe the controls.

593
00:52:14,000 --> 00:52:15,000
 For example, if they draw.

594
00:52:16,000 --> 00:52:17,000
 Dirty line like that.

595
00:52:17,000 --> 00:52:18,000
 Right.

596
00:52:18,000 --> 00:52:19,000
 We will have a mountain be generated.

597
00:52:20,000 --> 00:52:22,000
 This is the shape of the mountain follows.

598
00:52:23,000 --> 00:52:24,000
 That's here.

599
00:52:26,000 --> 00:52:27,000
 And we can.

600
00:52:27,000 --> 00:52:28,000
 Joe something green.

601
00:52:29,000 --> 00:52:31,000
 It will help the creator green grass.

602
00:52:32,000 --> 00:52:33,000
 We do something blue.

603
00:52:33,000 --> 00:52:35,000
 It will help your blue sky.

604
00:52:36,000 --> 00:52:37,000
 So this is how.

605
00:52:39,000 --> 00:52:40,000
 The AI.

606
00:52:41,000 --> 00:52:42,000
 Can't do.

607
00:52:43,000 --> 00:52:44,000
 Right now.

608
00:52:44,000 --> 00:52:45,000
 But how you can see.

609
00:52:58,000 --> 00:53:00,000
 So at the early time when the guy is.

610
00:53:01,000 --> 00:53:02,000
 Invented.

611
00:53:03,000 --> 00:53:04,000
 So.

612
00:53:04,000 --> 00:53:06,000
 I think they first try to generate.

613
00:53:06,000 --> 00:53:07,000
 The face.

614
00:53:08,000 --> 00:53:10,000
 So of course for face here we are.

615
00:53:11,000 --> 00:53:12,000
 Using the cropped face and.

616
00:53:13,000 --> 00:53:14,000
 Different faces.

617
00:53:14,000 --> 00:53:17,000
 And the picture issue just now we have a low quality right.

618
00:53:18,000 --> 00:53:19,000
 So they.

619
00:53:20,000 --> 00:53:21,000
 The people was trying to.

620
00:53:22,000 --> 00:53:23,000
 Figure out.

621
00:53:23,000 --> 00:53:25,000
 New which to improve the quality.

622
00:53:26,000 --> 00:53:27,000
 So.

623
00:53:28,000 --> 00:53:29,000
 So.

624
00:53:29,000 --> 00:53:30,000
 So.

625
00:53:30,000 --> 00:53:31,000
 So.

626
00:53:31,000 --> 00:53:32,000
 So.

627
00:53:32,000 --> 00:53:33,000
 So.

628
00:53:33,000 --> 00:53:34,000
 So.

629
00:53:34,000 --> 00:53:35,000
 So.

630
00:53:35,000 --> 00:53:36,000
 So.

631
00:53:36,000 --> 00:53:37,000
 So.

632
00:53:37,000 --> 00:53:38,000
 So.

633
00:53:38,000 --> 00:53:39,000
 So.

634
00:53:39,000 --> 00:53:40,000
 So.

635
00:53:40,000 --> 00:53:41,000
 So.

636
00:53:41,000 --> 00:53:42,000
 So.

637
00:53:43,000 --> 00:53:44,000
 So.

638
00:53:47,000 --> 00:53:48,000
 Yeah.

639
00:53:50,000 --> 00:53:51,000
 Yeah.

640
00:53:51,000 --> 00:53:53,000
 But you follow interest you can.

641
00:53:54,000 --> 00:53:57,000
 find the paper is some other published paper and quite famous.

642
00:53:58,000 --> 00:54:01,000
 And the quality being image or quality be generous.

643
00:54:02,000 --> 00:54:04,000
 Is higher than.

644
00:54:04,000 --> 00:54:06,000
 The very original gun.

645
00:54:06,000 --> 00:54:11,000
 And this year we saw this picture, right?

646
00:54:18,080 --> 00:54:23,080
 So, and I think in 2006, there was three papers

647
00:54:25,360 --> 00:54:28,320
 and all the AI.

648
00:54:28,320 --> 00:54:31,960
 So one of the work should be this Boseman machine

649
00:54:31,960 --> 00:54:36,960
 and the one with the Nobel Prize is this.

650
00:54:47,120 --> 00:54:52,120
 So, so now just briefly you choose again, right?

651
00:54:52,240 --> 00:54:57,240
 So later we will show that gun can be used

652
00:54:57,240 --> 00:54:59,440
 in many, many different applications.

653
00:55:00,759 --> 00:55:03,279
 But one of the advantage of a gun is that

654
00:55:04,600 --> 00:55:08,600
 during the training of the gun, the generator

655
00:55:08,600 --> 00:55:10,520
 never sees the training data.

656
00:55:10,520 --> 00:55:12,839
 So let's go back to the beginning.

657
00:55:12,839 --> 00:55:15,839
 So, let's say we have a machine that

658
00:55:15,839 --> 00:55:20,040
 has a machine that can be used in many different applications.

659
00:55:20,960 --> 00:55:23,640
 So let's go back to the slides just now.

660
00:55:34,960 --> 00:55:36,800
 Okay, we look at here, right?

661
00:55:39,040 --> 00:55:41,440
 Our real world image as a training data,

662
00:55:42,720 --> 00:55:46,600
 it was an input to the discriminator, right?

663
00:55:47,600 --> 00:55:51,839
 But it was never an input to the generator.

664
00:55:53,880 --> 00:55:56,960
 Right, that means when I choose the generator,

665
00:55:58,200 --> 00:56:00,520
 I do not have a direct input,

666
00:56:00,520 --> 00:56:03,120
 do not have access of the, or direct access

667
00:56:03,120 --> 00:56:04,400
 of the real world images.

668
00:56:06,960 --> 00:56:08,440
 So that means the generator,

669
00:56:08,440 --> 00:56:09,279
 let me see,

670
00:56:09,280 --> 00:56:14,280
 you only see based on the feedback from the discriminator.

671
00:56:22,440 --> 00:56:26,640
 This is actually different from the normal

672
00:56:28,440 --> 00:56:30,760
 seeing a network, right?

673
00:56:30,760 --> 00:56:32,960
 When we check seeing a network,

674
00:56:33,920 --> 00:56:36,400
 you can just consider this discriminator

675
00:56:36,520 --> 00:56:37,880
 and the network, right?

676
00:56:45,880 --> 00:56:48,480
 Did not see the training images.

677
00:56:49,960 --> 00:56:54,960
 This actually was at the pages of gun that is,

678
00:57:07,320 --> 00:57:12,320
 it's make it more robust to avoid overfitting.

679
00:57:16,480 --> 00:57:21,480
 So, now let's compare the gun with a normal deep learning

680
00:57:24,680 --> 00:57:27,520
 or normal seeing or chat warmers.

681
00:57:27,520 --> 00:57:31,720
 So a normal deep learning is try to train a network

682
00:57:31,720 --> 00:57:35,920
 based on those functions of the network.

683
00:57:37,120 --> 00:57:41,400
 And so let's say we, if we want to share

684
00:57:42,480 --> 00:57:46,680
 a simple common network, G, right?

685
00:57:46,680 --> 00:57:49,680
 So we are trying to meet my loss of G.

686
00:57:55,600 --> 00:57:58,720
 Full players, why is this matter, why is generator?

687
00:57:58,720 --> 00:58:00,120
 Instead of a simple,

688
00:58:02,240 --> 00:58:04,000
 here only one players, right?

689
00:58:06,400 --> 00:58:11,400
 Now I give, let you have 10 minutes to try.

690
00:58:21,000 --> 00:58:26,000
 If my objective function is designed to be,

691
00:58:29,080 --> 00:58:34,080
 have input X and Y, my objective is X times Y.

692
00:58:36,400 --> 00:58:41,400
 You try to see why this function is not differentiable

693
00:58:45,760 --> 00:58:47,240
 or not converged.

694
00:58:50,320 --> 00:58:51,820
 I give you 10 minutes to try.

695
00:59:06,400 --> 00:59:07,240
 Okay.

696
00:59:18,920 --> 00:59:20,880
 Of course you can look at yours.

697
00:59:20,880 --> 00:59:22,680
 So you have a couple of notes, right?

698
00:59:22,680 --> 00:59:24,840
 You can have a look at the notes

699
00:59:24,840 --> 00:59:29,840
 and follow the notes to try to understand this.

700
00:59:36,400 --> 00:59:37,240
 Okay.

701
01:06:36,400 --> 01:06:37,240
 Okay.

702
01:07:07,400 --> 01:07:09,360
 Let's go through this together.

703
01:07:09,360 --> 01:07:14,360
 So to change this game with this objective function, right?

704
01:07:25,400 --> 01:07:30,400
 So we will need to maximize this value

705
01:07:31,240 --> 01:07:35,360
 to find the Y, to maximize value first.

706
01:07:35,360 --> 01:07:38,440
 Then find the X to minimize this value.

707
01:07:39,680 --> 01:07:44,680
 So let's first assume a set of one.

708
01:07:46,720 --> 01:07:49,280
 Where both X and Y are positive.

709
01:07:49,280 --> 01:07:51,640
 Therefore the V is positive, right?

710
01:07:51,640 --> 01:07:56,640
 So at this time, if we want to adjust Y,

711
01:07:57,480 --> 01:08:00,800
 such that this V XY is maximized, what do we do?

712
01:08:00,800 --> 01:08:02,480
 We will increase Y, right?

713
01:08:03,400 --> 01:08:08,400
 And after Y is increased, it's still positive.

714
01:08:10,520 --> 01:08:15,520
 And the next step is try to minimize this V XY

715
01:08:16,040 --> 01:08:17,040
 by decrease X, right?

716
01:08:17,040 --> 01:08:22,040
 So we will need to increase Y first and decrease X.

717
01:08:22,760 --> 01:08:27,760
 So by increase, if the status is still XY positive, right?

718
01:08:32,000 --> 01:08:35,000
 We will keep increase Y and keep decrease X.

719
01:08:35,000 --> 01:08:38,000
 So and this is the end of the game.

720
01:08:38,000 --> 01:08:42,000
 So we will increase Y and decrease X.

721
01:08:42,000 --> 01:08:45,000
 So we will increase Y and decrease X.

722
01:08:45,680 --> 01:08:47,960
 So until what time?

723
01:08:47,960 --> 01:08:51,319
 Until X smaller than zero, right?

724
01:08:56,160 --> 01:09:01,160
 So from set one, where both X and Y are positive,

725
01:09:01,240 --> 01:09:05,300
 we keep increase Y and decrease X.

726
01:09:05,300 --> 01:09:07,560
 We will eventually come to set two,

727
01:09:07,560 --> 01:09:10,160
 where X is smaller than zero,

728
01:09:10,160 --> 01:09:13,680
 because we are, because Y is keeping increasing, right?

729
01:09:13,680 --> 01:09:15,800
 So Y will still be positive.

730
01:09:15,800 --> 01:09:18,260
 But at this time, V will be negative.

731
01:09:19,320 --> 01:09:22,160
 And instead too, right?

732
01:09:22,160 --> 01:09:24,520
 We will try to do the same thing,

733
01:09:25,400 --> 01:09:29,560
 because this is negative.

734
01:09:29,560 --> 01:09:34,560
 Now we try to maximize the V XY.

735
01:09:34,920 --> 01:09:37,400
 Maximize the V XY.

736
01:09:41,160 --> 01:09:44,680
 We will want to, because it's a negative value,

737
01:09:44,680 --> 01:09:47,640
 we want to reduce Y, right?

738
01:09:47,640 --> 01:09:52,200
 Because if Y is, since Y is positive,

739
01:09:52,200 --> 01:09:56,160
 we reduce it, we will make the overall product smaller.

740
01:09:57,880 --> 01:10:02,000
 And because this is a negative sign here,

741
01:10:02,000 --> 01:10:03,840
 the X is negative.

742
01:10:03,840 --> 01:10:06,440
 So we will reduce it, it will,

743
01:10:06,440 --> 01:10:08,920
 overall value will be increased.

744
01:10:08,920 --> 01:10:12,440
 And easily you can draw that.

745
01:10:13,640 --> 01:10:15,880
 At this time, we want to decrease X,

746
01:10:15,880 --> 01:10:17,720
 because make the X smaller,

747
01:10:19,160 --> 01:10:22,560
 it will make the overall V smaller.

748
01:10:24,480 --> 01:10:28,240
 So you continue this from,

749
01:10:29,600 --> 01:10:31,880
 you continue decrease Y and X,

750
01:10:31,880 --> 01:10:34,400
 and here it goes to the step three,

751
01:10:34,400 --> 01:10:37,640
 where the, because you are keep decreasing the Y

752
01:10:37,640 --> 01:10:41,400
 until you decrease X, then both XY will be negative.

753
01:10:41,400 --> 01:10:43,960
 And at this time, V will be positive again.

754
01:10:46,320 --> 01:10:50,360
 And then you repeat this, you will get step four,

755
01:10:50,360 --> 01:10:53,480
 because here you are, you will need to decrease Y

756
01:10:53,480 --> 01:10:56,840
 and increase X, you make X become positive,

757
01:10:56,840 --> 01:11:00,520
 Y is negative, and then you will have to increase Y

758
01:11:00,520 --> 01:11:05,000
 and increase X to optimize this function.

759
01:11:11,920 --> 01:11:13,680
 Eventually you will come back to,

760
01:11:17,040 --> 01:11:19,240
 come back to step five,

761
01:11:19,240 --> 01:11:22,760
 which is actually same as step one.

762
01:11:22,760 --> 01:11:25,520
 So that means you want to change this function, right?

763
01:11:26,360 --> 01:11:31,000
 If you are doing a cycling,

764
01:11:31,000 --> 01:11:32,440
 going back to original steps,

765
01:11:32,440 --> 01:11:34,560
 so it will never converge.

766
01:11:38,840 --> 01:11:43,600
 Okay, so now we have 15 minutes break.

767
01:11:43,600 --> 01:11:47,920
 And after that we will talk about the variation of the guns

768
01:11:47,920 --> 01:11:52,920
 and eventually how guns apply to the videos.

769
01:11:53,920 --> 01:11:54,760
 Okay.

770
01:12:02,920 --> 01:12:06,920
 You will come back by 7.57.

771
01:12:17,280 --> 01:12:18,520
 During the break time,

772
01:12:18,520 --> 01:12:20,440
 if you have any questions on the first part,

773
01:12:20,440 --> 01:12:21,440
 you can approach me.

774
01:12:22,920 --> 01:12:23,760
 Thank you.

775
01:12:52,920 --> 01:12:54,760
 Thank you.

776
01:13:22,920 --> 01:13:24,760
 Thank you.

777
01:13:52,920 --> 01:13:54,760
 Thank you.

778
01:14:22,920 --> 01:14:23,760
 Thank you.

779
01:14:52,920 --> 01:14:54,600
 Thank you.

780
01:15:22,920 --> 01:15:24,760
 Thank you.

781
01:15:52,920 --> 01:15:53,760
 Thank you.

782
01:16:22,920 --> 01:16:23,760
 Thank you.

783
01:16:52,920 --> 01:16:54,760
 Thank you.

784
01:17:22,920 --> 01:17:23,760
 Thank you.

785
01:17:52,920 --> 01:17:53,760
 Thank you.

786
01:18:22,920 --> 01:18:23,760
 Thank you.

787
01:18:52,920 --> 01:18:53,760
 Thank you.

788
01:19:22,920 --> 01:19:23,760
 Thank you.

789
01:19:52,920 --> 01:19:53,760
 Thank you.

790
01:20:22,920 --> 01:20:23,760
 Thank you.

791
01:20:52,920 --> 01:20:53,760
 Thank you.

792
01:21:22,920 --> 01:21:23,760
 Thank you.

793
01:21:52,920 --> 01:21:53,760
 Thank you.

794
01:22:22,920 --> 01:22:23,760
 Thank you.

795
01:22:52,920 --> 01:22:53,760
 Thank you.

796
01:23:22,920 --> 01:23:23,920
 Thank you.

797
01:23:52,920 --> 01:23:54,920
 Thank you.

798
01:24:22,920 --> 01:24:23,920
 Thank you.

799
01:24:52,920 --> 01:24:54,920
 Thank you.

800
01:25:22,920 --> 01:25:23,920
 Thank you.

801
01:25:52,920 --> 01:25:54,920
 Thank you.

802
01:26:22,920 --> 01:26:24,920
 Thank you.

803
01:26:52,920 --> 01:26:53,920
 Thank you.

804
01:27:12,920 --> 01:27:14,920
 Let's continue the second part.

805
01:27:15,920 --> 01:27:20,920
 Just now we choose the basic concept of the

806
01:27:20,920 --> 01:27:22,920
 generative network, right?

807
01:27:22,920 --> 01:27:28,920
 So that network will ask you to give a random input

808
01:27:28,920 --> 01:27:31,920
 and generate something, right?

809
01:27:31,920 --> 01:27:36,920
 But what if I want to give some,

810
01:27:36,920 --> 01:27:39,920
 ask the generative network to generate a certain thing

811
01:27:39,920 --> 01:27:41,920
 or certain type of object,

812
01:27:41,920 --> 01:27:45,920
 or some object in certain locations.

813
01:27:45,920 --> 01:27:48,920
 Let's say I want this generator to generate

814
01:27:48,920 --> 01:27:53,920
 a picture of an apple or a picture of a human.

815
01:27:53,920 --> 01:27:54,920
 How do I do it?

816
01:27:54,920 --> 01:27:58,920
 Because you, or your other words, right?

817
01:27:58,920 --> 01:28:01,920
 Which random variable I should give the generator

818
01:28:01,920 --> 01:28:08,920
 such that it can generate an apple or generate a facial image, right?

819
01:28:08,920 --> 01:28:13,920
 So it's actually very difficult for me to tell that.

820
01:28:13,920 --> 01:28:17,920
 So to overcome this issue, right?

821
01:28:18,920 --> 01:28:24,920
 We, and new concept or a variation of the gun

822
01:28:24,920 --> 01:28:26,920
 is called conditional gun.

823
01:28:26,920 --> 01:28:32,920
 Which is, I want to make the generator to generate

824
01:28:32,920 --> 01:28:36,920
 something conditional to an input.

825
01:28:36,920 --> 01:28:41,920
 So if my input is to say, I may give the input like,

826
01:28:41,920 --> 01:28:46,920
 I want to generate an image of apple.

827
01:28:46,920 --> 01:28:51,920
 So the generator will give me an image of apple.

828
01:28:51,920 --> 01:28:54,920
 So now you have the chat gpt, right?

829
01:28:54,920 --> 01:28:56,920
 So I'm not sure you can try.

830
01:28:56,920 --> 01:29:01,920
 I think you can, it's able to generate some images.

831
01:29:01,920 --> 01:29:06,920
 You can try chat gpt, even the basic free version.

832
01:29:07,920 --> 01:29:13,920
 So if we remove this C class part.

833
01:29:13,920 --> 01:29:15,920
 So here we have real world data.

834
01:29:15,920 --> 01:29:18,920
 We have a random variable noise.

835
01:29:18,920 --> 01:29:21,920
 Go through a generator to generate fake data and the generator.

836
01:29:21,920 --> 01:29:25,920
 This is the classical gun, right?

837
01:29:25,920 --> 01:29:30,920
 And the conditional guys, we have a mission here.

838
01:29:30,920 --> 01:29:33,920
 This is also input.

839
01:29:33,920 --> 01:29:38,920
 And this condition will be connected to the,

840
01:29:38,920 --> 01:29:45,920
 give to the, actually will be combined with the training data here.

841
01:29:45,920 --> 01:29:51,920
 And also give the input link to the generator.

842
01:29:51,920 --> 01:29:57,920
 So that means the generator will take the input of both the

843
01:29:57,920 --> 01:30:02,920
 condition and the random noise.

844
01:30:16,920 --> 01:30:18,920
 It's actually simple, right?

845
01:30:18,920 --> 01:30:22,920
 So you give a condition, you give me your condition.

846
01:30:22,920 --> 01:30:26,920
 And I'm going to give this, pass this condition to both the

847
01:30:26,920 --> 01:30:30,920
 training data and the generator.

848
01:30:30,920 --> 01:30:35,920
 So look carefully at, so this one will be give to the,

849
01:30:35,920 --> 01:30:40,920
 both the training data and the generator.

850
01:30:40,920 --> 01:30:47,920
 So let's say we want to use the minister digits data to

851
01:30:47,920 --> 01:30:52,920
 chain a generator, again, generate a digital number.

852
01:30:57,920 --> 01:31:01,920
 So if we use the original guy, right?

853
01:31:01,920 --> 01:31:06,920
 So it may take a random input to generate a number.

854
01:31:06,920 --> 01:31:09,920
 It could be any number from zero to nine.

855
01:31:09,920 --> 01:31:15,920
 But with the conditional, we will hope that we give this,

856
01:31:15,920 --> 01:31:18,920
 your input, give an input of one zero zero.

857
01:31:18,920 --> 01:31:22,920
 I can generate different variation of zero.

858
01:31:22,920 --> 01:31:25,920
 I gave a second input of zero one zero zero.

859
01:31:25,920 --> 01:31:30,920
 I will be able to generate one and until last zero zero one,

860
01:31:30,920 --> 01:31:34,920
 different initial nine.

861
01:31:34,920 --> 01:31:39,920
 So this is called conditional generation.

862
01:31:40,920 --> 01:31:45,920
 So what can we do with the conditional generation?

863
01:31:49,920 --> 01:31:56,920
 So for example, if I give you a input which is a label of,

864
01:31:56,920 --> 01:31:58,920
 or a symmetric labels,

865
01:31:58,920 --> 01:32:02,920
 let's say we use this blue color to represent the potential cars.

866
01:32:02,920 --> 01:32:05,920
 The green represents the trees.

867
01:32:05,920 --> 01:32:09,920
 Blue represents the sky.

868
01:32:14,920 --> 01:32:19,920
 A street immunizes.

869
01:32:19,920 --> 01:32:23,920
 So this is called conditional generation.

870
01:32:24,920 --> 01:32:28,920
 A street immunizes.

871
01:32:28,920 --> 01:32:30,920
 Right?

872
01:32:30,920 --> 01:32:40,920
 So here, the boundary of these labels of the car will defy,

873
01:32:40,920 --> 01:32:45,920
 or is like condition, where this car should be located.

874
01:32:45,920 --> 01:32:49,920
 It won't be a car here or here,

875
01:32:49,920 --> 01:32:54,920
 because my condition here is say this car should be here, here, here.

876
01:32:54,920 --> 01:32:56,920
 And the road should be here, right?

877
01:32:56,920 --> 01:32:57,920
 And the sky should be here.

878
01:32:57,920 --> 01:32:59,920
 So this should be sky.

879
01:32:59,920 --> 01:33:01,920
 It shouldn't be road.

880
01:33:01,920 --> 01:33:02,920
 And here it shouldn't be sky.

881
01:33:02,920 --> 01:33:04,920
 It should be road.

882
01:33:04,920 --> 01:33:07,920
 So this labels street.

883
01:33:13,920 --> 01:33:15,920
 Output.

884
01:33:19,920 --> 01:33:22,920
 At the same time, right, we can use this input.

885
01:33:22,920 --> 01:33:27,920
 Labels are the input on the street seen as output.

886
01:33:27,920 --> 01:33:31,920
 So this is a label to street.

887
01:33:31,920 --> 01:33:37,920
 But let's say if we give this as an input.

888
01:33:37,920 --> 01:33:44,920
 If the street seen as an input, this is the output.

889
01:33:44,920 --> 01:33:48,920
 What I'm doing?

890
01:33:48,920 --> 01:33:55,920
 If this street is an input, I pay this gun to get this.

891
01:33:55,920 --> 01:33:57,920
 What is the operation?

892
01:33:57,920 --> 01:34:00,920
 We call this symmetric representation, right?

893
01:34:00,920 --> 01:34:06,920
 So in the first part of this course, right, you may have learned,

894
01:34:06,920 --> 01:34:16,920
 we can use a different network to do a symmetric representation.

895
01:34:16,920 --> 01:34:21,920
 Conditional gun to do a symmetric representation.

896
01:34:21,920 --> 01:34:23,920
 Okay.

897
01:34:23,920 --> 01:34:34,920
 And there will be some difference between

898
01:34:34,920 --> 01:34:41,920
 for convolution network approach and the gun approach.

899
01:34:41,920 --> 01:34:47,920
 So if you have some experience, let's say do a segmentation of something.

900
01:34:47,920 --> 01:34:54,920
 So here, right, this is the satellite view images of the city, for example.

901
01:34:54,920 --> 01:34:57,920
 Or this may be white one, maybe the road.

902
01:34:57,920 --> 01:35:05,920
 The rest may be the trees or other fields, right?

903
01:35:05,920 --> 01:35:08,920
 From this input to the output, what we are doing.

904
01:35:08,920 --> 01:35:13,920
 We are trying to segment what are the road, right?

905
01:35:13,920 --> 01:35:20,920
 So if you ever have tried some training, some deep learning,

906
01:35:20,920 --> 01:35:25,920
 or you ever do segmentation approach,

907
01:35:25,920 --> 01:35:27,920
 there are some segments.

908
01:35:27,920 --> 01:35:30,920
 You may face what?

909
01:35:30,920 --> 01:35:32,920
 You may face where you do some things.

910
01:35:32,920 --> 01:35:37,920
 Your output may be discontinuous, right?

911
01:35:37,920 --> 01:35:41,920
 Let's say we do an edge detection, right?

912
01:35:41,920 --> 01:35:43,920
 A simple edge detection.

913
01:35:43,920 --> 01:35:45,920
 A lower line, right?

914
01:35:45,920 --> 01:35:51,920
 Some of the lines are very clear, but some place the line may be not that clear, right?

915
01:35:51,920 --> 01:35:55,920
 This quite often will appear, right?

916
01:35:55,920 --> 01:35:57,920
 So what will happen?

917
01:35:57,920 --> 01:36:00,920
 Your detection will be broken.

918
01:36:00,920 --> 01:36:05,920
 You will be able to detect easily in the background where the line is very clear.

919
01:36:05,920 --> 01:36:14,920
 But you may get disconnected or miss some lines as a place where the line is not that clear.

920
01:36:14,920 --> 01:36:18,920
 So you can see here, right?

921
01:36:18,920 --> 01:36:21,920
 We have a back.

922
01:36:21,920 --> 01:36:27,920
 If we use this as an input, we try to detect the lines, right?

923
01:36:27,920 --> 01:36:30,920
 You see here it's broken, right?

924
01:36:30,920 --> 01:36:40,920
 But we know in this back here the line is actually continuous, right?

925
01:36:40,920 --> 01:36:50,920
 We do a...

926
01:36:50,920 --> 01:36:53,920
 You will be...

927
01:36:53,920 --> 01:36:57,920
 have a better result in terms of the connectivity.

928
01:36:57,920 --> 01:37:00,920
 So you look at the...

929
01:37:00,920 --> 01:37:08,920
 If we check a gun, all the roads are actually continuously detected.

930
01:37:08,920 --> 01:37:17,920
 I want to say it won't be broken, but you get a chance of a broken road here will be small.

931
01:37:17,920 --> 01:37:25,920
 But if you want to check a direct sanitation, even we ask you to annotate where is the road, right?

932
01:37:25,920 --> 01:37:30,920
 It will be able to annotate correctly, right?

933
01:37:30,920 --> 01:37:35,920
 You know why?

934
01:37:35,920 --> 01:37:37,920
 The reason is...

935
01:37:37,920 --> 01:37:39,920
 Okay, you listen carefully.

936
01:37:39,920 --> 01:37:46,920
 The reason is when we are checking a gun with this input to get this output, right?

937
01:37:46,920 --> 01:37:55,920
 Our output, our training data, all are labeled with continuous levels.

938
01:37:55,920 --> 01:38:03,920
 If my output is not continuous from the discriminator point of view, right?

939
01:38:03,920 --> 01:38:05,920
 I can easily tell.

940
01:38:05,920 --> 01:38:11,920
 My ground choice is continuous, but my detection output is just continuous.

941
01:38:11,920 --> 01:38:24,920
 Later, we will make the gun to segment the road.

942
01:38:24,920 --> 01:38:30,920
 That has a distribution or visually looks similar to the training data.

943
01:38:30,920 --> 01:38:32,920
 And because of the training data is...

944
01:38:32,920 --> 01:38:34,920
 Because you annotate that, right?

945
01:38:34,920 --> 01:38:35,920
 So you will definitely...

946
01:38:35,920 --> 01:38:37,920
 You know it's all connected.

947
01:38:37,920 --> 01:38:46,920
 So because our training data is continuous, so your result from the gun will also be continuous.

948
01:38:46,920 --> 01:38:55,920
 And so this actually...

949
01:38:55,920 --> 01:38:59,920
 This is a task, an explanation.

950
01:38:59,920 --> 01:39:05,920
 We use the best approach, we will be better.

951
01:39:05,920 --> 01:39:14,920
 But of course, it will also come with consequence.

952
01:39:14,920 --> 01:39:18,920
 Just now, we mentioned, right?

953
01:39:18,920 --> 01:39:22,920
 The guys try to learn a distribution.

954
01:39:22,920 --> 01:39:34,920
 Let's go to the slides.

955
01:39:35,920 --> 01:39:45,920
 The guys are good at capturing the models of the distribution of the training data.

956
01:39:45,920 --> 01:39:52,920
 So my training data is all continuous, so my detection will be continuous.

957
01:39:52,920 --> 01:39:57,920
 Because if my detection is not continuous from the discriminator point of view, right?

958
01:39:57,920 --> 01:40:01,920
 I will just tell whether your output is continuous or not continuous.

959
01:40:01,920 --> 01:40:28,920
 Based on that, I can easily tell you whether your detection output is true or correct or not correct.

960
01:40:28,920 --> 01:40:31,920
 Okay.

961
01:40:31,920 --> 01:40:33,920
 Come back to here, right?

962
01:40:33,920 --> 01:40:41,920
 So we also have labels of the buildings or windows and structures and come back to the...

963
01:40:41,920 --> 01:40:44,920
 Converting to a true building.

964
01:40:44,920 --> 01:40:46,920
 If we go the other way wrong, right?

965
01:40:46,920 --> 01:40:49,920
 From these are the inputs, these are the outputs.

966
01:40:49,920 --> 01:40:53,920
 It will be similar to symmetric simulation.

967
01:40:53,920 --> 01:40:55,920
 And this case, right?

968
01:40:55,920 --> 01:40:57,920
 From color to gray scale, right?

969
01:40:57,920 --> 01:40:58,920
 Easy, right?

970
01:40:58,920 --> 01:41:01,920
 You have a simple equation to do that.

971
01:41:01,920 --> 01:41:04,920
 But from gray scale to color, right?

972
01:41:04,920 --> 01:41:06,920
 So...

973
01:41:06,920 --> 01:41:11,920
 Actually, from color to gray, some information is lost, right?

974
01:41:11,920 --> 01:41:14,920
 So from gray, come back to color, right?

975
01:41:14,920 --> 01:41:19,920
 So here we use scan or image-to-image translation.

976
01:41:19,920 --> 01:41:22,920
 We can achieve this.

977
01:41:22,920 --> 01:41:33,920
 Of course, we call this image-to-image translation is because my input and output are both like images, right?

978
01:41:33,920 --> 01:41:36,920
 Even though the schematic labels is...

979
01:41:36,920 --> 01:41:43,920
 You can display the images.

980
01:41:43,920 --> 01:41:45,920
 Also try night to day.

981
01:41:45,920 --> 01:41:49,920
 But I have some experience on this, right?

982
01:41:49,920 --> 01:41:55,920
 From day to night, you normally can do very well, right?

983
01:41:55,920 --> 01:42:02,920
 Because your day image normally have full information.

984
01:42:02,920 --> 01:42:04,920
 But from night to day, right?

985
01:42:04,920 --> 01:42:05,920
 You can try.

986
01:42:05,920 --> 01:42:08,920
 There are some chain network outside.

987
01:42:08,920 --> 01:42:10,920
 From night to day, you...

988
01:42:10,920 --> 01:42:13,920
 Major case, you want to get very good result.

989
01:42:13,920 --> 01:42:18,920
 Because at night, a lot of information here...

990
01:42:18,920 --> 01:42:20,920
 It's not well captured.

991
01:42:20,920 --> 01:42:22,920
 Here, like this...

992
01:42:22,920 --> 01:42:25,920
 We also call this a saturation.

993
01:42:25,920 --> 01:42:32,920
 Of course, over exposure or under exposure, both are too bright or too dark.

994
01:42:32,920 --> 01:42:35,920
 Both are called saturation.

995
01:42:35,920 --> 01:42:39,920
 Because this is a saturated, so you want to be able to see what's information here.

996
01:42:39,920 --> 01:42:43,920
 So you want to be able to recover this.

997
01:42:44,920 --> 01:42:51,920
 Here, from this sketch to the back, we call it...

998
01:42:51,920 --> 01:42:53,920
 Add the color into it.

999
01:42:53,920 --> 01:42:56,920
 The other way, from the back to the...

1000
01:42:56,920 --> 01:43:00,920
 This one is equivalent to edge detection.

1001
01:43:00,920 --> 01:43:02,920
 So you can see, right?

1002
01:43:02,920 --> 01:43:05,920
 From image to image translation, you can do a lot of things.

1003
01:43:05,920 --> 01:43:08,920
 You can do symmetric of sanitation.

1004
01:43:08,920 --> 01:43:12,920
 You can do greater color coloring.

1005
01:43:12,920 --> 01:43:16,920
 You can do day to night or day translation.

1006
01:43:16,920 --> 01:43:19,920
 You can do edge detection, right?

1007
01:43:19,920 --> 01:43:24,920
 So I'm also working on this to use image to image translation to...

1008
01:43:24,920 --> 01:43:28,920
 Let's say we have different camera, right?

1009
01:43:28,920 --> 01:43:40,920
 Of course, a camera will have so-called image processing to convert the raw input or raw data in the sensor side to the image you are seeing.

1010
01:43:40,920 --> 01:43:43,920
 In this process, they have removed the noise.

1011
01:43:43,920 --> 01:43:47,920
 But actually, different sensors may have different noise.

1012
01:43:47,920 --> 01:44:04,920
 So we can also do the image to image translation such that my data captured from device A can become data covered by device B.

1013
01:44:10,920 --> 01:44:26,920
 So...

1014
01:44:26,920 --> 01:44:32,920
 Image to image translation can be categorized into actually two different categories.

1015
01:44:32,920 --> 01:44:36,920
 One we call paired image to image translation.

1016
01:44:36,920 --> 01:44:39,920
 Of course, the other is figured out, right?

1017
01:44:39,920 --> 01:44:41,920
 It's unpaired.

1018
01:44:41,920 --> 01:44:42,920
 What's the difference?

1019
01:44:42,920 --> 01:44:47,920
 The difference is in paired image to image translation.

1020
01:44:47,920 --> 01:44:57,920
 We will have an image input with corresponding output.

1021
01:44:57,920 --> 01:45:02,920
 So let's say we have a...

1022
01:45:02,920 --> 01:45:03,920
 Downsampling, right?

1023
01:45:03,920 --> 01:45:05,920
 We have a factory image.

1024
01:45:05,920 --> 01:45:14,920
 Downsampling, please.

1025
01:45:14,920 --> 01:45:16,920
 Or do segmentation, right?

1026
01:45:16,920 --> 01:45:20,920
 From a street image to a...

1027
01:45:20,920 --> 01:45:21,920
 ...segmentation labels.

1028
01:45:21,920 --> 01:45:28,920
 Or from the labels to the synthesis of street images.

1029
01:45:28,920 --> 01:45:32,920
 And from a single image, right?

1030
01:45:32,920 --> 01:45:33,920
 To aspects.

1031
01:45:33,920 --> 01:45:40,920
 What's the depth of...

1032
01:45:40,920 --> 01:45:47,920
 Back to the images.

1033
01:45:47,920 --> 01:45:57,920
 So in paired image to image translation, we actually have one to one mapping between the...

1034
01:45:57,920 --> 01:46:13,920
 ...synced images.

1035
01:46:13,920 --> 01:46:18,920
 Now a quick test.

1036
01:46:18,920 --> 01:46:26,920
 If we...

1037
01:46:26,920 --> 01:46:32,920
 ...enraitor and to get a...

1038
01:46:32,920 --> 01:46:34,920
 ...back.

1039
01:46:34,920 --> 01:46:38,920
 And we also have a discriminator to tell whether it's true or not.

1040
01:46:38,920 --> 01:46:42,920
 Is this conditional?

1041
01:46:42,920 --> 01:46:43,920
 How many say yes?

1042
01:46:43,920 --> 01:46:47,920
 You can raise your hand.

1043
01:46:47,920 --> 01:46:50,920
 How many say no?

1044
01:46:50,920 --> 01:46:52,920
 Is it either yes or no?

1045
01:46:52,920 --> 01:46:53,920
 Okay, someone's...

1046
01:46:53,920 --> 01:47:05,920
 Try to be active, okay.

1047
01:47:05,920 --> 01:47:09,920
 So this actually is a...

1048
01:47:09,920 --> 01:47:16,920
 ...conversion of a gun.

1049
01:47:16,920 --> 01:47:17,920
 Here?

1050
01:47:17,920 --> 01:47:32,920
 Yeah?

1051
01:47:32,920 --> 01:47:34,920
 I give you the X.

1052
01:47:34,920 --> 01:47:41,920
 And we have a network G and TRD to generate this GX.

1053
01:47:41,920 --> 01:47:44,920
 And my network is like this.

1054
01:47:44,920 --> 01:47:50,920
 This one is not conditional gun.

1055
01:47:50,920 --> 01:47:56,920
 Which part is missing?

1056
01:47:56,920 --> 01:48:09,920
 I don't know.

1057
01:48:09,920 --> 01:48:14,920
 Not included what?

1058
01:48:14,920 --> 01:48:16,920
 No, not this.

1059
01:48:16,920 --> 01:48:21,920
 Actually, class is one kind of condition.

1060
01:48:21,920 --> 01:48:30,920
 Here, my condition is this.

1061
01:48:30,920 --> 01:48:33,920
 You know the answer?

1062
01:48:33,920 --> 01:48:35,920
 You try. Anybody can try.

1063
01:48:35,920 --> 01:48:38,920
 Remember, just now we were talking about gun, right?

1064
01:48:38,920 --> 01:48:48,920
 What's the input?

1065
01:48:48,920 --> 01:48:51,920
 Okay, you got some of the answers?

1066
01:48:51,920 --> 01:48:52,920
 Yes?

1067
01:48:52,920 --> 01:49:00,920
 So because the discriminator don't have the condition of the X.

1068
01:49:00,920 --> 01:49:04,920
 That's one reason is...

1069
01:49:04,920 --> 01:49:11,920
 Where is the random variable?

1070
01:49:11,920 --> 01:49:25,920
 So...

1071
01:49:25,920 --> 01:49:35,920
 This comes with the so-called X.

1072
01:49:35,920 --> 01:49:44,920
 We are...

1073
01:49:44,920 --> 01:49:46,920
 Conditional gun, right?

1074
01:49:46,920 --> 01:49:49,920
 So this X is a condition.

1075
01:49:49,920 --> 01:49:51,920
 And it comes with the generator.

1076
01:49:51,920 --> 01:49:54,920
 It also comes with the discriminator.

1077
01:49:54,920 --> 01:50:02,920
 This is the reason why the network just now is not conditional gun.

1078
01:50:02,920 --> 01:50:14,920
 Because the X is not given to the discriminator.

1079
01:50:14,920 --> 01:50:18,920
 Okay, this one I may want to skip.

1080
01:50:18,920 --> 01:50:27,920
 So this thing can be applied to supra-lucine.

1081
01:50:27,920 --> 01:50:33,920
 And this is supra-lucine again.

1082
01:50:33,920 --> 01:50:37,920
 Now let's talk about unpaired.

1083
01:50:37,920 --> 01:50:39,920
 The paired gun, right?

1084
01:50:39,920 --> 01:50:44,920
 In the paired image translation, you have one from one mapping.

1085
01:50:44,920 --> 01:50:50,920
 But in red here...

1086
01:50:50,920 --> 01:50:55,920
 Paired training data is a bit time consuming.

1087
01:50:55,920 --> 01:50:57,920
 Of course you can do it.

1088
01:50:57,920 --> 01:50:59,920
 But if...

1089
01:50:59,920 --> 01:51:05,920
 Let's say one year later you graduate and you take a job, right?

1090
01:51:05,920 --> 01:51:11,920
 If your company asks you just every day to collect the data,

1091
01:51:11,920 --> 01:51:14,920
 you will say, I don't want to do that.

1092
01:51:14,920 --> 01:51:16,920
 So trust me, that you will say that.

1093
01:51:16,920 --> 01:51:30,920
 That's why I'm always coming.

1094
01:51:30,920 --> 01:51:36,920
 Nobody like...

1095
01:51:36,920 --> 01:51:41,920
 Everybody like to work on something with high technology.

1096
01:51:41,920 --> 01:51:44,920
 And keep collecting the data is not something...

1097
01:51:44,920 --> 01:51:47,920
 Of course, sometimes we have to do that.

1098
01:51:47,920 --> 01:51:51,920
 But we always try to find our way.

1099
01:51:51,920 --> 01:51:55,920
 If I don't keep collecting the data, I still can't do it.

1100
01:51:55,920 --> 01:51:59,920
 So in reality, right?

1101
01:51:59,920 --> 01:52:05,920
 Let's say if we want to change the network,

1102
01:52:05,920 --> 01:52:11,920
 we can turn horses to zebras, right?

1103
01:52:11,920 --> 01:52:16,920
 It will be very difficult to have one-to-one machine

1104
01:52:16,920 --> 01:52:25,920
 where the shape of the horse is exactly the same as the zebra.

1105
01:52:25,920 --> 01:52:29,920
 You can easily get a lot of images of horses

1106
01:52:29,920 --> 01:52:32,920
 and get a lot of images of zebras.

1107
01:52:32,920 --> 01:52:39,920
 If you want these two animals to be exactly paired,

1108
01:52:39,920 --> 01:52:43,920
 it will be very difficult.

1109
01:52:43,920 --> 01:53:00,920
 But we still want zebras.

1110
01:53:00,920 --> 01:53:08,920
 So although each image will not have a mapping,

1111
01:53:08,920 --> 01:53:17,920
 one-to-one mapping, but these two domains could be mapped.

1112
01:53:17,920 --> 01:53:21,920
 For example, I may take an image of the horses

1113
01:53:21,920 --> 01:53:29,920
 where the size of the horse is comparable to the image of zebras.

1114
01:53:29,920 --> 01:53:35,920
 To the size of the zebras in the image of zebras.

1115
01:53:35,920 --> 01:53:43,920
 If this side is...

1116
01:53:43,920 --> 01:53:50,920
 So we call this...

1117
01:53:50,920 --> 01:53:54,920
 ...pair.

1118
01:53:54,920 --> 01:53:59,920
 And here comes the idea of a cycle gun.

1119
01:53:59,920 --> 01:54:02,920
 So inclusion is very simple, right?

1120
01:54:02,920 --> 01:54:05,920
 So if y have two domain x and y,

1121
01:54:05,920 --> 01:54:15,920
 I want to have a generator or a gun generator to convert x to y.

1122
01:54:15,920 --> 01:54:20,920
 But we also hope this y can come back to x.

1123
01:54:20,920 --> 01:54:24,920
 So x can go to y, y can come back to x.

1124
01:54:24,920 --> 01:54:27,920
 Then we have two generators.

1125
01:54:27,920 --> 01:54:30,920
 Y is called g, y is called f.

1126
01:54:30,920 --> 01:54:34,920
 So g is converted x to y.

1127
01:54:34,920 --> 01:54:37,920
 f is converted y to x.

1128
01:54:37,920 --> 01:54:41,920
 This forms a cycle, right?

1129
01:54:41,920 --> 01:54:45,920
 So I can fly from Singapore to China,

1130
01:54:45,920 --> 01:54:49,920
 but I should also be flying back, right?

1131
01:54:50,920 --> 01:54:56,920
 And this process, right?

1132
01:54:56,920 --> 01:54:59,920
 You can consider.

1133
01:55:20,920 --> 01:55:25,920
 You can consider, right?

1134
01:55:25,920 --> 01:55:30,920
 And if we compare...

1135
01:55:30,920 --> 01:55:35,920
 ...to the same thing for the y.

1136
01:55:35,920 --> 01:55:40,920
 So we try to minimize this cycle consistency.

1137
01:55:40,920 --> 01:55:44,920
 So we try to minimize this cycle consistency.

1138
01:55:45,920 --> 01:55:50,920
 Then we can change the...

1139
01:55:58,920 --> 01:56:03,920
 Let's say I do a translator, right?

1140
01:56:04,920 --> 01:56:10,920
 ...translator, right?

1141
01:56:10,920 --> 01:56:13,920
 ...from Chinese to the English.

1142
01:56:13,920 --> 01:56:22,920
 I hope that English...

1143
01:56:22,920 --> 01:56:26,920
 During the translation, all the information should be saved.

1144
01:56:26,920 --> 01:56:32,920
 If there's some information being lost, just come back.

1145
01:56:34,920 --> 01:56:37,920
 Just give it to the translation.

1146
01:56:37,920 --> 01:56:40,920
 Give it an English sentence.

1147
01:56:40,920 --> 01:56:45,920
 Let's try to translate to Chinese,

1148
01:56:45,920 --> 01:56:50,920
 and then translate it back to see whether it's the same or not.

1149
01:56:50,920 --> 01:56:53,920
 I believe it won't be identical,

1150
01:56:53,920 --> 01:56:58,920
 but a good network should be close to each other.

1151
01:57:03,920 --> 01:57:07,920
 So with a side gun, right?

1152
01:57:07,920 --> 01:57:10,920
 We can do...

1153
01:57:10,920 --> 01:57:16,920
 ...transfer for different weather from zebra to horse to zebra,

1154
01:57:16,920 --> 01:57:20,920
 and from summer to winter and winter to summer, right?

1155
01:57:20,920 --> 01:57:25,920
 So if we want to use a paired gun, right?

1156
01:57:25,920 --> 01:57:27,920
 The paired image...

1157
01:57:27,920 --> 01:57:31,920
 We need to collect the data from the summer and the same data,

1158
01:57:31,920 --> 01:57:34,920
 same place in the winter, right?

1159
01:57:34,920 --> 01:57:39,920
 So if I want to turn Singapore Street View,

1160
01:57:39,920 --> 01:57:41,920
 become a winter view, there's no way.

1161
01:57:41,920 --> 01:57:46,920
 Because we don't have paired winter...

1162
01:57:46,920 --> 01:57:53,920
 ...here, there, and take a picture in the summer

1163
01:57:53,920 --> 01:57:55,920
 and half a year later, right?

1164
01:57:55,920 --> 01:57:58,920
 The texture of the winter, then...

1165
01:57:58,920 --> 01:58:00,920
 Of course, you can get some data, right?

1166
01:58:00,920 --> 01:58:05,920
 But with a side gun, we do not use it, right?

1167
01:58:05,920 --> 01:58:08,920
 With a side gun, we can do...

1168
01:58:08,920 --> 01:58:14,920
 ...we can...

1169
01:58:14,920 --> 01:58:18,920
 ...the same city, maybe,

1170
01:58:18,920 --> 01:58:24,920
 and then we can turn to the buildings to be completely different.

1171
01:58:24,920 --> 01:58:30,920
 But at winter time, we do not require the camera to be at the same location,

1172
01:58:30,920 --> 01:58:34,920
 or exact same location, just similar location will be fine.

1173
01:58:34,920 --> 01:58:39,920
 And then we can change from winter to summer.

1174
01:58:39,920 --> 01:58:49,920
 And...

1175
01:58:49,920 --> 01:59:01,920
 ...for side gun, right?

1176
01:59:01,920 --> 01:59:04,920
 So actually even for normal gun, right?

1177
01:59:04,920 --> 01:59:13,920
 So there's one potential challenge is sometimes...

1178
01:59:13,920 --> 01:59:17,920
 ...the training, the model will be collapsed.

1179
01:59:17,920 --> 01:59:19,920
 So with the one-to-one mapping, right?

1180
01:59:19,920 --> 01:59:24,920
 We hope every item here have a unique mapping on the right side.

1181
01:59:24,920 --> 01:59:29,920
 But when the model collapsed, everything will be mapped to one thing.

1182
01:59:29,920 --> 01:59:44,920
 And this is the issue.

1183
01:59:44,920 --> 01:59:49,920
 Now just now we show some images.

1184
01:59:49,920 --> 01:59:52,920
 Effect...

1185
01:59:52,920 --> 01:59:55,920
 ...the real image, I ask you to...

1186
01:59:55,920 --> 01:59:57,920
 ...which one is the effect, right?

1187
01:59:58,920 --> 02:00:03,920
 I can see from the details, right?

1188
02:00:03,920 --> 02:00:08,920
 It's one of the weakness of the gun network.

1189
02:00:08,920 --> 02:00:18,920
 And this few years, there's another type of generation technology being popular,

1190
02:00:18,920 --> 02:00:22,920
 which we call diffusion.

1191
02:00:22,920 --> 02:00:32,920
 So I only want to introduce the concept of...

1192
02:00:32,920 --> 02:00:41,920
 ...input...

1193
02:00:41,920 --> 02:00:45,920
 ...turn this input one step into many, many steps.

1194
02:00:45,920 --> 02:00:49,920
 And in each step, I add some noise.

1195
02:00:49,920 --> 02:00:53,920
 So here is an image driver.

1196
02:00:53,920 --> 02:01:04,920
 I'll add some noise.

1197
02:01:04,920 --> 02:01:11,920
 Make this...

1198
02:01:11,920 --> 02:01:17,920
 ...like completely random, right?

1199
02:01:17,920 --> 02:01:21,920
 From X0 to X1, there's a network.

1200
02:01:21,920 --> 02:01:25,920
 Normally they use a unit structure.

1201
02:01:25,920 --> 02:01:31,920
 So if you haven't learned a unit, I think in my part, I will cover that.

1202
02:01:31,920 --> 02:01:35,920
 And from X2 to X1 to X2, there will be another unit.

1203
02:01:35,920 --> 02:01:38,920
 So let's say N is 1000.

1204
02:01:38,920 --> 02:01:41,920
 It's like true 1000 units.

1205
02:01:41,920 --> 02:01:43,920
 And each unit, you add some noise.

1206
02:01:43,920 --> 02:01:46,920
 You will get this random.

1207
02:01:46,920 --> 02:01:51,920
 And if we change this one, right?

1208
02:01:51,920 --> 02:01:58,920
 If we make use of ideal cycle gun, we should come back.

1209
02:01:58,920 --> 02:02:01,920
 So when we have that unit, we add noise.

1210
02:02:01,920 --> 02:02:10,920
 We also hope to have a unit that can remove noise.

1211
02:02:10,920 --> 02:02:15,920
 From X1, I want to go back to Xn minus one.

1212
02:02:15,920 --> 02:02:18,920
 I want to go back to Xn minus two.

1213
02:02:18,920 --> 02:02:23,920
 And cheer go back to X0.

1214
02:02:23,920 --> 02:02:26,920
 This...

1215
02:02:26,920 --> 02:02:29,920
 From left to right, we add noise, right?

1216
02:02:29,920 --> 02:02:35,920
 From right side to left side, we are removing noise.

1217
02:02:35,920 --> 02:02:38,920
 Or we can solve this noise.

1218
02:02:38,920 --> 02:02:40,920
 So...

1219
02:02:40,920 --> 02:02:44,920
 You can think of what...

1220
02:02:44,920 --> 02:02:49,920
 We may have some task to do noise removal, right?

1221
02:02:49,920 --> 02:02:55,920
 This place is to remove the noise, right?

1222
02:02:55,920 --> 02:03:01,920
 So this diffusion has an application that can be used for removal noise.

1223
02:03:01,920 --> 02:03:13,920
 But one of the big advantage of diffusion is that this process...

1224
02:03:14,920 --> 02:03:18,920
 ...

1225
02:03:18,920 --> 02:03:19,920
 ...

1226
02:03:19,920 --> 02:03:25,920
 ...

1227
02:03:25,920 --> 02:03:30,920
 ...

1228
02:03:30,920 --> 02:03:34,920
 ...

1229
02:03:34,920 --> 02:03:35,920
 ...

1230
02:03:35,920 --> 02:03:38,920
 ...

1231
02:03:38,920 --> 02:03:43,920
 ...

1232
02:03:43,920 --> 02:03:49,920
 So this you can try if you have some access of the GPUs.

1233
02:03:49,920 --> 02:03:52,920
 There are many public...

1234
02:03:52,920 --> 02:04:08,920
 ...

1235
02:04:08,920 --> 02:04:12,920
 Now, so...

1236
02:04:12,920 --> 02:04:17,920
 Just now we are talking about using image as an example.

1237
02:04:17,920 --> 02:04:20,920
 So come back to video.

1238
02:04:20,920 --> 02:04:24,920
 So how the game can be used to generate a video.

1239
02:04:24,920 --> 02:04:29,920
 Of course, the video may have images and...

1240
02:04:29,920 --> 02:04:30,920
 ...

1241
02:04:30,920 --> 02:04:31,920
 ...

1242
02:04:31,920 --> 02:04:32,920
 ...

1243
02:04:32,920 --> 02:04:33,920
 ...

1244
02:04:33,920 --> 02:04:34,920
 ...

1245
02:04:34,920 --> 02:04:35,920
 ...

1246
02:04:35,920 --> 02:04:36,920
 ...

1247
02:04:36,920 --> 02:04:37,920
 ...

1248
02:04:37,920 --> 02:04:38,920
 ...

1249
02:04:38,920 --> 02:04:39,920
 ...

1250
02:04:39,920 --> 02:04:40,920
 ...

1251
02:04:40,920 --> 02:04:43,920
 So video is a sequence of images.

1252
02:04:43,920 --> 02:04:46,920
 Just now we learn how to generate images.

1253
02:04:46,920 --> 02:04:49,920
 Now, to generate video, right?

1254
02:04:49,920 --> 02:04:52,920
 We actually generate a sequence of images.

1255
02:04:52,920 --> 02:05:05,920
 ...

1256
02:05:05,920 --> 02:05:06,920
 ...

1257
02:05:06,920 --> 02:05:07,920
 ...

1258
02:05:07,920 --> 02:05:08,920
 ...

1259
02:05:08,920 --> 02:05:09,920
 ...

1260
02:05:09,920 --> 02:05:10,920
 ...

1261
02:05:10,920 --> 02:05:13,920
 but I also make sure this a series image...

1262
02:05:13,920 --> 02:05:14,920
 ...

1263
02:05:14,920 --> 02:05:15,920
 ...

1264
02:05:15,920 --> 02:05:16,920
 ...

1265
02:05:16,920 --> 02:05:17,920
 ...

1266
02:05:17,920 --> 02:05:18,920
 ...

1267
02:05:18,920 --> 02:05:19,920
 ...

1268
02:05:19,920 --> 02:05:20,920
 ...

1269
02:05:20,920 --> 02:05:21,920
 ...

1270
02:05:21,920 --> 02:05:23,920
 So, how the way is...

1271
02:05:23,920 --> 02:05:24,920
 ...

1272
02:05:24,920 --> 02:05:25,920
 ...

1273
02:05:25,920 --> 02:05:26,920
 ...

1274
02:05:26,920 --> 02:05:27,920
 ...

1275
02:05:27,920 --> 02:05:28,920
 ...

1276
02:05:28,920 --> 02:05:29,920
 ...

1277
02:05:29,920 --> 02:05:30,920
 ...

1278
02:05:30,920 --> 02:05:31,920
 ...

1279
02:05:31,920 --> 02:05:32,920
 ...

1280
02:05:32,920 --> 02:05:37,920
 How we generate a video is take care of making sure the...

1281
02:05:37,920 --> 02:05:38,920
 ...

1282
02:05:38,920 --> 02:05:39,920
 ...

1283
02:05:39,920 --> 02:05:40,920
 ...

1284
02:05:40,920 --> 02:05:41,920
 ...

1285
02:05:41,920 --> 02:05:42,920
 ...

1286
02:05:42,920 --> 02:05:43,920
 ...

1287
02:05:43,920 --> 02:05:44,920
 ...

1288
02:05:44,920 --> 02:05:45,920
 ...

1289
02:05:45,920 --> 02:05:46,920
 ...

1290
02:05:46,920 --> 02:05:47,920
 ...

1291
02:05:47,920 --> 02:05:48,920
 ...

1292
02:05:48,920 --> 02:05:49,920
 ...

1293
02:05:49,920 --> 02:05:50,920
 ...

1294
02:05:50,920 --> 02:05:51,920
 ...

1295
02:05:51,920 --> 02:05:52,920
 And of course, you can use...

1296
02:05:52,920 --> 02:05:53,920
 ...

1297
02:05:53,920 --> 02:05:54,920
 ...

1298
02:05:54,920 --> 02:05:55,920
 ...

1299
02:05:55,920 --> 02:05:56,920
 ...

1300
02:05:56,920 --> 02:05:57,920
 ...

1301
02:05:57,920 --> 02:05:58,920
 ...

1302
02:05:58,920 --> 02:06:01,920
 ...

1303
02:06:01,920 --> 02:06:06,920
 So let's come to some other approach

1304
02:06:08,760 --> 02:06:12,760
 where they convert a text for video.

1305
02:06:14,880 --> 02:06:19,880
 So when we generate a single image, right?

1306
02:06:19,960 --> 02:06:24,960
 So we just make sure this image is a similar distribution

1307
02:06:25,360 --> 02:06:27,760
 compared with the training images.

1308
02:06:27,760 --> 02:06:29,520
 When we generate a video, right?

1309
02:06:29,520 --> 02:06:34,360
 So besides to make the image looks real,

1310
02:06:34,360 --> 02:06:39,360
 we also make sure the image sequence looks real.

1311
02:06:42,440 --> 02:06:45,240
 And when we have a text input,

1312
02:06:45,240 --> 02:06:46,920
 this is like a condition, right?

1313
02:06:47,760 --> 02:06:49,080
 Text, let's say,

1314
02:06:49,080 --> 02:06:56,080
 this image should be

1315
02:07:10,080 --> 02:07:12,080
 between the text and the video.

1316
02:07:19,080 --> 02:07:24,080
 Okay.

1317
02:07:30,080 --> 02:07:33,480
 Although this just looks quite complicated,

1318
02:07:34,760 --> 02:07:36,760
 but the main concept here is

1319
02:07:42,360 --> 02:07:45,360
 we want this network to generate something

1320
02:07:45,360 --> 02:07:48,360
 where the image look real.

1321
02:07:50,080 --> 02:07:55,080
 And of course this comes with,

1322
02:08:00,400 --> 02:08:02,600
 we should have some training data

1323
02:08:02,600 --> 02:08:05,080
 that can tell stories.

1324
02:08:08,240 --> 02:08:13,240
 So the images is,

1325
02:08:19,080 --> 02:08:24,080
 this one frame two to three,

1326
02:08:30,400 --> 02:08:33,880
 it should follow the similar appearance

1327
02:08:33,880 --> 02:08:36,680
 in existing video data,

1328
02:08:36,680 --> 02:08:40,600
 or the data you are used to change the video generation.

1329
02:08:43,280 --> 02:08:45,760
 So besides the image itself, right?

1330
02:08:50,040 --> 02:08:55,040
 So this case maybe

1331
02:08:57,760 --> 02:08:59,760
 is more easier to understand.

1332
02:09:01,400 --> 02:09:03,200
 So for video, right?

1333
02:09:03,200 --> 02:09:05,800
 So we know the video actually can be

1334
02:09:05,800 --> 02:09:10,800
 an image plus a motion, right?

1335
02:09:11,360 --> 02:09:14,080
 So if a video, am I working here?

1336
02:09:15,080 --> 02:09:16,280
 Then you can say this is

1337
02:09:17,040 --> 02:09:22,040
 an image of me, and from one frame to another frame,

1338
02:09:23,880 --> 02:09:24,920
 I'm working, right?

1339
02:09:24,920 --> 02:09:26,480
 There's a motion.

1340
02:09:26,480 --> 02:09:28,480
 So we may have asked,

1341
02:09:35,840 --> 02:09:40,840
 so if we can generate the image in a real disk way,

1342
02:09:41,080 --> 02:09:45,360
 and also make sure the motion is realistic.

1343
02:09:45,440 --> 02:09:48,960
 So if I'm working at speed,

1344
02:09:48,960 --> 02:09:53,960
 like example, five kilo per hour, for example, right?

1345
02:09:57,480 --> 02:10:01,920
 And this is my training data.

1346
02:10:01,920 --> 02:10:04,380
 I will generate a video.

1347
02:10:04,380 --> 02:10:07,080
 I shouldn't be running very, very fast,

1348
02:10:07,080 --> 02:10:09,880
 like a car is driving, right?

1349
02:10:09,880 --> 02:10:12,599
 Because in another video, I can go in that speed.

1350
02:10:16,000 --> 02:10:21,000
 So I'm not sure how many of you are taking the course

1351
02:10:24,599 --> 02:10:26,719
 of the video signal processing.

1352
02:10:26,719 --> 02:10:28,240
 You know, video compression, right?

1353
02:10:28,240 --> 02:10:33,240
 So we basically compress the image into

1354
02:10:35,080 --> 02:10:40,080
 i-frame, b-frame, p-frame, and p-frame.

1355
02:10:41,040 --> 02:10:43,599
 The i-frame is the independent recording frame,

1356
02:10:43,600 --> 02:10:47,320
 and the rest may be based on the prediction

1357
02:10:47,320 --> 02:10:50,780
 from the previous frames.

1358
02:10:51,720 --> 02:10:56,040
 So you can say that one frame is the image frame.

1359
02:10:56,040 --> 02:10:58,440
 The rest of the motion frame.

1360
02:11:06,640 --> 02:11:10,080
 So we'll be generating the motions, motion vectors.

1361
02:11:10,080 --> 02:11:13,000
 So if the motion vectors are realistic,

1362
02:11:13,000 --> 02:11:14,680
 then my video will be real.

1363
02:11:31,760 --> 02:11:34,200
 So this solar, right?

1364
02:11:34,200 --> 02:11:39,200
 So it's, we can try in our website.

1365
02:11:39,200 --> 02:11:44,200
 And it is based on, I'm not sure

1366
02:11:51,120 --> 02:11:53,840
 whether you have learned about the future mode

1367
02:11:53,840 --> 02:11:54,960
 I mentioned just now, right?

1368
02:11:54,960 --> 02:11:58,400
 And the transformer is a new architecture

1369
02:11:58,400 --> 02:12:02,080
 that previously may learn about convolutional network, right?

1370
02:12:02,080 --> 02:12:04,120
 Transformer is based on attention,

1371
02:12:10,200 --> 02:12:12,559
 convolutional network.

1372
02:12:12,559 --> 02:12:15,880
 And this solar is purely based on transformer

1373
02:12:15,880 --> 02:12:17,599
 and diffusion models.

1374
02:12:17,599 --> 02:12:21,720
 And it's going to be a generous, realistic videos.

1375
02:12:26,000 --> 02:12:26,840
 How is this?

1376
02:12:26,840 --> 02:12:31,840
 So in summary, today we,

1377
02:12:43,000 --> 02:12:45,240
 we choose the guns,

1378
02:12:46,080 --> 02:12:47,720
 generation networks.

1379
02:12:47,720 --> 02:12:52,360
 And it includes the generator and also discriminator.

1380
02:12:52,360 --> 02:12:56,200
 Of course, the very one has best one generator

1381
02:12:56,200 --> 02:12:58,200
 and one discriminator.

1382
02:12:58,200 --> 02:13:02,000
 But nowadays there are a lot of approaches

1383
02:13:02,000 --> 02:13:04,240
 where they may have multiple generator

1384
02:13:04,240 --> 02:13:08,000
 and multiple discriminator.

1385
02:13:08,000 --> 02:13:12,760
 So if you see, if you go do some research in the area,

1386
02:13:12,760 --> 02:13:14,559
 you will be able to see that.

1387
02:13:16,800 --> 02:13:18,360
 The generators try to generate

1388
02:13:26,340 --> 02:13:28,940
 as input random noise is gonna go there.

1389
02:13:31,000 --> 02:13:32,240
 And discriminator is t dismiss,

1390
02:13:35,559 --> 02:13:39,679
 ser-

1391
02:13:39,679 --> 02:13:41,200
 blockchain.

1392
02:13:43,320 --> 02:13:45,000
 And per function.

1393
02:13:45,000 --> 02:13:48,420
 That is function of the speculative type,

1394
02:13:50,900 --> 02:13:53,000
 not set up to receive.

1395
02:13:53,000 --> 02:13:54,720
 So it's being identified.

1396
02:13:54,720 --> 02:13:59,720
 The other, right.

1397
02:13:59,720 --> 02:14:04,720
 It's like, left hand fight with your right hand.

1398
02:14:08,880 --> 02:14:11,320
 And eventually both hands can fight very well.

1399
02:14:12,880 --> 02:14:13,720
 And,

1400
02:14:16,960 --> 02:14:17,800
 by,

1401
02:14:17,800 --> 02:14:22,800
 and the model will become better.

1402
02:14:26,200 --> 02:14:31,200
 At the end of the network when the network is converged,

1403
02:14:41,600 --> 02:14:44,200
 both components are good as they are.

1404
02:14:47,800 --> 02:14:48,640
 Right?

1405
02:15:00,120 --> 02:15:00,960
 Right?

1406
02:15:02,640 --> 02:15:07,640
 And because the generator is doing very good,

1407
02:15:08,880 --> 02:15:13,880
 you can generate data that's for the simulator.

1408
02:15:14,560 --> 02:15:16,200
 Disminator.

1409
02:15:16,200 --> 02:15:20,280
 And when the output of the samples from the generator

1410
02:15:20,280 --> 02:15:23,160
 and the samples from the real world distribution

1411
02:15:24,040 --> 02:15:25,800
 are given to the simulator,

1412
02:15:27,000 --> 02:15:28,360
 what does the simulator do?

1413
02:15:29,600 --> 02:15:32,120
 It will not be able to tear, right?

1414
02:15:32,120 --> 02:15:35,960
 Because you can fool me.

1415
02:15:35,960 --> 02:15:38,960
 That's why just now I say the simulator will get it.

1416
02:15:43,880 --> 02:15:44,720
 Right?

1417
02:15:52,760 --> 02:15:57,760
 But because the generator is very, very well,

1418
02:15:58,480 --> 02:16:02,840
 so you will get 0.5.

1419
02:16:02,840 --> 02:16:07,840
 But of course, if you go try, train your own approach,

1420
02:16:08,560 --> 02:16:12,560
 you want to get, ideally, ideally get 0.5,

1421
02:16:12,560 --> 02:16:14,520
 but you won't get that.

1422
02:16:15,560 --> 02:16:19,200
 An example is just now you see the fact data

1423
02:16:19,200 --> 02:16:20,840
 and the details are missing, right?

1424
02:16:29,320 --> 02:16:32,920
 Okay, so in the second part,

1425
02:16:32,920 --> 02:16:35,000
 we do have one assignment.

1426
02:16:35,000 --> 02:16:36,920
 And this assignment will be,

1427
02:16:42,559 --> 02:16:43,400
 what's called?

1428
02:16:44,480 --> 02:16:47,639
 Yeah, this is the first one I should have, right?

1429
02:16:47,639 --> 02:16:48,959
 Have keys, right?

1430
02:16:49,920 --> 02:16:51,160
 And then you have a,

1431
02:16:51,160 --> 02:16:52,000
 and then you have a,

1432
02:16:52,120 --> 02:16:54,320
 yeah, final score?

1433
02:16:54,320 --> 02:17:11,520
 Here.

1434
02:17:11,520 --> 02:17:20,080
 Finish.

1435
02:17:20,080 --> 02:17:25,080
 Suppose you receive a task, and the task,

1436
02:17:34,959 --> 02:17:37,400
 let's say you're a company, right?

1437
02:17:45,039 --> 02:17:48,360
 Fake images of Donald Trump, right?

1438
02:17:49,360 --> 02:17:54,360
 And this is just the task to give it to you.

1439
02:17:56,720 --> 02:18:00,080
 I hope you can describe how you are doing.

1440
02:18:08,200 --> 02:18:10,840
 Put this into the system,

1441
02:18:11,280 --> 02:18:16,280
 and in the day or tomorrow, maybe,

1442
02:18:16,360 --> 02:18:20,120
 and you will be able to upload your solution to this.

1443
02:18:21,680 --> 02:18:23,120
 Yeah, so I will let you,

1444
02:18:24,600 --> 02:18:29,280
 I will just look at your final one as your solution.

1445
02:18:30,799 --> 02:18:35,799
 So I will keep the system open until November.

1446
02:18:36,719 --> 02:18:39,240
 So I want you to describe

1447
02:18:45,599 --> 02:18:48,439
 how you should use to change it, right?

1448
02:18:49,799 --> 02:18:53,599
 So second is what is the network architecture you are using?

1449
02:18:55,879 --> 02:18:59,160
 And besides the data and the network,

1450
02:19:00,279 --> 02:19:02,639
 so what other resource you want?

1451
02:19:05,799 --> 02:19:10,799
 So you have some, think carefully of this task

1452
02:19:20,799 --> 02:19:25,799
 and give me your explanation and how you think,

1453
02:19:26,000 --> 02:19:28,439
 your thoughts in this task.

1454
02:19:29,840 --> 02:19:34,679
 Yeah, I can remind you it's not as simple as you may think.

1455
02:19:35,680 --> 02:19:37,440
 So, but,

1456
02:19:40,280 --> 02:19:42,280
 and I think in the last two years

1457
02:19:42,280 --> 02:19:44,680
 when I teach video signals,

1458
02:19:52,800 --> 02:19:56,000
 I want to go for PhD because my,

1459
02:19:56,000 --> 02:20:00,600
 let's say this A or B has a lot of map.

1460
02:20:05,520 --> 02:20:10,520
 They don't really look at your scores.

1461
02:20:15,520 --> 02:20:18,400
 Of course, your all is all C compared with another

1462
02:20:18,400 --> 02:20:20,400
 with all A is matters.

1463
02:20:29,400 --> 02:20:33,400
 B plus or B minus one structure itself is one.

1464
02:20:35,680 --> 02:20:36,680
 Some students,

1465
02:20:42,680 --> 02:20:45,680
 you'll look at your record as groups and never look at it.

1466
02:20:47,680 --> 02:20:48,680
 For,

1467
02:20:53,680 --> 02:20:54,680
 part of paper before,

1468
02:20:56,680 --> 02:20:59,680
 I see you here from your seniors,

1469
02:20:59,680 --> 02:21:02,680
 how competitive we are in the future.

1470
02:21:02,680 --> 02:21:04,680
 I'm curious how competitive we are now

1471
02:21:04,680 --> 02:21:06,680
 if we want to get that scholarship to do PhD

1472
02:21:06,680 --> 02:21:09,680
 in previous computer science,

1473
02:21:09,680 --> 02:21:11,680
 and I'll call it CCDS, right?

1474
02:21:19,680 --> 02:21:20,680
 The why?

1475
02:21:27,680 --> 02:21:28,680
 A subject,

1476
02:21:29,680 --> 02:21:31,680
 but doing PhD is,

1477
02:21:32,680 --> 02:21:35,680
 it's not for you to learn something, right?

1478
02:21:35,680 --> 02:21:38,680
 So, at time you think you want to learn something,

1479
02:21:38,680 --> 02:21:42,680
 you are already, PhD is for you to invent something,

1480
02:21:43,680 --> 02:21:44,680
 to discover something.

1481
02:21:52,680 --> 02:21:53,680
 Much helpful.

1482
02:21:56,680 --> 02:22:01,680
 So, this is also why I hope you to explain your design

1483
02:22:01,680 --> 02:22:02,680
 and your course.

1484
02:22:04,680 --> 02:22:05,680
 You just spend time on it.

1485
02:22:14,680 --> 02:22:15,680
 And also,

1486
02:22:23,680 --> 02:22:25,680
 based on my experience, right?

1487
02:22:25,680 --> 02:22:29,680
 So, the criteria for your information is,

1488
02:22:30,680 --> 02:22:31,680
 we actually,

1489
02:22:43,680 --> 02:22:44,680
 only 100 score, right?

1490
02:22:44,680 --> 02:22:46,680
 There's no way, so they will adjust.

1491
02:22:50,680 --> 02:22:52,680
 You try to think of this,

1492
02:22:59,680 --> 02:23:00,680
 by no effort.

1493
02:23:07,680 --> 02:23:09,680
 Okay, I think that's,

1494
02:23:10,680 --> 02:23:12,680
 most of, that's almost everything today.

1495
02:23:13,680 --> 02:23:18,680
 And, I also like to share

1496
02:23:22,680 --> 02:23:24,680
 my opinion on the,

1497
02:23:26,680 --> 02:23:28,680
 what you should learn from this course.

1498
02:23:29,680 --> 02:23:30,680
 Or,

1499
02:23:36,680 --> 02:23:38,680
 what are the opinions when I'm,

1500
02:23:40,680 --> 02:23:43,680
 from bachelor to come here to for PhD study?

1501
02:23:44,680 --> 02:23:48,680
 I actually know very little about the potential research topics.

1502
02:23:49,680 --> 02:23:53,680
 And therefore, I just choose one topic I hear about.

1503
02:23:54,680 --> 02:23:55,680
 But from this course,

1504
02:23:55,680 --> 02:23:59,680
 I hope you know more about the research topic

1505
02:23:59,680 --> 02:24:00,680
 that's currently hot,

1506
02:24:01,680 --> 02:24:03,680
 or you may be able to work on it.

1507
02:24:05,680 --> 02:24:07,680
 So, I'm not going to examine your,

1508
02:24:12,680 --> 02:24:13,680
 so,

1509
02:24:26,680 --> 02:24:33,680
 but I will test you on how you understand the things,

1510
02:24:33,680 --> 02:24:35,680
 understand the concept.

1511
02:24:36,680 --> 02:24:38,680
 So, I can do that.

1512
02:24:52,680 --> 02:24:53,680
 Technology.

1513
02:24:55,680 --> 02:24:56,680
 Technology.

1514
02:25:14,680 --> 02:25:15,680
 Or existing.

1515
02:25:16,680 --> 02:25:17,680
 If we,

1516
02:25:17,680 --> 02:25:19,680
 to say whether it's novel or not,

1517
02:25:19,680 --> 02:25:21,680
 we may say it's not really novel.

1518
02:25:22,680 --> 02:25:24,680
 But what it dissolves is,

1519
02:25:25,680 --> 02:25:26,680
 how to do,

1520
02:25:27,680 --> 02:25:28,680
 how to,

1521
02:25:33,680 --> 02:25:37,680
 the network can generate the data

1522
02:25:38,680 --> 02:25:39,680
 as long as you wish.

1523
02:25:41,680 --> 02:25:43,680
 So, it is one of the potential ways

1524
02:25:44,680 --> 02:25:47,680
 to solve the data.

1525
02:25:48,680 --> 02:25:51,680
 So, you may hear about the AI have three main components.

1526
02:25:52,680 --> 02:25:53,680
 Why is the data?

1527
02:25:56,680 --> 02:25:57,680
 Right.

1528
02:25:58,680 --> 02:26:03,680
 So, data is one with the generate the AI.

1529
02:26:11,680 --> 02:26:12,680
 Or mix them or

1530
02:26:20,680 --> 02:26:22,680
 say in this lecture, I shared again.

1531
02:26:23,680 --> 02:26:25,680
 So, and from the general,

1532
02:26:35,680 --> 02:26:36,680
 difference.

1533
02:26:37,680 --> 02:26:38,680
 Conceal is a little different.

1534
02:26:38,680 --> 02:26:40,680
 It's just different dimensionality of the data.

1535
02:26:41,680 --> 02:26:42,680
 Images are here, right?

1536
02:26:42,680 --> 02:26:43,680
 We also have a 3D.

1537
02:26:44,680 --> 02:26:45,680
 Pretty much.

1538
02:26:53,680 --> 02:26:57,680
 And the image plus become video is,

1539
02:26:57,680 --> 02:27:02,680
 is, is other go is another kind of it is just to

1540
02:27:07,680 --> 02:27:08,680
 the time.

1541
02:27:09,680 --> 02:27:10,680
 Of course, you may have 4D, right?

1542
02:27:10,680 --> 02:27:15,680
 So, I have MRI data plus time.

1543
02:27:22,680 --> 02:27:36,680
 So, that's, that's the single way you

1544
02:27:37,680 --> 02:27:40,680
 data of the fact of the video, right?

1545
02:27:41,680 --> 02:27:46,680
 So, you look at the talk, I believe there are some

1546
02:27:46,680 --> 02:27:48,680
 things that are not,

1547
02:27:48,680 --> 02:27:50,680
 but the fact of the video,

1548
02:27:55,680 --> 02:27:58,680
 the fact of the video that looks really quite high quality.

1549
02:28:06,680 --> 02:28:09,680
 This assignment and the, the score,

1550
02:28:09,680 --> 02:28:12,680
 the assignment, it won't be, don't worry about that.

1551
02:28:12,680 --> 02:28:18,680
 So, if you're fair, either you didn't submit the assignment.

1552
02:28:26,680 --> 02:28:28,680
 You also didn't attend the quiz.

1553
02:28:30,680 --> 02:28:32,680
 It's two parts, right?

1554
02:28:33,680 --> 02:28:38,680
 So, I think it's about 40% of the issue.

1555
02:28:43,680 --> 02:28:47,680
 And until I see you, as long as you got 50,

1556
02:28:47,680 --> 02:28:51,680
 I'll score, I'll score your pass already.

1557
02:28:53,680 --> 02:28:57,680
 The, the, the, the, the result is already become zero.

1558
02:29:02,680 --> 02:29:04,680
 Score 70, right?

1559
02:29:05,680 --> 02:29:09,680
 Point six times 70, you still can pass, right?

1560
02:29:10,680 --> 02:29:11,680
 42.

1561
02:29:11,680 --> 02:29:16,680
 So it's actually quite easy to pass, get something.

1562
02:29:27,260 --> 02:29:28,760
 And if you go for a job,

1563
02:29:35,260 --> 02:29:36,280
 the top,

1564
02:29:37,280 --> 02:29:39,280
 I don't need a company,

1565
02:29:40,280 --> 02:29:42,160
 I don't look at the transfer rate.

1566
02:29:42,160 --> 02:29:43,680
 I just talk to each of you,

1567
02:29:43,680 --> 02:29:45,720
 ask what you have done,

1568
02:29:45,720 --> 02:29:46,880
 whether you can...

1569
02:29:56,360 --> 02:29:57,760
 Some students can answer.

1570
02:30:05,800 --> 02:30:08,320
 I think you don't know the details.

1571
02:30:08,320 --> 02:30:09,160
 So...

1572
02:30:19,160 --> 02:30:21,520
 I can tell.

1573
02:30:21,520 --> 02:30:25,720
 Yeah, and the score for this wanna be very...

1574
02:30:25,720 --> 02:30:28,199
 I think as long as it submits your solution,

1575
02:30:28,199 --> 02:30:29,920
 you shouldn't be a...

1576
02:30:29,920 --> 02:30:33,600
 You should get at least a pass within this part.

1577
02:30:33,600 --> 02:30:35,240
 Yeah, but on average,

1578
02:30:35,240 --> 02:30:37,640
 these are...

