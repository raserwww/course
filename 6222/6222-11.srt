1
00:00:00,000 --> 00:00:02,000
 you

2
00:00:30,000 --> 00:00:32,000
 you

3
00:01:00,000 --> 00:01:02,000
 you

4
00:01:30,000 --> 00:01:32,000
 you

5
00:02:00,000 --> 00:02:02,000
 you

6
00:02:30,000 --> 00:02:36,000
 you

7
00:02:37,120 --> 00:02:39,120
 You

8
00:02:39,120 --> 00:02:46,120
 All available except for one view.

9
00:02:46,120 --> 00:02:56,760
 there's rear seats.

10
00:02:57,000 --> 00:03:00,500
 .

11
00:03:02,020 --> 00:03:08,080
 Okay, good evening. There's a set of the

12
00:03:08,080 --> 00:03:14,080
 machine review for video.

13
00:03:16,120 --> 00:03:21,800
 So, for machine vision for video, right, so there covers quite a lot of topics and here

14
00:03:21,800 --> 00:03:24,400
 I just list a few.

15
00:03:24,400 --> 00:03:34,200
 And actually in, I think actually in in-dutch application, right, so much of the case in

16
00:03:34,200 --> 00:03:39,640
 recognition related tasks are essentially dealing with videos.

17
00:03:39,640 --> 00:03:48,399
 So later I will explain why the in-dutch application is talking about the video instead of pure

18
00:03:48,399 --> 00:03:49,880
 image.

19
00:03:49,880 --> 00:04:00,839
 So, the first and probably one of the very popular application is object detection and

20
00:04:00,839 --> 00:04:01,839
 tracking.

21
00:04:01,840 --> 00:04:08,840
 So, and this is going to be one of the important.

22
00:04:08,840 --> 00:04:11,080
 Hello?

23
00:04:11,080 --> 00:04:19,320
 The second is action recognition, right, so for example you want to shake hand with someone

24
00:04:19,320 --> 00:04:23,680
 and you want to wave, right, so it's action recognition, right.

25
00:04:23,680 --> 00:04:29,320
 But action recognition is actually quite different from object detection and tracking.

26
00:04:29,320 --> 00:04:33,360
 And later we will also have some example.

27
00:04:33,360 --> 00:04:37,320
 And the third is probably the video event.

28
00:04:37,320 --> 00:04:46,080
 So I see many of us may watch football or watch basketball, right, and when players shoot

29
00:04:46,080 --> 00:04:52,280
 the balls, so you want to catch that moment for the shooting event, right, or scoring

30
00:04:52,280 --> 00:04:54,200
 event.

31
00:04:54,200 --> 00:05:02,240
 And I've seen long time ago when I came here and I also hear some topics like in swimming

32
00:05:02,240 --> 00:05:03,240
 pools.

33
00:05:03,240 --> 00:05:11,640
 We monitor the swimming pool to detect the possible people who maybe had risk of drawing.

34
00:05:11,640 --> 00:05:19,080
 And also for anomaly detection, let's have one example for anomaly detection based on

35
00:05:19,080 --> 00:05:21,080
 video.

36
00:05:21,080 --> 00:05:29,159
 And of course for besides recognition and understanding task, enhancement is also important

37
00:05:29,159 --> 00:05:31,840
 application.

38
00:05:31,840 --> 00:05:38,680
 And the last one is the optical flow because it's a processing technology but it's very

39
00:05:38,680 --> 00:05:46,240
 related with video, especially in machine side where the computation course is quite

40
00:05:46,240 --> 00:05:47,240
 limited.

41
00:05:47,600 --> 00:05:53,120
 So I believe there are, there may also have other courses like deep learning or computer

42
00:05:53,120 --> 00:05:54,120
 vision.

43
00:05:54,120 --> 00:06:03,680
 But in machine vision, one of the special requirement is that I need the AI to be down in the edge

44
00:06:03,680 --> 00:06:06,440
 side or at the machine side.

45
00:06:06,440 --> 00:06:13,000
 You know where we have a machine, right, so like robotics or mobile phones.

46
00:06:13,000 --> 00:06:17,360
 Our computer resources is very limited.

47
00:06:17,360 --> 00:06:22,360
 Of course in many applications, the machine can also be connected to the cloud.

48
00:06:22,360 --> 00:06:28,640
 But not every application will allow you to have access to the cloud.

49
00:06:28,640 --> 00:06:34,840
 And also even if you have the cloud access, right, you may still have some processing at

50
00:06:34,840 --> 00:06:36,680
 the machine side.

51
00:06:36,680 --> 00:06:40,720
 So let's see one of the examples.

52
00:06:41,440 --> 00:06:48,360
 So, I see the first one is the video.

53
00:06:48,360 --> 00:06:58,160
 So this top left is a case where we may have some, put some camera in a shopping mall and

54
00:06:58,160 --> 00:07:04,440
 try to monitor the entrance of the mall to see how many people is coming to the mall

55
00:07:04,440 --> 00:07:06,440
 today, right?

56
00:07:06,440 --> 00:07:18,360
 And so how can we achieve the function of counting the people?

57
00:07:18,360 --> 00:07:25,080
 So you can see the people walking into the mall.

58
00:07:25,080 --> 00:07:34,760
 For example, we can set up a virtual door along this line, for example, right?

59
00:07:34,760 --> 00:07:46,080
 We can set up a virtual door from this line, right?

60
00:07:46,080 --> 00:07:51,039
 So we may need to count how many people cross the line, right?

61
00:07:51,039 --> 00:07:59,640
 Because obviously we cannot count based on images because every minute is right.

62
00:07:59,640 --> 00:08:07,000
 So normally we have every second, actually we have many, many frames.

63
00:08:07,000 --> 00:08:16,719
 And if you count the person per image, right, so you have an issue or you may count the

64
00:08:16,719 --> 00:08:20,840
 people multiple times during one second, right?

65
00:08:20,840 --> 00:08:31,280
 So let's say a video normally, hello?

66
00:08:31,280 --> 00:08:35,400
 Let's say a video normally have 15 frames or even more per second.

67
00:08:35,400 --> 00:08:42,120
 So that means you have to deal with 15 images per image per second.

68
00:08:42,120 --> 00:08:49,680
 And from these images, right, you need to count how many people are crossing the lines.

69
00:08:49,680 --> 00:09:03,319
 So the second application is surveillance in the power or utility industry or many other

70
00:09:03,319 --> 00:09:05,319
 places.

71
00:09:05,319 --> 00:09:12,040
 And whereas workers are less, whereas hammers have some suits to be wear, right?

72
00:09:12,040 --> 00:09:26,680
 And you may see, right, we have some...

73
00:09:26,680 --> 00:09:32,800
 Hello?

74
00:09:32,800 --> 00:09:35,560
 We may have some bounding box, right?

75
00:09:35,560 --> 00:09:42,239
 So we will detect each person and we will detect whether the person wears a hammer or

76
00:09:42,239 --> 00:09:44,760
 wears a uniform.

77
00:09:44,760 --> 00:09:51,319
 So this application, so it's the same, it's...

78
00:09:51,319 --> 00:09:53,680
 It's the image.

79
00:09:53,680 --> 00:10:05,520
 Because you will have one camera put for example at some corner of this scene, right?

80
00:10:05,520 --> 00:10:08,880
 And this camera look at the person.

81
00:10:08,880 --> 00:10:12,560
 And every second you have many, many frames, right?

82
00:10:12,560 --> 00:10:20,480
 So and once you detect a person without hammers, you know there's a...

83
00:10:20,480 --> 00:10:22,480
 There is a...

84
00:10:22,480 --> 00:10:26,720
 Where the inspection should be reported.

85
00:10:26,720 --> 00:10:32,480
 So there's one person without hammers.

86
00:10:32,480 --> 00:10:34,199
 But there's a reality, right?

87
00:10:34,200 --> 00:10:40,360
 So you give the report, you give the alarm to some central system.

88
00:10:40,360 --> 00:10:43,080
 But this person is still there.

89
00:10:43,080 --> 00:10:45,920
 He's still no hammer, right?

90
00:10:45,920 --> 00:10:51,000
 So in the next second, you still get the same detection.

91
00:10:51,000 --> 00:11:02,080
 So that means your system will be keep reporting.

92
00:11:02,080 --> 00:11:07,800
 So this definitely there are some issues in terms of implementation.

93
00:11:07,800 --> 00:11:14,360
 We will show how this will be solved based on video analysis.

94
00:11:14,360 --> 00:11:20,920
 And this is the case where we may use video lens to monitor whether the elderly people

95
00:11:20,920 --> 00:11:25,920
 fell down in the toilet or example.

96
00:11:25,920 --> 00:11:32,640
 And this is quite different from here.

97
00:11:32,640 --> 00:11:43,079
 Because how to describe a video where the people is fell down, which is not that clear

98
00:11:43,079 --> 00:11:45,479
 from computer.

99
00:11:45,479 --> 00:11:48,000
 It's very easy for us to see it.

100
00:11:48,000 --> 00:11:51,199
 But for computer it's not easy.

101
00:11:51,200 --> 00:12:08,160
 And this is a case for...

102
00:12:08,160 --> 00:12:20,560
 Now I let you watch this video.

103
00:12:20,560 --> 00:12:27,560
 You watch this video.

104
00:12:27,560 --> 00:12:30,239
 Okay, we can stop here.

105
00:12:30,239 --> 00:12:40,959
 So we can see that for each person, right, we have a bounding box that represents detection

106
00:12:40,959 --> 00:12:43,280
 of the person, right?

107
00:12:43,280 --> 00:12:51,280
 And we also see for each different person, the bounding box has been assigned with different

108
00:12:51,280 --> 00:12:54,040
 colors, right?

109
00:12:54,040 --> 00:12:55,880
 But from the normal video, right?

110
00:12:55,880 --> 00:12:57,720
 So this box is not there.

111
00:12:57,720 --> 00:12:58,880
 So what do we...

112
00:12:58,880 --> 00:13:00,079
 That means...

113
00:13:00,079 --> 00:13:08,520
 It means we are detecting the person and also differentiates different person, right?

114
00:13:08,520 --> 00:13:10,640
 And then you look at the video, right?

115
00:13:10,640 --> 00:13:26,960
 The bounding box for each person has a unique color.

116
00:13:26,960 --> 00:13:34,400
 Right?

117
00:13:34,400 --> 00:13:44,680
 So from the video, you can tell so that human detection seems quite accurate, right?

118
00:13:44,680 --> 00:13:52,240
 And then you look at this video carefully.

119
00:13:52,240 --> 00:13:58,160
 I'm not sure whether you can observe something quite strange.

120
00:13:58,160 --> 00:14:01,760
 For example, now you look at the...

121
00:14:01,760 --> 00:14:08,800
 Besides the human detection, right, we also detect the face, right?

122
00:14:08,800 --> 00:14:12,719
 And this represents the camera.

123
00:14:12,719 --> 00:14:16,520
 And this represents the age and the gender of the person.

124
00:14:16,520 --> 00:14:17,520
 You look at here, right?

125
00:14:17,520 --> 00:14:31,199
 This way is something 18 or 16?

126
00:14:31,199 --> 00:14:32,199
 And you look at here, right?

127
00:14:32,199 --> 00:14:37,199
 This is 23, right?

128
00:14:37,200 --> 00:15:02,400
 Now you're 17, right?

129
00:15:02,400 --> 00:15:05,160
 So you observe something very strange, right?

130
00:15:05,160 --> 00:15:08,680
 So for each person, it's one person, right?

131
00:15:08,680 --> 00:15:16,280
 The fixed person, the age as mentioned is changing from one frame to another frame, right?

132
00:15:16,280 --> 00:15:25,000
 Of course, for gender, it's related more accurately, so it stays as a male.

133
00:15:25,000 --> 00:15:29,520
 And imagine you are developing a system to do this thing, right?

134
00:15:29,520 --> 00:15:40,600
 So from the user point of view, right, what you will be expecting, maybe it's very difficult

135
00:15:40,600 --> 00:15:44,760
 for me to tell what's the age of this person.

136
00:15:44,760 --> 00:15:48,400
 But what I can know is this person should be the same age, right?

137
00:15:48,400 --> 00:15:49,400
 It should be changing.

138
00:15:50,400 --> 00:16:05,800
 And you may also see the facial expression.

139
00:16:05,800 --> 00:16:09,640
 Sometimes she's happy, sometimes she's neutral, right?

140
00:16:09,640 --> 00:16:17,240
 So let's see if there's some change of the facial.

141
00:16:17,240 --> 00:16:25,920
 You can see the happy sometimes discussed, right?

142
00:16:25,920 --> 00:16:33,760
 So if we are working naturally, so normally my facial should change much, right?

143
00:16:33,760 --> 00:16:38,760
 Unless I'm popular to do it or I'm doing something else, I'll suddenly become happy, right?

144
00:16:38,760 --> 00:16:43,800
 It's very seldom we will be jumping from, I'm happy and very angry.

145
00:16:44,359 --> 00:16:49,359
 Of course, you may feel something, you can fall from that roof.

146
00:16:49,359 --> 00:16:51,959
 Then you get angry, it's possible.

147
00:16:51,959 --> 00:16:58,400
 But it should be jumping from one state to another state, right?

148
00:16:58,400 --> 00:17:06,879
 So this tells us, for video, besides we are looking at the accuracy per image,

149
00:17:06,960 --> 00:17:13,600
 we will also look at the accuracy in the time space, right?

150
00:17:16,240 --> 00:17:26,560
 So for the human detection, and we try to recognize this as the same person

151
00:17:26,560 --> 00:17:29,360
 and assign a same color, right?

152
00:17:29,360 --> 00:17:35,120
 So this is actually detailed by the first texture we introduced just now.

153
00:17:35,159 --> 00:17:37,560
 Got detection and tracking.

154
00:17:44,159 --> 00:17:49,840
 So now let's see how detection and tracking is achieved.

155
00:17:51,439 --> 00:17:57,320
 So here we just shoot a short video, actually it's a G file.

156
00:17:57,320 --> 00:18:02,560
 And one of my child is walking along the street, right?

157
00:18:02,800 --> 00:18:04,280
 This is what we see, right?

158
00:18:10,960 --> 00:18:15,720
 But although we can see a video from human,

159
00:18:15,720 --> 00:18:20,480
 but we will send this video to computer, right?

160
00:18:20,480 --> 00:18:27,480
 So from the computer, it just reads one frame by one frame, right?

161
00:18:27,560 --> 00:18:35,520
 So that means what the computer sees is a sequence of images.

162
00:18:35,520 --> 00:18:38,320
 Of course, some strong correlation between images.

163
00:18:38,320 --> 00:18:46,120
 And a lot of times, people ask, we are also seeing these images.

164
00:18:46,120 --> 00:18:53,360
 It's just our human perception makes us feel that we are looking at a video,

165
00:18:53,360 --> 00:18:54,760
 like continuous.

166
00:18:54,760 --> 00:19:01,360
 But actually, you see a sequence of images.

167
00:19:01,360 --> 00:19:08,360
 Now the question is for a computer, if we want the computer to understand this,

168
00:19:08,360 --> 00:19:09,800
 what can we do?

169
00:19:09,800 --> 00:19:11,280
 Or what should we do?

170
00:19:13,240 --> 00:19:17,960
 So this is to support the detection tracking.

171
00:19:17,960 --> 00:19:23,440
 So I assume you have some knowledge on how the object detection is done.

172
00:19:23,480 --> 00:19:26,760
 Yeah, usually I may have some slides later.

173
00:19:28,680 --> 00:19:33,080
 So in order to let the computer to understand this, right?

174
00:19:33,080 --> 00:19:36,360
 So we have to object detection.

175
00:19:36,360 --> 00:19:43,040
 Of course, in this case here, we are defined as a human object.

176
00:19:43,040 --> 00:19:47,880
 So in the first frame, right, so we can detect two persons, right?

177
00:19:48,880 --> 00:19:54,960
 And then we apply the same thing to the next slides and the next frame,

178
00:19:54,960 --> 00:19:56,240
 third frame, and fourth frame.

179
00:20:00,120 --> 00:20:08,920
 And we will get two persons from each frame.

180
00:20:08,920 --> 00:20:13,080
 Assuming we can detect the human correctly, right?

181
00:20:13,080 --> 00:20:17,879
 So after this one, right, so in our detector,

182
00:20:17,879 --> 00:20:20,760
 it's just human and non-human area, right?

183
00:20:27,960 --> 00:20:32,360
 So in order for the computer to understand this,

184
00:20:32,360 --> 00:20:36,679
 there's some association between the consecutive frames.

185
00:20:36,679 --> 00:20:40,560
 We need to tell whether this person and this person is the same person,

186
00:20:40,560 --> 00:20:42,440
 or this person and this person is the same person.

187
00:20:43,600 --> 00:20:50,159
 And by association, the same person with a unique ID, say person one, right?

188
00:20:50,159 --> 00:20:53,600
 So we are actually doing the job called tracking.

189
00:21:02,480 --> 00:21:09,200
 So by detecting and tracking, we will get,

190
00:21:09,200 --> 00:21:13,960
 and after tracking, we will assign a unique ID for the person.

191
00:21:13,960 --> 00:21:18,400
 So we can get the blue line to be the person one,

192
00:21:18,400 --> 00:21:20,680
 the yellow line to be the person two.

193
00:21:21,760 --> 00:21:29,400
 So counter or the development history, right?

194
00:21:29,400 --> 00:21:37,880
 So the first or the earlier technology detection and

195
00:21:37,880 --> 00:21:40,280
 tracking is doing it by two steps.

196
00:21:41,480 --> 00:21:46,520
 Why is, we do detection first, detection all frames.

197
00:21:46,520 --> 00:21:51,360
 The second is compare the detection outcome and

198
00:21:51,360 --> 00:21:53,680
 that's called the tracking.

199
00:21:54,800 --> 00:21:57,760
 So it's detection followed by tracking.

200
00:21:57,760 --> 00:21:59,760
 It's two separate steps.

201
00:21:59,760 --> 00:22:14,240
 So we call the step to associate the detection as one or

202
00:22:14,240 --> 00:22:17,160
 multiple objects as the tracking.

203
00:22:17,160 --> 00:22:33,200
 So, of course, I am not going to detail how the tracking can be done.

204
00:22:33,200 --> 00:22:37,880
 There are many, many approaches and some are very traditional approach.

205
00:22:37,880 --> 00:22:42,840
 And the typical way you just remember is detection.

206
00:22:42,840 --> 00:22:51,639
 But of course, some work may do segmentation, which is not really quite

207
00:22:51,639 --> 00:22:56,080
 different from here, but it's just with segmentation, you will try to get

208
00:22:56,080 --> 00:22:58,879
 the exact boundary instead of bounding box.

209
00:22:58,880 --> 00:23:00,400
 So again, you associate that.

210
00:23:20,800 --> 00:23:23,000
 Now you look at this video again, right?

211
00:23:23,000 --> 00:23:27,000
 So you understand?

212
00:23:27,000 --> 00:23:30,440
 So in order to get assigned the same color, right?

213
00:23:30,440 --> 00:23:36,400
 So we actually have down the track to the same person across the frames.

214
00:23:39,120 --> 00:23:43,640
 And of course, this task, right, is besides detection and detection,

215
00:23:43,640 --> 00:23:50,120
 we also include facial detection and facial landmarks and the age,

216
00:23:50,120 --> 00:23:56,920
 the skin, the expressions and also the skeleton of the human.

217
00:23:57,640 --> 00:23:59,720
 And also includes a distance estimation.

218
00:24:10,320 --> 00:24:14,240
 Or can be considered as part of the detections.

219
00:24:14,240 --> 00:24:22,360
 Because for human detection, if you have learned about the object detection,

220
00:24:22,360 --> 00:24:25,760
 it's top left corner and bottom right.

221
00:24:25,760 --> 00:24:29,439
 And for facial, right, so it's also a point.

222
00:24:42,080 --> 00:24:49,719
 So in terms of object detection, image level and also in video level,

223
00:24:49,720 --> 00:24:57,400
 there's one of the major differences whether you consider as called temporal continuity.

224
00:24:57,400 --> 00:25:03,320
 The approach, I should just now or you can just now, the detection tracking, right?

225
00:25:03,320 --> 00:25:10,200
 So we actually didn't consider the temporal continuity in detection.

226
00:25:10,200 --> 00:25:17,880
 We detect in each image or each frame is independent, right?

227
00:25:20,720 --> 00:25:30,720
 But we know there's a perduous.

228
00:25:34,720 --> 00:25:38,720
 The machine actually can be used to improve the detection.

229
00:25:38,720 --> 00:25:45,720
 But so far in commercial use, my job is to look.

230
00:25:50,720 --> 00:25:52,720
 Mainly because the...

231
00:25:58,720 --> 00:26:00,720
 I can do the job.

232
00:26:00,720 --> 00:26:11,720
 And in order to achieve the continuity, right, we can do a simple process like smoothing.

233
00:26:11,720 --> 00:26:14,720
 This will solve our problems.

234
00:26:14,720 --> 00:26:24,720
 But in terms of doing research, right, there are definitely works that can use the continuity in the detection.

235
00:26:24,720 --> 00:26:30,720
 But here is a demo of the different face detection algorithms.

236
00:26:45,720 --> 00:26:47,720
 Let's first answer the question.

237
00:26:49,720 --> 00:26:58,720
 Face detection is a computer vision task in which we detect the presence of human faces as well as its location within an image or a video stream.

238
00:26:58,720 --> 00:27:05,720
 Face detection is applied in multiple fields from healthcare to security, authentication, entertainment.

239
00:27:05,720 --> 00:27:06,720
 The list goes on.

240
00:27:06,720 --> 00:27:13,720
 Some of the well-known applications are auto focus and digital cameras, crowd analysis and social media filters.

241
00:27:13,720 --> 00:27:19,720
 With such a wide range of applications, it also has a lot of hurdles that it needs to overcome.

242
00:27:24,720 --> 00:27:26,720
 In this video.

243
00:27:29,720 --> 00:27:30,720
 Okay.

244
00:27:30,720 --> 00:27:42,720
 So you can see that this nine different cases is detection output of different algorithms.

245
00:27:42,720 --> 00:27:47,720
 You can see that different algorithms may have different output or different performance.

246
00:27:47,720 --> 00:27:54,720
 These six plus this one, they all can detect face from the red to the large angle.

247
00:27:54,720 --> 00:27:57,720
 These two, they fail to detect, right?

248
00:27:57,720 --> 00:28:05,720
 And this actually appears quite often where we are detecting in a video because...

249
00:28:06,720 --> 00:28:11,720
 You can imagine your video is around the boundary.

250
00:28:11,720 --> 00:28:14,720
 Oh, being detectable or not detectable.

251
00:28:14,720 --> 00:28:19,720
 That means within one second, many, many frames.

252
00:28:19,720 --> 00:28:21,720
 Some frames detect the object.

253
00:28:21,720 --> 00:28:24,720
 Some frames you fail to detect, right?

254
00:28:24,720 --> 00:28:33,720
 If you want to try to experience that, you can find some challenging cases where you do some object testing.

255
00:28:33,720 --> 00:28:35,720
 You may face that.

256
00:28:35,720 --> 00:28:40,720
 And this is the main challenge in detection attractors.

257
00:28:42,720 --> 00:28:44,720
 And we should just now, right?

258
00:28:44,720 --> 00:28:45,720
 We are...

259
00:28:51,720 --> 00:28:56,720
 We are detecting the object in each frames and try to associate.

260
00:28:56,720 --> 00:29:08,720
 But if my detection here is not successful, then you will have challenging association with these things.

261
00:29:08,720 --> 00:29:11,720
 So, of course, our solution is...

262
00:29:12,720 --> 00:29:19,720
 ...to improve the performance of the object detection.

263
00:29:20,720 --> 00:29:27,720
 However, you can never get an object detectable that's here, achieve 100%.

264
00:29:27,720 --> 00:29:33,720
 So, an alternative solution is once we detect object here, right?

265
00:29:33,720 --> 00:29:52,720
 We automatically move the box here and try to move or slide in the window, the box here, to an object that's max or best matches with the object here.

266
00:29:53,720 --> 00:29:56,720
 So, this is a valid way they can do it.

267
00:29:56,720 --> 00:30:00,720
 Of course, this will go deeper into the research.

268
00:30:01,720 --> 00:30:08,720
 So, in detection tracking, objects are very mature and relative very mature.

269
00:30:08,720 --> 00:30:15,720
 Because in drones and robotics, they have a lot of applications.

270
00:30:15,720 --> 00:30:20,720
 There are still some space to improve, especially the tracking.

271
00:30:20,720 --> 00:30:23,720
 And so far, the commercial tracking algorithm, right?

272
00:30:23,720 --> 00:30:29,720
 So, they are still based on the so-called camera filter.

273
00:30:29,720 --> 00:30:31,720
 And...

274
00:30:36,720 --> 00:30:42,720
 So far, the speed is about the issue for machine vision or machine sight.

275
00:30:42,720 --> 00:30:49,720
 So, when I detect and try to check, right, this computation is about the magic concerns.

276
00:30:49,720 --> 00:31:02,720
 But with this course, right, I'm not going to talk too much on this, but you may have faced such tasks where you go for an interview.

277
00:31:02,720 --> 00:31:09,720
 But in academic, this is not really a very important topic now.

278
00:31:09,720 --> 00:31:14,720
 It used to be quite hot in the last 10 years, maybe.

279
00:31:14,720 --> 00:31:21,720
 But now, we are saying the object detection is relatively mature, especially with YOLO series.

280
00:31:21,720 --> 00:31:44,720
 So, I guess this video is from one of the professor websites from NCHU.

281
00:31:44,720 --> 00:31:51,720
 So, this technology we talk about is called re-identification.

282
00:31:51,720 --> 00:32:00,720
 And it's very often be used to... let's say we have a CCTV camera in different places of the country, right?

283
00:32:00,720 --> 00:32:05,720
 And we want to detect the person whether the person wants to read the...

284
00:32:05,720 --> 00:32:09,720
 the school in the university, right?

285
00:32:09,720 --> 00:32:17,720
 And we may have images of the same person from different side, different angle.

286
00:32:17,720 --> 00:32:31,720
 And the purpose of REID is to identify whether this green one is the same person, this red one is the same person or not.

287
00:32:31,720 --> 00:32:37,720
 And how it is done by detection and tracking.

288
00:32:37,720 --> 00:32:41,720
 So, detection is easy, right?

289
00:32:41,720 --> 00:32:51,720
 And after detection, we will...

290
00:32:51,720 --> 00:33:02,720
 For each human detected, we try to represent as a vector and compare them whether this same person or not.

291
00:33:02,720 --> 00:33:19,720
 So, this stuff by the sort of tracking.

292
00:33:19,720 --> 00:33:33,720
 But within... I think not many years ago, they realized that the previous approach for REID has some limitation.

293
00:33:33,720 --> 00:33:48,720
 And they invented this new approach called joint detection and embedding.

294
00:33:48,720 --> 00:33:59,720
 So, the top part, if you are familiar, you will know this is just the feature of tracking, our FPN structure.

295
00:33:59,720 --> 00:34:10,720
 So, with the feature being collected, then we have the prediction head to do different tasks, including classification, regression and embedding.

296
00:34:10,719 --> 00:34:18,719
 So, the classification is to tell whether this is a specific object you are interested.

297
00:34:18,719 --> 00:34:26,719
 The regression is actually for the detection of the coordinate of the object.

298
00:34:26,719 --> 00:34:29,719
 What's new here?

299
00:34:29,719 --> 00:34:36,719
 Or what's really new from the previous is this embedding.

300
00:34:36,719 --> 00:34:57,720
 So, the main difference between joint detection and embedding in short GDE with previous REID or detection tracking is here we do the embedding.

301
00:34:57,720 --> 00:35:08,720
 We have an actual reputation called embedding, which is used to identify whether this is a same person or not.

302
00:35:08,720 --> 00:35:17,720
 While the previous approach is equivalent to object detection first, then calculate the embedding.

303
00:35:17,720 --> 00:35:25,720
 Of course, they use... In the academic, they use a new name called embedding.

304
00:35:26,720 --> 00:35:31,720
 But you can just consider this, understand this as a feature of tracking.

305
00:35:31,720 --> 00:35:36,720
 So, just remember this concept, right?

306
00:35:36,720 --> 00:35:44,720
 So, the previous approach of REID is by detection and then tracking.

307
00:35:44,720 --> 00:35:51,720
 Or detection, then represent that object, or person or whatever.

308
00:35:51,720 --> 00:36:01,720
 Now, we detect and at the same time, we want to describe the person.

309
00:36:01,720 --> 00:36:03,720
 So, this is a major difference.

310
00:36:03,720 --> 00:36:10,720
 Of course, there are many, many ways to implement this. This is just the illustration of the concept.

311
00:36:10,720 --> 00:36:16,720
 But you remember this because one day you want to go for a job, right?

312
00:36:16,720 --> 00:36:21,720
 So, they may ask you what's the difference between GDE and REID?

313
00:36:21,720 --> 00:36:24,720
 I hope you can answer that.

314
00:36:24,720 --> 00:36:32,720
 Of course, in terms of how many, how to design a GDE, how to achieve joint detection,

315
00:36:32,720 --> 00:36:37,720
 how to train a model that we achieve that is much deeper.

316
00:36:37,720 --> 00:36:42,720
 But at least you should know this basic concept.

317
00:36:42,720 --> 00:36:47,720
 So, this is a valid purpose of Delta I introduced this here.

318
00:36:47,720 --> 00:37:09,720
 Okay.

319
00:37:09,720 --> 00:37:22,720
 Here I'm showing, this actually is done by the DJI, his previous REID technology.

320
00:37:22,720 --> 00:37:30,720
 And I don't know how many years ago, but this technology was about two years ago

321
00:37:30,720 --> 00:37:37,720
 because when I teach the video system setting, I get this from one of my previous members.

322
00:37:37,720 --> 00:37:40,720
 He was working with DJI.

323
00:37:40,720 --> 00:37:49,720
 And unfortunately, we are not able to get the same test of two different algorithms.

324
00:37:49,720 --> 00:37:54,720
 But here I want to show that this is a REID technology, right?

325
00:37:54,720 --> 00:37:58,720
 And okay, just now you see the tracking from the lady, right?

326
00:37:58,720 --> 00:38:02,720
 Now they switch to a different person.

327
00:38:02,720 --> 00:38:07,720
 So this means REID actually fair to work.

328
00:38:07,720 --> 00:38:09,720
 Let's work.

329
00:38:09,720 --> 00:38:21,720
 Check it out.

330
00:38:21,720 --> 00:38:25,720
 So you can see we get the, detect the curve.

331
00:38:25,720 --> 00:38:31,720
 And just now the very, just now there's a loss of the object.

332
00:38:31,720 --> 00:38:35,720
 Now you see it's changing to another person.

333
00:38:35,720 --> 00:38:44,720
 So this is the limitation of the previous detection tracking.

334
00:38:44,720 --> 00:38:54,720
 Where this is achieved by FairMode JD, you can search this keyword to find the algorithms.

335
00:38:54,720 --> 00:39:04,720
 And you can see, right, even if there's some accruing and the argument can still be able to detect the person

336
00:39:04,720 --> 00:39:08,720
 and track the person correctly.

337
00:39:08,720 --> 00:39:17,720
 Of course, I believe in your showtime, it won't be easy for you to understand why JD is better than REID.

338
00:39:17,720 --> 00:39:29,720
 But intuitively I can explain and the reason is when we do the REID or the previous REID or joint detection,

339
00:39:29,720 --> 00:39:32,720
 previous detection tracking, right?

340
00:39:32,720 --> 00:39:37,720
 We are doing it in two steps, detection and tracking.

341
00:39:37,720 --> 00:39:43,720
 And these two steps are optimized individually.

342
00:39:43,720 --> 00:39:56,720
 So when you are, when you are changing the object detection, you didn't really think about how do I do it for tracking.

343
00:39:56,720 --> 00:40:05,720
 When you are doing device, develop the tracking algorithms, your detection algorithm is already out.

344
00:40:05,720 --> 00:40:07,720
 You cannot change it.

345
00:40:07,720 --> 00:40:17,720
 But in JD, your detection and your embedding is optimized simultaneously, right?

346
00:40:17,720 --> 00:40:25,720
 That's the, and because of the simultaneous optimization, you get better achievement.

347
00:40:25,720 --> 00:40:32,720
 If you have interest, right, you can study the JD code.

348
00:40:33,720 --> 00:40:38,720
 If you're looking for a job in JD.

349
00:40:38,720 --> 00:41:07,720
 So the second topic we want to talk about is the video or sometimes they call action-recognition.

350
00:41:07,720 --> 00:41:15,720
 Or video event detection.

351
00:41:15,720 --> 00:41:20,720
 So you can get, there's one dataset from this link.

352
00:41:20,720 --> 00:41:25,720
 You can go and play with it.

353
00:41:25,720 --> 00:41:29,720
 There are many detection tasks.

354
00:41:29,720 --> 00:41:40,720
 And some are relatively, relatively easier, let's say, to detect a push-up or ride a bicycle or ride a horse.

355
00:41:40,720 --> 00:41:45,720
 Because these are normally done by, you have a video clip.

356
00:41:45,720 --> 00:41:54,720
 You are going to classify whether this video click is riding horse, is it people running or is it shaking of the hands.

357
00:41:54,720 --> 00:42:01,720
 And another case is, looks similar, but it's actually different.

358
00:42:01,720 --> 00:42:07,720
 Like here, right, so the person's face is blocked.

359
00:42:07,720 --> 00:42:13,720
 And is a video, is a wedding ceremony.

360
00:42:13,720 --> 00:42:18,720
 And for this kind of case, right.

361
00:42:18,720 --> 00:42:24,720
 So the understanding of the event is actually based on, you have a right here.

362
00:42:24,720 --> 00:42:28,720
 And therefore you can detect this, right.

363
00:42:28,720 --> 00:42:33,720
 Essentially it's not really based on action or something.

364
00:42:33,720 --> 00:42:36,720
 But here is a lot of based on some action.

365
00:42:48,720 --> 00:43:04,720
 So in video event, I remember when, okay, so now you see the player shoots the basketball.

366
00:43:04,720 --> 00:43:08,720
 And this is a football case.

367
00:43:19,720 --> 00:43:31,720
 In video event, right, so the task is, if you have a video, can you detect whether there's a goal or not.

368
00:43:31,720 --> 00:43:42,720
 Right, or give you the video, can you capture the moment where the player shoots the football.

369
00:43:48,720 --> 00:44:04,720
 So in terms of technology, right, so the video event or action recognition or some different case,

370
00:44:04,720 --> 00:44:08,720
 or more complicated video detection, video recognition, right.

371
00:44:08,720 --> 00:44:12,720
 They are using quite similar strategies.

372
00:44:18,720 --> 00:44:24,720
 It's not really based on a clip or video sequence.

373
00:44:24,720 --> 00:44:30,720
 And we will to extract the features from each frame and concatenate together.

374
00:44:30,720 --> 00:44:40,720
 And pass the features to a classifier to tell whether this is a specific action or a specific event.

375
00:44:40,720 --> 00:44:45,720
 These are defined by the training data.

376
00:44:53,720 --> 00:45:07,720
 But if you look at only this part, right, facial tracking and classifier, this is almost identical to the object recognition, right.

377
00:45:07,720 --> 00:45:25,720
 In object recognition, if you play with the image net, and they are desired to be learning to train the network to extract the features and then map that to object classifying.

378
00:45:25,720 --> 00:45:28,720
 Here is also the same.

379
00:45:28,720 --> 00:45:34,720
 But we do realize that in video, right, because we have many, many frames.

380
00:45:34,720 --> 00:45:46,720
 And if we get some videos and change this one, and we realize that this model is quite sensitive to the sampling rate of the videos.

381
00:45:46,720 --> 00:45:49,720
 This, I can play like this, right.

382
00:45:49,720 --> 00:45:52,720
 So I can wave in a slow speed.

383
00:45:52,720 --> 00:45:56,720
 I can also wave very fast.

384
00:45:56,720 --> 00:46:03,720
 So if my training data is 100 different videos, I wave very fast.

385
00:46:03,720 --> 00:46:08,720
 Now if you give me a testing data where I wave very slow.

386
00:46:08,720 --> 00:46:10,720
 What?

387
00:46:14,720 --> 00:46:20,720
 We train the model and wave very slow. We can also still detect the recognize.

388
00:46:20,720 --> 00:46:22,720
 But the computer is not that smart.

389
00:46:22,720 --> 00:46:32,720
 The computer models, they actually can detect the data that is similar to your training data.

390
00:46:32,720 --> 00:46:43,720
 So if you are training the model with very fast movement and detect with a slow movement, it's going to fail.

391
00:46:43,720 --> 00:46:49,720
 So this actually is equivalent to the video sampling rate.

392
00:46:49,720 --> 00:47:00,720
 So a lot of effort in video recognition, right.

393
00:47:00,720 --> 00:47:09,720
 They are trying to design how do I do the video sampling such that different videos can be normalized.

394
00:47:09,720 --> 00:47:14,720
 So this is one of the topics here, right.

395
00:47:14,720 --> 00:47:17,720
 Another is how do I extract the features?

396
00:47:17,720 --> 00:47:22,720
 Because here is a video sequence. This is not a single image.

397
00:47:22,720 --> 00:47:27,720
 So compare with image recognition, right.

398
00:47:27,720 --> 00:47:34,720
 I have to consider the association between the different frames.

399
00:47:44,720 --> 00:47:53,720
 So just a mention, right.

400
00:47:53,720 --> 00:47:55,720
 So why is sample this?

401
00:47:55,720 --> 00:48:01,720
 There's a real, so a raw video sequence to a video clip.

402
00:48:01,720 --> 00:48:11,720
 And in many of the research, right, so I see the video clips maybe eight frames or 16 frames if I'm not wrong.

403
00:48:11,720 --> 00:48:22,720
 And the task is I, in order to change this, right, so I can get many training data where each training data is 16 frames.

404
00:48:22,720 --> 00:48:29,720
 And we have a level of the data and then eventually you can change the algorithm.

405
00:48:29,720 --> 00:48:40,720
 And so this, if we do not consider this part, right, so this is very similar to the object recognition.

406
00:48:41,720 --> 00:48:52,720
 So here are just some examples of the technology in video recognition.

407
00:48:52,720 --> 00:48:59,720
 Why is the long term recurrent convolution network?

408
00:48:59,720 --> 00:49:01,720
 So,

409
00:49:06,720 --> 00:49:12,720
 Nishing in the sequence as input, right, so we may have several images.

410
00:49:12,720 --> 00:49:17,720
 Just now I showed that computer see a video is a few frames, right.

411
00:49:17,720 --> 00:49:20,720
 So we may have, for example, three frames.

412
00:49:20,720 --> 00:49:27,720
 And from each frame, right, we try to extract features that can represent these frames.

413
00:49:27,720 --> 00:49:35,720
 And this long short term memory is a structure that can show the different frames.

414
00:49:35,720 --> 00:49:46,720
 And by combining these features together, we can make a decision or classification whether this is a high jump or other actions.

415
00:49:47,720 --> 00:49:52,720
 Well, a slight difference is image caption.

416
00:49:52,720 --> 00:50:08,720
 We may have an image as input, but we are trying to use text to describe these images.

417
00:50:09,720 --> 00:50:14,720
 So of course, they also use long short term memory.

418
00:50:18,720 --> 00:50:22,720
 And it covers these same features to this.

419
00:50:22,720 --> 00:50:29,720
 And this is often done by, now they are so-called contrastive learning.

420
00:50:29,720 --> 00:50:34,720
 So they can do by trying the feature from this text.

421
00:50:34,720 --> 00:50:37,720
 Of course, they call it a text encoder.

422
00:50:37,720 --> 00:50:46,720
 And try to, because this is text is describing this image, right.

423
00:50:46,720 --> 00:50:56,720
 And they are believe that text encoder will be extracted features and image encoder will be extracted.

424
00:50:56,720 --> 00:50:58,720
 These two features should be the same.

425
00:50:58,720 --> 00:51:09,720
 And that's called the contrastive image language learning.

426
00:51:09,720 --> 00:51:17,720
 And this is actually the, I think it's some kind of the foundation of the recent foundation models.

427
00:51:17,720 --> 00:51:25,720
 The foundation model was trained or inspired based on this.

428
00:51:26,720 --> 00:51:38,720
 And here, instead of based on single image, we can do the description based on video sequence.

429
00:51:38,720 --> 00:51:50,720
 And of course, a lot of research is just to design different network here, try to describe the video.

430
00:51:55,720 --> 00:52:05,720
 Here is another approach.

431
00:52:05,720 --> 00:52:08,720
 Of course, that's just for you.

432
00:52:08,720 --> 00:52:12,720
 This is not really a quite state of art.

433
00:52:17,720 --> 00:52:19,720
 You charge.

434
00:52:19,720 --> 00:52:23,720
 So let's say we can have three consecutive frames, right?

435
00:52:23,720 --> 00:52:28,720
 So normally we, in image based feature from the issue image.

436
00:52:28,720 --> 00:52:41,720
 But here we can do a convolution across the different frames to get the features from the time of special temporal features.

437
00:52:41,720 --> 00:52:46,720
 Of course, this is not really a very, it's not really a very high efficient algorithm.

438
00:52:46,720 --> 00:52:52,720
 But this is one of the early arguments that researchers are trying.

439
00:52:54,720 --> 00:53:06,720
 Here is one of our own work, my own work.

440
00:53:06,720 --> 00:53:18,720
 And what you are showing here, you can see here is a Cini MRI data captured from the heart.

441
00:53:24,720 --> 00:53:31,720
 Yeah, so you can see the movement of the heart, right?

442
00:53:31,720 --> 00:53:36,720
 And what our computer sees is a set of frames.

443
00:53:36,720 --> 00:53:41,720
 The purpose is this, is from this video moment.

444
00:53:41,720 --> 00:53:47,720
 Can you tell whether this is from a healthy subject or unhealthy subject?

445
00:53:47,720 --> 00:53:57,720
 Of course, this microvascular obstruction is one of the conditions of the disease.

446
00:53:57,720 --> 00:54:02,720
 So what do we do?

447
00:54:02,720 --> 00:54:07,720
 How to achieve that?

448
00:54:07,720 --> 00:54:18,720
 So we actually make use of the 3D convolution.

449
00:54:18,720 --> 00:54:22,720
 So of course, your data is a set of frames.

450
00:54:22,720 --> 00:54:27,720
 And we use a 3D CIN to extract the features from this one.

451
00:54:27,720 --> 00:54:33,720
 And this R2 plus 1D is another motion feature extraction.

452
00:54:33,720 --> 00:54:37,720
 And then with that we can extract some motion features.

453
00:54:37,720 --> 00:54:40,720
 And here is the classifiers.

454
00:54:40,720 --> 00:54:46,720
 Here is, you don't need to look at this because this is a specific track,

455
00:54:46,720 --> 00:54:50,720
 methods dealing with this specific data.

456
00:54:53,720 --> 00:54:58,720
 So this actually is our latest...

457
00:54:59,720 --> 00:55:03,720
 I'll show this one.

458
00:55:03,720 --> 00:55:15,720
 How to design the feature extraction here is one of the hot topics in dealing with video data scenes and offsets.

459
00:55:15,720 --> 00:55:17,720
 Doing the classifier here.

460
00:55:17,720 --> 00:55:22,720
 But here the part, if you are active in the area, you may have heard it.

461
00:55:22,720 --> 00:55:27,720
 It's just some existing algorithms.

462
00:55:28,720 --> 00:55:44,720
 So in some of the network, right?

463
00:55:44,720 --> 00:55:54,720
 So the overview...

464
00:55:54,720 --> 00:56:00,720
 This, they may have two streams to process the data.

465
00:56:00,720 --> 00:56:03,720
 Because we know that for video, right?

466
00:56:03,720 --> 00:56:07,720
 So we may have image, the first frame.

467
00:56:07,720 --> 00:56:10,720
 You can just consider the image, right?

468
00:56:10,720 --> 00:56:16,720
 But from the first frame to subsequent frames, we have the motion, right?

469
00:56:16,720 --> 00:56:23,720
 So we may consider each video as image plus motion.

470
00:56:23,720 --> 00:56:27,720
 Then you can follow...

471
00:56:27,720 --> 00:56:34,720
 Okay, I extract the image features, I extract the motion features, and then combine them together.

472
00:56:34,720 --> 00:56:38,720
 And in deep learning, right?

473
00:56:38,720 --> 00:56:45,720
 How do I get the data to change my model?

474
00:56:45,720 --> 00:56:47,720
 Right.

475
00:56:47,720 --> 00:56:52,720
 So I think if you hear about there are three basic elements.

476
00:56:52,720 --> 00:57:00,720
 That is your data, your computer resources, and network structures.

477
00:57:00,720 --> 00:57:05,720
 That will be the three basic elements for deep learning or for AI.

478
00:57:05,720 --> 00:57:10,720
 But here, if we are doing the special...

479
00:57:10,720 --> 00:57:19,720
 ...the motion, we may change these two parts individually with other data.

480
00:57:19,720 --> 00:57:32,720
 For example...

481
00:57:32,720 --> 00:57:42,720
 This is the case for the heart disease.

482
00:57:42,720 --> 00:57:46,720
 This data you have to capture from human.

483
00:57:46,720 --> 00:57:59,720
 You can't ask anybody to do the scan and give you the data.

484
00:57:59,720 --> 00:58:07,720
 So when we train the deep learning, we definitely hope large amount data.

485
00:58:07,720 --> 00:58:09,720
 How do we do it?

486
00:58:09,720 --> 00:58:17,720
 Instead of relying on pure medical images, I may use other images.

487
00:58:17,720 --> 00:58:25,720
 Could it be... or videos, could it be non-medical domain to train the motion instructions?

488
00:58:25,720 --> 00:58:30,720
 And then use medical images to find the model.

489
00:58:30,720 --> 00:58:32,720
 So we call this the training.

490
00:58:32,720 --> 00:58:39,720
 So you train the model with very large data related or non-related with your task.

491
00:58:39,720 --> 00:58:45,720
 And fine tune the model with the data from your...

492
00:58:45,720 --> 00:58:59,720
 ...and you can actually get better results.

493
00:58:59,720 --> 00:59:07,720
 Okay, I think we can have 15 minutes break before we talk about the enhancement.

494
00:59:07,720 --> 00:59:16,720
 If you have any questions, you can approach me.

495
00:59:16,720 --> 00:59:24,720
 So we come back at 7.45.

496
00:59:59,720 --> 01:00:09,720
 Okay.

497
01:00:29,720 --> 01:00:39,720
 Okay.

498
01:00:59,720 --> 01:01:09,720
 Okay.

499
01:01:29,720 --> 01:01:49,720
 Okay.

500
01:01:49,720 --> 01:01:59,720
 Okay.

501
01:02:19,720 --> 01:02:39,720
 Okay.

502
01:02:39,720 --> 01:02:49,720
 Okay.

503
01:02:49,720 --> 01:02:59,720
 Okay.

504
01:02:59,720 --> 01:03:09,720
 Okay.

505
01:03:09,720 --> 01:03:29,720
 Okay.

506
01:03:29,720 --> 01:03:39,720
 Okay.

507
01:03:39,720 --> 01:03:49,720
 Okay.

508
01:03:49,720 --> 01:03:59,720
 Okay.

509
01:03:59,720 --> 01:04:09,720
 Okay.

510
01:04:09,720 --> 01:04:19,720
 Okay.

511
01:04:19,720 --> 01:04:29,720
 Okay.

512
01:04:29,720 --> 01:04:39,720
 Okay.

513
01:04:39,720 --> 01:04:49,720
 Okay.

514
01:04:49,720 --> 01:04:59,720
 Okay.

515
01:04:59,720 --> 01:05:09,720
 Okay.

516
01:05:09,720 --> 01:05:19,720
 Okay.

517
01:05:19,720 --> 01:05:29,720
 Okay.

518
01:05:29,720 --> 01:05:39,720
 Okay.

519
01:05:39,720 --> 01:05:49,720
 Okay.

520
01:05:49,720 --> 01:05:59,720
 Okay.

521
01:05:59,720 --> 01:06:09,720
 Okay.

522
01:06:09,720 --> 01:06:19,720
 Okay.

523
01:06:19,720 --> 01:06:29,720
 Okay.

524
01:06:29,720 --> 01:06:39,720
 Okay.

525
01:06:39,720 --> 01:06:49,720
 Okay.

526
01:06:49,720 --> 01:06:59,720
 Okay.

527
01:06:59,720 --> 01:07:09,720
 Okay.

528
01:07:09,720 --> 01:07:19,720
 Okay.

529
01:07:19,720 --> 01:07:29,720
 Okay.

530
01:07:29,720 --> 01:07:39,720
 Okay.

531
01:07:39,720 --> 01:07:49,720
 Okay.

532
01:07:49,720 --> 01:07:59,720
 Okay.

533
01:07:59,720 --> 01:08:09,720
 Okay.

534
01:08:09,720 --> 01:08:19,719
 Okay.

535
01:08:19,719 --> 01:08:29,719
 Okay.

536
01:08:29,719 --> 01:08:35,719
 Okay.

537
01:08:35,720 --> 01:08:45,720
 Okay.

538
01:08:45,720 --> 01:08:55,720
 Okay.

539
01:08:55,720 --> 01:09:01,720
 Okay.

540
01:09:01,720 --> 01:09:11,720
 Okay.

541
01:09:11,720 --> 01:09:21,720
 Okay.

542
01:09:21,720 --> 01:09:31,720
 Okay.

543
01:09:31,720 --> 01:09:41,720
 Okay.

544
01:09:41,720 --> 01:09:49,720
 Okay.

545
01:09:49,720 --> 01:09:59,720
 Okay.

546
01:09:59,720 --> 01:10:09,720
 Okay.

547
01:10:09,720 --> 01:10:17,720
 Okay.

548
01:10:17,720 --> 01:10:27,720
 Okay.

549
01:10:27,720 --> 01:10:37,720
 Okay.

550
01:10:37,720 --> 01:10:43,720
 Okay.

551
01:10:43,720 --> 01:10:53,720
 Okay.

552
01:10:53,720 --> 01:11:03,720
 Okay.

553
01:11:03,720 --> 01:11:11,720
 Okay.

554
01:11:11,720 --> 01:11:21,720
 Okay.

555
01:11:21,720 --> 01:11:31,720
 Okay.

556
01:11:31,720 --> 01:11:37,720
 Okay.

557
01:11:37,720 --> 01:11:47,720
 Okay.

558
01:11:47,720 --> 01:11:57,720
 Okay.

559
01:11:57,720 --> 01:12:07,720
 Okay.

560
01:12:27,720 --> 01:12:37,720
 Okay.

561
01:12:37,720 --> 01:12:47,720
 Okay.

562
01:12:47,720 --> 01:12:53,720
 Okay.

563
01:12:53,720 --> 01:13:03,720
 Okay.

564
01:13:03,720 --> 01:13:13,720
 Okay.

565
01:13:13,720 --> 01:13:19,720
 Okay.

566
01:13:19,720 --> 01:13:29,720
 Okay.

567
01:13:29,720 --> 01:13:39,720
 Okay.

568
01:13:39,720 --> 01:13:45,720
 Okay.

569
01:13:45,720 --> 01:13:55,720
 Okay.

570
01:13:55,720 --> 01:14:05,720
 Okay.

571
01:14:05,720 --> 01:14:13,720
 Okay.

572
01:14:13,720 --> 01:14:23,720
 Okay.

573
01:14:23,720 --> 01:14:33,720
 Okay.

574
01:14:33,720 --> 01:14:39,720
 Okay.

575
01:14:39,720 --> 01:14:49,720
 Okay.

576
01:14:49,720 --> 01:14:59,720
 Okay.

577
01:14:59,720 --> 01:15:07,720
 Okay.

578
01:15:07,720 --> 01:15:17,720
 Okay.

579
01:15:17,720 --> 01:15:27,720
 Okay.

580
01:15:27,720 --> 01:15:33,720
 Okay.

581
01:15:33,720 --> 01:15:41,720
 Okay.

582
01:15:41,720 --> 01:15:43,720
 Okay.

583
01:15:43,720 --> 01:15:45,720
 Okay.

584
01:15:45,720 --> 01:15:53,720
 Okay.

585
01:15:53,720 --> 01:15:59,720
 Okay.

586
01:15:59,720 --> 01:16:01,720
 Okay.

587
01:16:01,720 --> 01:16:05,720
 So, the idea is that if you can do it, you try to do it.

588
01:16:05,720 --> 01:16:13,440
 Because to do that, at least you need some GPU resources, but I believe maybe not every

589
01:16:13,440 --> 01:16:16,720
 student can have the access in short time.

590
01:16:16,720 --> 01:16:20,720
 But if you can, you try to implement that.

591
01:16:20,720 --> 01:16:30,280
 The reason I asked you to do this is for this, definitely by the generous network, right?

592
01:16:30,280 --> 01:16:40,920
 And now the generator is very, very hot topic in both academic and in industry.

593
01:16:40,920 --> 01:16:43,200
 So just share something, right?

594
01:16:43,200 --> 01:16:51,759
 So maybe a few years ago, many companies, start-up companies, say, I'm an AI company.

595
01:16:51,759 --> 01:16:57,679
 Now if you go out, they say I'm an AI GC company, AI generator content company.

596
01:16:57,680 --> 01:17:06,600
 So they are paying more attention on the generation, so instead of purely AI.

597
01:17:06,600 --> 01:17:09,720
 And then you get familiar with this.

598
01:17:09,720 --> 01:17:16,560
 We are definitely helping you in whatever future work you may dealing with.

599
01:17:16,560 --> 01:17:21,120
 If you're looking for an industry job, if you want to apply for a PhD with this kind of

600
01:17:21,120 --> 01:17:23,200
 experience, it will be good.

601
01:17:23,200 --> 01:17:36,800
 But with this course, you just submit a two-page document to explain how you plan to do it.

602
01:17:36,800 --> 01:17:38,800
 You'll be sufficient.

603
01:17:38,800 --> 01:17:39,800
 Yeah.

604
01:17:39,800 --> 01:18:07,960
 So the second part is we will first have the video enhancement.

605
01:18:07,960 --> 01:18:13,280
 Here we also have video sanitation.

606
01:18:13,280 --> 01:18:18,720
 And the last week, we talked about the generative network, right?

607
01:18:18,720 --> 01:18:27,960
 And I believe the last lectures is more important to you.

608
01:18:27,960 --> 01:18:34,000
 In terms of research, video enhancement is, or it has been there for quite a long time

609
01:18:34,000 --> 01:18:35,000
 ago.

610
01:18:35,160 --> 01:18:36,160
 Yeah.

611
01:18:36,160 --> 01:18:44,840
 Because I've seen in many ago, there are some like films, for example.

612
01:18:44,840 --> 01:18:49,960
 And these films, they have been saving for some time, and then they have some noise,

613
01:18:49,960 --> 01:18:58,760
 and they already have been dealing with the noise in videos.

614
01:18:58,760 --> 01:19:09,520
 But we include this topic so that it's more complete in this lecture.

615
01:19:09,520 --> 01:19:17,160
 So our course denoises one in the unit.

616
01:19:17,160 --> 01:19:20,120
 Another one is the motion blur.

617
01:19:20,120 --> 01:19:25,040
 Because motion is almost everywhere.

618
01:19:25,040 --> 01:19:33,040
 And I believe when many years ago, or 20 years ago, when we were using cameras to take pictures,

619
01:19:33,040 --> 01:19:37,480
 if we are shaking, then you will get blurry images.

620
01:19:37,480 --> 01:19:42,680
 I think when I'm young, those cameras are not as good as now.

621
01:19:42,680 --> 01:19:44,680
 So you take the images.

622
01:19:44,680 --> 01:19:51,440
 You're only the expert, the expert, the expert person, we can be able to take images.

623
01:19:51,440 --> 01:19:56,719
 And now, of course, we have the mobile phones can take images.

624
01:19:56,719 --> 01:20:04,320
 They have some special design in the phones, such that even if you are shaking, the images

625
01:20:04,320 --> 01:20:09,400
 are still being shot.

626
01:20:09,400 --> 01:20:12,120
 But that denomines the motion is not there.

627
01:20:12,120 --> 01:20:13,120
 It's there.

628
01:20:13,120 --> 01:20:17,320
 It's just they have already processed it.

629
01:20:17,320 --> 01:20:27,320
 And this motion blur is one of the very important things we should deal with.

630
01:20:27,320 --> 01:20:36,519
 And now if you want to try to take an image at low light conditions or at night times,

631
01:20:36,519 --> 01:20:42,599
 you will face more challenges because of the motion.

632
01:20:42,600 --> 01:20:55,800
 So to understand how the motion may affect the image quality, it's actually very straightforward.

633
01:20:55,800 --> 01:21:00,120
 It can be modeled by a point spread function.

634
01:21:00,120 --> 01:21:06,120
 Let's say this is the original signals.

635
01:21:06,120 --> 01:21:14,360
 And this is a point spread function that represents the motion.

636
01:21:14,360 --> 01:21:23,320
 And the conversion of the two will plus some additive noise will be leading to the motion

637
01:21:23,320 --> 01:21:25,320
 blur.

638
01:21:36,120 --> 01:21:52,920
 So, in case there's no motion, right, so actually the point spread function is equal

639
01:21:52,920 --> 01:22:00,200
 to one if for N1 and N2 equal to zero and zero elsewhere.

640
01:22:00,200 --> 01:22:07,320
 But in practice, right, so this point spread function is want to be like this and it will

641
01:22:07,320 --> 01:22:25,679
 be leading to the, actually it means overlapping of the images from one space to another space.

642
01:22:25,680 --> 01:22:30,680
 So I see where I'm working on image processing.

643
01:22:30,680 --> 01:22:35,600
 This is the image, it's one of the standard images we are using.

644
01:22:35,600 --> 01:22:40,360
 Many people just use the image and the test, the algorithms and show the results, they

645
01:22:40,360 --> 01:22:41,360
 publish the paper.

646
01:22:41,360 --> 01:22:48,040
 But I think the last year or something, they are saying I should be general, we are not

647
01:22:48,040 --> 01:22:50,360
 allowed you to use these images.

648
01:22:50,679 --> 01:22:57,080
 Anyway, you can still use this image to show how the different blur may appear or looks

649
01:22:57,080 --> 01:23:10,080
 like.

650
01:23:10,080 --> 01:23:26,320
 So now if we know the point spread function, we actually can do the recovery of the images.

651
01:23:26,320 --> 01:23:33,480
 But in real life, right, so you don't know what's the motion corners or the point spread

652
01:23:33,480 --> 01:23:34,480
 functions.

653
01:23:34,480 --> 01:23:35,960
 So, give me use this image, right.

654
01:23:35,960 --> 01:23:38,800
 You don't know what's the point spread function.

655
01:23:38,800 --> 01:23:46,640
 And if you happen to use point spread function that is not accurate, then you will not be

656
01:23:46,640 --> 01:23:49,880
 able to recover the images.

657
01:23:49,880 --> 01:23:55,840
 So this is the potential result when your point spread function is wrong.

658
01:23:55,840 --> 01:24:08,600
 And so a lot of cases, the work is how to estimate the point spread functions.

659
01:24:08,600 --> 01:24:21,960
 So and with the deep learning being available, so we no longer try to estimate the point

660
01:24:21,960 --> 01:24:23,320
 spread functions.

661
01:24:23,320 --> 01:24:32,440
 And instead we use encoder decoder structures, which is I think it's used almost everywhere

662
01:24:32,440 --> 01:24:42,559
 now and try to give the encoder the blur image and give the decoder, hope the decoder can

663
01:24:42,559 --> 01:24:45,639
 get the, recover the image.

664
01:24:45,639 --> 01:24:49,080
 So using the deep learning.

665
01:24:49,080 --> 01:24:51,840
 Of course it's very difficult to understand how it works, right.

666
01:24:51,840 --> 01:24:58,040
 So this is also the reason why we say this deep learning is a black box.

667
01:24:58,040 --> 01:25:06,600
 But this kind of approach, right, is in terms of academic research, it could be something

668
01:25:06,600 --> 01:25:09,720
 that can be published somewhere in practical use, right.

669
01:25:09,720 --> 01:25:15,640
 So I believe I have tried this before to deal with something, right.

670
01:25:16,440 --> 01:25:23,880
 In real life, the blur and this could have become from various many, many reasons.

671
01:25:23,880 --> 01:25:32,760
 And therefore this approach, if you use it in real life data, you actually, you will

672
01:25:32,760 --> 01:25:35,200
 be disappointed in the result.

673
01:25:35,200 --> 01:25:44,280
 Even though in lab where the data follow some idea assumption, it works.

674
01:25:44,280 --> 01:25:57,360
 But in reality it's not going to work.

675
01:25:57,360 --> 01:26:04,480
 This is another case of, another application of the video, we can also say it's a video

676
01:26:04,480 --> 01:26:08,840
 enhancement that is to remove the turbulence effect.

677
01:26:08,840 --> 01:26:14,720
 So basically if you, I think if you throw something into the water and you try to take

678
01:26:14,720 --> 01:26:20,440
 a video of the scene, right, you may get something like that.

679
01:26:20,440 --> 01:26:25,800
 And in this case, right, it's, the noise is not the main issue.

680
01:26:25,800 --> 01:26:32,760
 The main issue is when the water is, have some turbulence, the scene is changing.

681
01:26:32,760 --> 01:26:38,520
 And the change is actually, it's not really a linear change or rigid change.

682
01:26:39,200 --> 01:26:40,880
 So, it's not rigid.

683
01:26:40,880 --> 01:26:47,320
 So like from one frame to another frame, there's a non-rigid deformation.

684
01:26:47,320 --> 01:26:58,640
 And let's say if you have a world document under the water and you make the water, you

685
01:26:58,640 --> 01:27:03,720
 do some dispersion of the water, then you may see the world like this, right.

686
01:27:03,720 --> 01:27:06,240
 So how can you recover this?

687
01:27:06,240 --> 01:27:14,760
 So for such approach, right, so that there are actually people using more experimental

688
01:27:14,760 --> 01:27:15,760
 approach.

689
01:27:15,760 --> 01:27:24,200
 So anyway, we, for this video frame that we actually get a sequence of data and we try

690
01:27:24,200 --> 01:27:34,599
 to using some non-rigid registration algorithms to register this data.

691
01:27:34,600 --> 01:27:42,720
 And after registration, right, you actually can use an approach called low rank decomposition.

692
01:27:42,720 --> 01:27:47,920
 So I'm not sure how many you can still remember low rank record.

693
01:27:47,920 --> 01:27:49,560
 What is a low rank means?

694
01:27:49,560 --> 01:27:57,440
 How many you can know what's the meaning of low rank, you can raise your hand.

695
01:27:57,440 --> 01:27:58,440
 Anybody know?

696
01:27:58,440 --> 01:28:01,440
 Nobody know?

697
01:28:02,440 --> 01:28:13,440
 So, the low rank is, so I feel we have dealing with linear algebra, right.

698
01:28:13,440 --> 01:28:17,519
 So in undergraduate, you definitely have a linear algebra.

699
01:28:17,519 --> 01:28:24,080
 And for each matrix, right, actually our, each image is, is typically represented by

700
01:28:24,080 --> 01:28:32,600
 the matrix, each matrix you can compute is a rank.

701
01:28:32,600 --> 01:28:45,440
 While where we have the, this sequence being registered and for each pixel or each location,

702
01:28:45,440 --> 01:28:47,280
 a long difference sequence.

703
01:28:47,280 --> 01:28:52,400
 If it is really well aligned, it should be have the same value, right.

704
01:28:52,400 --> 01:28:59,519
 So now if we have a vector of all the ones, so, okay, I give an example.

705
01:28:59,519 --> 01:29:04,280
 So let's say we have a matrix, the first row is all the ones.

706
01:29:04,280 --> 01:29:06,280
 The second row is all the tools.

707
01:29:06,280 --> 01:29:08,559
 And the third row is all the trees.

708
01:29:08,559 --> 01:29:14,320
 What do you think is the rank of this matrix of all one, two, three?

709
01:29:14,320 --> 01:29:18,040
 Okay, so the rank is one.

710
01:29:18,040 --> 01:29:19,040
 Why?

711
01:29:19,400 --> 01:29:24,560
 The second row can be represented by the first row, right.

712
01:29:24,560 --> 01:29:32,480
 And if we, here is a matrix, right, each sequence is a matrix.

713
01:29:32,480 --> 01:29:41,600
 If we just really represent this one as one vector, let's say this is 200 by 200 image.

714
01:29:41,600 --> 01:29:50,560
 We change it to be 40, 40k a vector.

715
01:29:50,560 --> 01:29:57,760
 Just image, I put it straight into one vector.

716
01:29:57,760 --> 01:30:02,920
 And I put the first image in the first row, the second image in the second row, and the

717
01:30:02,920 --> 01:30:05,880
 third image in the third row.

718
01:30:05,880 --> 01:30:13,680
 So in ideal case, if all the frames are identical after registration, what's the rank of the

719
01:30:13,680 --> 01:30:14,680
 matrix?

720
01:30:14,680 --> 01:30:25,440
 Because all the first row, the second row, and third row actually will be identical.

721
01:30:25,440 --> 01:30:27,840
 So the rank is also one, right.

722
01:30:27,840 --> 01:30:32,440
 So that's why we do a low rank decomposition.

723
01:30:32,440 --> 01:30:39,280
 We will be able to solve for the reference image.

724
01:30:39,280 --> 01:30:46,440
 So low rank, I didn't include the detail here, but the low rank representation is, I give

725
01:30:46,440 --> 01:30:50,480
 you a matrix which may not be low rank.

726
01:30:50,480 --> 01:30:59,759
 You decompose it into two metrics where the first matrix is low rank, the second matrix

727
01:30:59,759 --> 01:31:03,679
 is noise.

728
01:31:03,679 --> 01:31:08,679
 So this is how they do it.

729
01:31:08,680 --> 01:31:31,280
 And so the next we are, I would like to introduce the optical flow.

730
01:31:31,280 --> 01:31:42,719
 So this technology itself doesn't look like we're using video, but actually it's used

731
01:31:42,719 --> 01:31:55,200
 to compute how the flow, what's the flow from one frame to another frame, or to check the

732
01:31:55,200 --> 01:32:13,880
 movement.

733
01:32:13,880 --> 01:32:25,680
 So let's say we have one frame IT and the T represents the time, right.

734
01:32:25,680 --> 01:32:28,840
 And then we have another frame IT plus one.

735
01:32:28,840 --> 01:32:40,880
 So how do I know the flow at each point here or each point box here?

736
01:32:40,880 --> 01:32:52,640
 So using the optical flow, we are trying to compute the, we can say it's a velocity vector,

737
01:32:52,640 --> 01:32:59,160
 or you can say, what is the motion here at this point from frame one to frame two, it

738
01:32:59,160 --> 01:33:02,320
 moves to this direction or this direction.

739
01:33:02,320 --> 01:33:17,440
 So how the motion moves will be determining the so-called optical flow.

740
01:33:17,440 --> 01:33:24,200
 So in terms of definition, optical flow is a relation of the motion field.

741
01:33:24,200 --> 01:33:32,080
 And it's capturing how what's the displacement of the pixels of the image plane from one

742
01:33:32,080 --> 01:33:38,920
 frame to the next frame.

743
01:33:38,920 --> 01:33:50,000
 And the most optical flow is based on some assumptions such as spatial coherence and

744
01:33:50,000 --> 01:33:52,920
 also time coherence.

745
01:33:53,640 --> 01:34:00,880
 The special conclusion is that we assume that two neighboring pixels or very close pixels

746
01:34:00,880 --> 01:34:04,120
 neighboring points in the same thing.

747
01:34:04,120 --> 01:34:11,040
 Typically it's not every time, but in the majority case maybe the same surface, right.

748
01:34:11,040 --> 01:34:15,400
 So like we have this pointer here, right.

749
01:34:15,400 --> 01:34:20,640
 So any two points, they are constrained by the surface.

750
01:34:20,680 --> 01:34:29,160
 So if this I move, right, all the points move with similar directions.

751
01:34:41,000 --> 01:34:49,560
 Another assumption is the temporal persistence, meaning the image motion of a surface patch

752
01:34:49,600 --> 01:34:58,440
 change from one frame to another frame or a change over the time should be very gradually.

753
01:34:58,440 --> 01:35:07,400
 So this gradually there's no clear definition of how gradually is gradually, but it's quite

754
01:35:07,400 --> 01:35:10,680
 related with the sampling rate of the video.

755
01:35:10,680 --> 01:35:19,520
 So normally we watch video, some video I've seen is like 60 frames per second.

756
01:35:19,520 --> 01:35:29,200
 And in terms of real time, we normally at least 15 frames per second.

757
01:35:29,200 --> 01:35:35,320
 So from 15 frames per second to 60 frames per second, there's four times of difference

758
01:35:35,320 --> 01:35:37,040
 sampling rate.

759
01:35:37,040 --> 01:35:47,680
 So this sampling rate will be related with whether this is considered gradual or not.

760
01:35:51,640 --> 01:35:59,760
 And in Optifluida there's one famous constraint that called brightness constraint.

761
01:35:59,760 --> 01:36:17,160
 So the basic assumption is that from a point x, y to one frame, we have a small displacement

762
01:36:17,160 --> 01:36:21,720
 to x plus data x and y plus data y, right.

763
01:36:21,720 --> 01:36:27,640
 So the brightness of this point should be maintained.

764
01:36:30,760 --> 01:36:37,760
 This is approximation, it's not really a very strict condition.

765
01:36:41,760 --> 01:36:54,760
 So this means if I have a point at time t and a frame of time t with a point at x, y,

766
01:36:54,760 --> 01:37:02,760
 if this point have a vector on this direction and move to x plus data x and y plus data

767
01:37:02,760 --> 01:37:07,760
 in time t plus one, these two points should be the same intensity.

768
01:37:07,760 --> 01:37:10,760
 So this gets the equation here.

769
01:37:10,760 --> 01:37:15,760
 It's called the brightness consistency assumption.

770
01:37:16,760 --> 01:37:27,760
 So I believe you have learned about the Taylor series how to expand the Taylor series, right.

771
01:37:27,760 --> 01:37:29,760
 So we can do this.

772
01:37:30,760 --> 01:37:45,760
 So the intensity of i x plus data x, y plus data y and t plus data t, right, will be equal

773
01:37:45,760 --> 01:37:50,760
 to i x, y, t plus the variation items.

774
01:37:50,760 --> 01:38:02,760
 So y is the derivative of i with the pressure of x times data x plus the derivative of i

775
01:38:02,760 --> 01:38:14,760
 with data y times data y with y and also the derivative over t times data t.

776
01:38:14,760 --> 01:38:16,760
 So we can do this.

777
01:38:16,760 --> 01:38:22,760
 And then we can also add the second order and third order and high order items.

778
01:38:22,760 --> 01:38:31,760
 But normally we can assume the high order items are ignorable and just put as zero.

779
01:38:35,760 --> 01:38:42,760
 And since we have the assumption of the brightness constraint, right, this one equal to this, right.

780
01:38:42,760 --> 01:38:49,760
 So this one to be here, that means these two can be counter each other.

781
01:38:49,760 --> 01:38:54,760
 That means this item will be equal to zero, right.

782
01:39:01,760 --> 01:39:09,760
 With this equal to this, right, so these two items can be structured and the high order items are ignored.

783
01:39:09,760 --> 01:39:11,760
 So the top will be zero.

784
01:39:17,760 --> 01:39:32,760
 And if we put the data t in the, to divide the, here, we divide this item with data t, right.

785
01:39:32,760 --> 01:39:42,760
 And then we will have the i with derivative of x, data t divided by data, data x divided by data t, right.

786
01:39:42,760 --> 01:39:44,760
 And also here data y divided by data t.

787
01:39:44,760 --> 01:39:48,760
 The last item of the data t divided by data t will be one, right.

788
01:39:48,760 --> 01:39:50,760
 So this one will be equal to zero.

789
01:39:51,760 --> 01:40:11,760
 And if we let the data t be approaching zero, this item will be the differential of dt by dx of dt, right.

790
01:40:12,760 --> 01:40:24,760
 So this equation is called the brightness consistency equation.

791
01:40:29,760 --> 01:40:34,760
 So you can rewrite this one to this item or this items.

792
01:40:41,760 --> 01:40:54,760
 So this equation is often used in the optical flow.

793
01:40:54,760 --> 01:41:09,760
 And if we rewrite the items, you will realize this, right.

794
01:41:09,760 --> 01:41:24,760
 So the delta of the i dot product with uv, uv actually represents the speed of the x and y directions.

795
01:41:24,760 --> 01:41:28,760
 And plus it will be zero.

796
01:41:28,760 --> 01:41:35,760
 This actually means the motion perpendicular to the gradient.

797
01:41:35,760 --> 01:41:48,760
 So here the motion perpendicular to the gradient cannot be measured because the inner product will be equal to zero.

798
01:41:48,760 --> 01:42:01,760
 So this is the equation.

799
01:42:01,760 --> 01:42:06,760
 Next let's move to the video simulation.

800
01:42:06,760 --> 01:42:15,760
 Compared with video enhancement, I believe video simulation will be more of the interest to the research.

801
01:42:15,760 --> 01:42:31,760
 And this actually is compared with the video object detection and object detection.

802
01:42:31,760 --> 01:42:47,760
 The video simulation is also similar to the image simulation except that we need to consider the time domain coherence.

803
01:42:47,760 --> 01:42:55,760
 So before that, we first understand what is the simulation.

804
01:42:55,760 --> 01:43:03,760
 So we often say this is you give the net deep learning, you give some pictures in and if you give some picture out.

805
01:43:03,760 --> 01:43:15,760
 So you can have a person riding a horse try to segment the boundary of the horse and also the human.

806
01:43:15,760 --> 01:43:21,760
 You can have animals and cheese try to segment the boundary of this.

807
01:43:21,760 --> 01:43:31,760
 And of course besides sanitation, right, the picture in show can also be in the case of depth estimation.

808
01:43:31,760 --> 01:43:46,760
 So this is a table you try to estimate the depth from the cameras.

809
01:43:46,760 --> 01:44:03,760
 So when deep learning was first invented for classification tasks, right, so the people were thinking, so let's say how the community can be done, right.

810
01:44:03,760 --> 01:44:15,760
 So we basically give an image and it just features and gradually compute a vector of 1000 dimensions.

811
01:44:15,760 --> 01:44:24,760
 So this is actually a bit down in the image net data set and there are 1000 class of objects.

812
01:44:24,760 --> 01:44:30,760
 And this vector, each element in the vector represents the property of the object.

813
01:44:30,760 --> 01:44:38,760
 This image to be the object could be cut, could be dog, could be any of the 1000.

814
01:44:39,760 --> 01:44:55,760
 And then because this is a card, right, so they are expecting the coefficient for the cut to be the highest among the 1000 vectors.

815
01:44:55,760 --> 01:45:08,760
 So, actually RCNA is one of the classic object detection algorithms, right.

816
01:45:08,760 --> 01:45:24,760
 So you have the image input, you try to extract some, they call the region proposals and then for each proposal, right, they compute the same features and try to classify whether this is human or any other objects.

817
01:45:24,760 --> 01:45:37,760
 So this is how the very early version of the method for deep learning based object detection.

818
01:45:37,760 --> 01:45:51,760
 So, RN is doing a given image, right, I'm trying to get only box of dog and cut and other objects.

819
01:45:51,760 --> 01:46:04,760
 So, people will have the question, right, how do I use this deep learning network for the purpose of simulation, right.

820
01:46:04,760 --> 01:46:09,760
 Simulation compared with the difference just now, right.

821
01:46:09,760 --> 01:46:18,760
 If it's recognition, it's just a class, whether it's cut or dog or anything else.

822
01:46:18,760 --> 01:46:26,760
 And object detection is to take the bounding box of the object.

823
01:46:26,760 --> 01:46:36,760
 But simulation is, you need to give a map to expect, tell me where exactly is the cut and the dog.

824
01:46:36,760 --> 01:46:41,760
 And this matrix and of course the rest will be background, right.

825
01:46:41,760 --> 01:46:47,760
 So this matrix, we have the same as the input images.

826
01:46:47,760 --> 01:46:59,760
 And this is why we call this pixel and it picks out because you get the same amount of pixels output compared with your input.

827
01:46:59,760 --> 01:47:09,760
 And for those people who work on deep learning, right, they always like to make the network be end to end learning.

828
01:47:09,760 --> 01:47:13,760
 So that means my input and output are fixed.

829
01:47:13,760 --> 01:47:24,760
 Try to optimize your network to best approach this output.

830
01:47:24,760 --> 01:47:28,760
 So now we look at the very early network.

831
01:47:28,760 --> 01:47:34,760
 So you have some features, convolutional network to each other features.

832
01:47:34,760 --> 01:47:43,760
 And after feature, you try to help to fully collect the lasers to get the classification.

833
01:47:43,760 --> 01:47:47,760
 So how to modify this network for sanitation.

834
01:47:47,760 --> 01:48:00,760
 So the motivation is instead of using the fully connected network, they just use convolution and replace that with convolution.

835
01:48:04,760 --> 01:48:17,760
 And the final vector, which makes this vector be the same size of the h times w and we can reshape into this.

836
01:48:17,760 --> 01:48:28,760
 And that's achieved the purpose of, picks out.

837
01:48:28,760 --> 01:48:47,760
 So if we give the network, we train the network with this kind of ground shoes and we will be teaching the network to do sanitation.

838
01:48:47,760 --> 01:48:56,760
 So UNET is one of the very popular network.

839
01:48:56,760 --> 01:49:09,760
 It was, I think it's originally published in MEEK, I think, is one of the network applied for medical image sanitation.

840
01:49:09,760 --> 01:49:20,760
 And I think at the same time, so there's one paper in CEPR or something, it has very similar structure as UNET.

841
01:49:20,760 --> 01:49:29,760
 But I think at the very time, UNET is not that popular compared with the, I think it's called FPN or something.

842
01:49:29,760 --> 01:49:38,760
 But recently years, they just find this UNET structure is, so it's very simple and it's very useful.

843
01:49:38,760 --> 01:49:44,760
 And they are using this in the diffusion models.

844
01:49:44,760 --> 01:49:51,760
 In diffusion models, they are just UNET one, UNET two, UNET three and the connected with each other.

845
01:49:51,760 --> 01:49:55,760
 It becomes a diffusion models.

846
01:49:55,760 --> 01:49:58,760
 So simple but effective.

847
01:49:58,760 --> 01:50:02,760
 So they use it in many, many places.

848
01:50:09,760 --> 01:50:18,760
 So this UNET, right, so the structure is, you first have image input, right.

849
01:50:18,760 --> 01:50:27,760
 So you have a structure features in by two convolutional network and then you're done sample.

850
01:50:27,760 --> 01:50:33,760
 And another two convolutional network and done sample and the convolution again and done some more convolution.

851
01:50:33,760 --> 01:50:52,760
 And this stage, right, we call it the contraction phase because after each measure, the dimension of the, so let's hear, right, my input image input is 5.7.2 times 5.7.2, right.

852
01:50:53,760 --> 01:51:03,760
 And after convolution, if we do this one, if we do not consider the padding, it will reduce by 2.

853
01:51:03,760 --> 01:51:11,760
 And this done sampling here will be reduced by half and here another half.

854
01:51:11,760 --> 01:51:17,760
 So you can see the image dimension here is or feature dimension here is reducing.

855
01:51:17,760 --> 01:51:28,760
 But at the same time, right, when my feature dimension is reducing, I definitely have discussed some information.

856
01:51:28,760 --> 01:51:34,760
 If my channel number is maintained.

857
01:51:34,760 --> 01:51:46,760
 In order to not to discuss too many information, so in the contract phase, right, so you can see here is 64 features.

858
01:51:46,760 --> 01:51:51,760
 But come here, you got 128 features.

859
01:51:51,760 --> 01:52:08,760
 So in the contract phase, we are reduced the image dimension, but increase the number of channels from 64 to 102 to 125, 256 and 512.

860
01:52:08,760 --> 01:52:23,760
 So here we are on the second phase, right, on the right side.

861
01:52:23,760 --> 01:52:30,760
 On the right side is, we call it expansion phase.

862
01:52:30,760 --> 01:52:35,760
 And here we are trying to create higher resolution mapping.

863
01:52:35,760 --> 01:52:45,760
 And this arrow here means we will take the map here to be appended here, so that some of the information can be maintained.

864
01:52:45,760 --> 01:52:52,760
 This overall structure called the unit.

865
01:52:52,760 --> 01:52:58,760
 It's look at the U-sheet, so this is why they are called unit.

866
01:52:58,760 --> 01:53:04,760
 So this is one of the basic structures for the image level simultaneously.

867
01:53:04,760 --> 01:53:19,760
 Of course, in the past 10 years, there are many, many different variations of the work that have been done to change the unit.

868
01:53:19,760 --> 01:53:30,760
 For example, we may do something here, and we can also add some units along this arrows.

869
01:53:30,760 --> 01:53:48,760
 So I'm not going to the different variation of the units, but I hope you at least know the unit.

870
01:53:48,760 --> 01:53:53,760
 So this is the meaning of the arrow.

871
01:53:53,760 --> 01:54:02,760
 So it's to concatenate the features here with the features here and in the outer here.

872
01:54:02,760 --> 01:54:17,760
 So this unit structure, you can use for sanitation, you can use for image generation, you can use for many other purposes.

873
01:54:17,760 --> 01:54:31,760
 So from high level understanding, right?

874
01:54:31,760 --> 01:54:45,760
 So in the concrete phase, we are reducing the spatial dimensions, but increasing the abstract levels, so-called work.

875
01:54:45,760 --> 01:55:06,760
 And in the expression phase, we are recovering the details and the dimensions, which actually equivalent to the various objects.

876
01:55:06,760 --> 01:55:28,760
 And we show that the research shows that concatenate the feature maps from the concrete phase will help to recover the location information.

877
01:55:28,760 --> 01:55:36,760
 So with some background on how the image sanitation is done.

878
01:55:36,760 --> 01:55:44,760
 Now let's look at what's the difference between image sanitation and view sanitation.

879
01:55:44,760 --> 01:55:58,760
 So this stack former is, I think it's one of the, because originally the unit is based on signal structure.

880
01:55:58,760 --> 01:56:02,760
 So in the recent years, there's new structure called transformers.

881
01:56:02,760 --> 01:56:08,760
 And based on transformers, they have designed a network called stack former.

882
01:56:08,760 --> 01:56:18,760
 So when stack former is applied to a video, right? So we are just applying sanitation on frame by frame, independent.

883
01:56:18,760 --> 01:56:27,760
 So the sanitation of the first frame and the second frame and third frame, they are totally independent.

884
01:56:27,760 --> 01:56:33,760
 We never consider the correlation between the conceptual frames.

885
01:56:33,760 --> 01:56:41,760
 And this cost to find future mining for video smelch is one of the approach in publishing CVPR.

886
01:56:41,760 --> 01:56:45,760
 And they have considered that frame to frame.

887
01:56:45,760 --> 01:56:49,760
 And this approach is actually from one of my colleagues.

888
01:56:49,760 --> 01:56:52,760
 I'm not sure whether they really publish the work or not.

889
01:56:52,760 --> 01:56:56,760
 But the results, you should better.

890
01:57:04,760 --> 01:57:09,760
 You watch the machine output.

891
01:57:09,760 --> 01:57:35,760
 You may see now, right? So there are some flickering, right?

892
01:57:35,760 --> 01:57:41,760
 So from one frame to another frame, the result is not stable, right?

893
01:57:41,760 --> 01:57:46,760
 And here is quite consistent here, but the center is not that good.

894
01:57:46,760 --> 01:57:51,760
 And here is very obvious, right?

895
01:57:51,760 --> 01:57:56,760
 So you can see that from for video sanitation, right?

896
01:57:56,760 --> 01:58:02,760
 So we will care about the consistency from one frame to another frame.

897
01:58:02,760 --> 01:58:15,760
 And the purely image based, you will have the jumping from one frame to another frame.

898
01:58:15,760 --> 01:58:24,760
 Of course, you can try to improve the sanitation of each individual frames.

899
01:58:24,760 --> 01:58:31,760
 With that accuracy, it will improve. You will get some improvement.

900
01:58:31,760 --> 01:58:36,760
 But unless you can achieve 100%, right, you will always face this kind of issue.

901
01:58:36,760 --> 01:58:48,760
 Whereas the sanitation boundaries or levels may be not that obvious, maybe near the borderline or not that clear case,

902
01:58:48,760 --> 01:58:53,760
 you will have this, we call it flickering artifact.

903
01:58:53,760 --> 01:58:58,760
 Whereas video, right, they are trying to solve these issues.

904
01:59:01,760 --> 01:59:16,760
 So this flickering artifact is repaint the one we see from one frame to another frame.

905
01:59:16,760 --> 01:59:25,760
 So of course, the potential solution is you can still based on image based sanitation,

906
01:59:25,760 --> 01:59:39,760
 but you try to apply some smoothing in continuous frames, right?

907
01:59:39,760 --> 01:59:43,760
 Here I am to show one of the videos.

908
01:59:43,760 --> 01:59:49,760
 Welcome to the world's first on device learning demo for temporarily consistent video segmentation,

909
01:59:49,760 --> 01:59:52,760
 presented by Qualcomm AI Research.

910
01:59:52,760 --> 01:59:59,760
 Semantic segmentation is a popular computer vision task that assigns every pixel of an image to a label.

911
01:59:59,760 --> 02:00:06,760
 It enables many emerging use cases, including autonomous driving, smart cameras and XR applications.

912
02:00:06,760 --> 02:00:14,760
 However, existing segmentation solutions often have flickering artifacts and lack temporal consistency between video frames.

913
02:00:14,760 --> 02:00:22,760
 Related work addressing these challenges still have limitations, including inaccurate temporal consistency between frames,

914
02:00:22,760 --> 02:00:38,760
 the lack of an accurate metric to model consistency and difficulty deploying real time on smartphones.

915
02:00:38,760 --> 02:00:45,760
 In this demo, we showcase consistent and robust video segmentation using on device learning.

916
02:00:45,760 --> 02:00:50,760
 To address the limitations of related work, we propose three solutions.

917
02:00:50,760 --> 02:00:55,760
 The first one is OGS ADAPT, our novel on device learning method.

918
02:00:55,760 --> 02:00:58,760
 OGS ADAPT consists of two networks.

919
02:00:58,760 --> 02:01:04,760
 First, a base network main net, which performs segmentation for the input video.

920
02:01:04,760 --> 02:01:11,760
 Second, a tiny auxiliary network OGS net, which accomplishes efficient on device learning.

921
02:01:11,760 --> 02:01:16,760
 Both outputs are combined to generate the final prediction and to update OGS net,

922
02:01:16,760 --> 02:01:22,760
 which in turn helps enhance the temporal consistency of the original output.

923
02:01:22,760 --> 02:01:32,760
 To enable real time adaptation on a smartphone, we utilize heterogeneous computing on snapdragon processors to distribute AI tasks to the DSP and GPU,

924
02:01:32,760 --> 02:01:36,760
 efficiently accelerating AI computations.

925
02:01:36,760 --> 02:01:40,760
 We also propose a novel temporal consistency metric.

926
02:01:40,760 --> 02:01:45,760
 It evaluates the similarity and perceptual features between two video frames.

927
02:01:45,760 --> 02:01:51,760
 Let's take a look at the results and see how our OGS ADAPT technique improves temporal consistency.

928
02:01:51,760 --> 02:01:56,760
 For the video frames without OGS ADAPT, you can see flickering in the base network output.

929
02:01:56,760 --> 02:02:00,760
 With OGS ADAPT, no flickering occurs.

930
02:02:00,760 --> 02:02:07,760
 Using our full stack AI research approach, we utilize hardware acceleration to efficiently run in parallel,

931
02:02:07,760 --> 02:02:15,760
 the OGS net model on the Qualcomm Adreno GPU and the main net model on the Qualcomm Hexagon processor.

932
02:02:15,760 --> 02:02:23,760
 With our optimizations, we reduce the inference time by over five times to 37 milliseconds and achieve real time performance.

933
02:02:23,760 --> 02:02:28,760
 Quantitatively, we show clear improvement in segmentation performance,

934
02:02:28,760 --> 02:02:33,760
 with temporal consistency and mean intersection over union scores increasing.

935
02:02:33,760 --> 02:02:40,760
 And this concludes the demonstration of our temporally consistent video semantic segmentation demo.

936
02:02:40,760 --> 02:02:51,760
 Stay tuned for more advances and efficient perception. Thanks for watching.

937
02:02:51,760 --> 02:02:56,760
 Okay, so because this course is about the machine vision, right?

938
02:02:56,760 --> 02:03:01,760
 So on the machine side, I just mentioned earlier, right?

939
02:03:01,760 --> 02:03:04,760
 Speed is one of the important things.

940
02:03:04,760 --> 02:03:14,760
 For video, you need to consider the special or time consistency or from frame to frame consistency.

941
02:03:14,760 --> 02:03:19,760
 But you also need to make sure this processing can be done in real time.

942
02:03:19,760 --> 02:03:30,760
 For video, right? So I remember when I do these things, like we normally need to process each frame within 50 milliseconds

943
02:03:30,760 --> 02:03:36,760
 or even a shorter time of 30 or 20 milliseconds.

944
02:03:36,760 --> 02:03:43,760
 And in terms of frame per frame rate, normally at least 10 frames per second,

945
02:03:43,760 --> 02:03:46,760
 you need to make sure your AI can be able to process that.

946
02:03:46,760 --> 02:03:53,760
 And this is not processing in your cloud GPU. You need to press in edge side.

947
02:03:53,760 --> 02:04:00,760
 And this is depending on the computing powers at the edge side.

948
02:04:17,760 --> 02:04:24,760
 So I see in China, right?

949
02:04:24,760 --> 02:04:34,760
 So they are doing a lot of things that's using automatic algorithms to detect, for example,

950
02:04:34,760 --> 02:04:37,760
 whether there are people doing that, jail working.

951
02:04:37,760 --> 02:04:41,760
 And this one lady was captured.

952
02:04:41,760 --> 02:04:43,760
 And they...

953
02:04:51,760 --> 02:05:01,760
 But they realize it's from out of place on the bus.

954
02:05:01,760 --> 02:05:04,760
 So the best way to try to...

955
02:05:04,760 --> 02:05:08,760
 I believe most of the people from China may know this lady, right?

956
02:05:08,760 --> 02:05:11,760
 It's from the Goli Air Con.

957
02:05:11,760 --> 02:05:14,760
 So they are doing advisement.

958
02:05:14,760 --> 02:05:16,760
 The lady's picture is there.

959
02:05:16,760 --> 02:05:26,760
 And when this bus is crossing the zebra and the zebra cross, right?

960
02:05:26,760 --> 02:05:32,760
 So they capture the images and they have a face recognition, recognize...

961
02:05:32,760 --> 02:05:36,760
 Oh, this is the lady.

962
02:05:36,760 --> 02:05:40,760
 And this is all the case of the...

963
02:05:40,760 --> 02:05:46,760
 It's actually done by detection and tracking and recognition.

964
02:05:46,760 --> 02:05:52,760
 And so you guess what has been missing?

965
02:05:52,760 --> 02:05:58,760
 Why they have this wrong detection?

966
02:05:58,760 --> 02:06:10,760
 So the first thing is...

967
02:06:10,760 --> 02:06:14,760
 Although the bus is moving, right?

968
02:06:14,760 --> 02:06:17,760
 The camera is maybe fixed.

969
02:06:17,760 --> 02:06:21,760
 But we can also consider this from the camera point of view.

970
02:06:21,760 --> 02:06:27,760
 And from the video and each frame, right?

971
02:06:27,760 --> 02:06:29,760
 It didn't...

972
02:06:29,760 --> 02:06:39,760
 It does not tell whether the video is taken from a real human or taken from a photo, right?

973
02:06:39,760 --> 02:06:40,760
 So this...

974
02:06:40,760 --> 02:06:48,760
 That's how people try to detect if I'm taking a video from a real person

975
02:06:48,760 --> 02:06:54,760
 or take a video from pictures.

976
02:06:54,760 --> 02:06:59,760
 So this is one potato issue that has been missing.

977
02:06:59,760 --> 02:07:03,760
 The second issue is...

978
02:07:03,760 --> 02:07:05,760
 For the 2D...

979
02:07:05,760 --> 02:07:07,760
 For the image that is 2D, right?

980
02:07:07,760 --> 02:07:13,760
 But if it's a real human, right, it should be a 3D structure, right?

981
02:07:13,760 --> 02:07:15,760
 So in reality, right?

982
02:07:15,760 --> 02:07:19,760
 So where we are doing object detection and tracking,

983
02:07:19,760 --> 02:07:23,760
 if we remember just now the video, right?

984
02:07:23,760 --> 02:07:25,760
 We may...

985
02:07:25,760 --> 02:07:28,760
 We remember the RID case, right?

986
02:07:28,760 --> 02:07:33,760
 We have a lady walking in that direction and you check along the lady, right?

987
02:07:33,760 --> 02:07:37,760
 And suddenly there are some blocks occlusion, right?

988
02:07:37,760 --> 02:07:41,760
 And therefore the tracker will lose the person

989
02:07:41,760 --> 02:07:46,760
 and actually detect the other person, right?

990
02:07:46,760 --> 02:07:48,760
 But in reality, right?

991
02:07:48,760 --> 02:07:52,760
 So this lady walking in that direction, yeah,

992
02:07:52,760 --> 02:07:57,760
 it will get far, far away from my cameras, right?

993
02:07:57,760 --> 02:08:00,760
 If we make use of this distance information,

994
02:08:00,760 --> 02:08:04,760
 you will know this lady suddenly disappears,

995
02:08:04,760 --> 02:08:09,760
 it will search in that direction with the same movement.

996
02:08:09,760 --> 02:08:14,760
 So 2D versus 3D is...

997
02:08:14,760 --> 02:08:18,760
 The real world is always 3D.

998
02:08:18,760 --> 02:08:24,760
 But our cameras is taking 2D information.

999
02:08:24,760 --> 02:08:29,760
 So our object detection and tracking is done by 2D images, not 3D.

1000
02:08:29,760 --> 02:08:36,760
 So this is one of the information missing.

1001
02:08:36,760 --> 02:08:43,760
 And in another case, possibly that can be used to correct this case is motion.

1002
02:08:43,760 --> 02:08:46,760
 So if this is a human, right?

1003
02:08:46,760 --> 02:08:49,760
 So I believe that in hard list,

1004
02:08:49,760 --> 02:08:52,760
 stung there are no movements, muscle.

1005
02:08:52,760 --> 02:08:55,760
 I definitely will move, my eyes will blink, right?

1006
02:08:55,760 --> 02:09:00,760
 But if there is a picture in the chain, in the bus, right?

1007
02:09:00,760 --> 02:09:04,760
 It won't have many movements.

1008
02:09:04,760 --> 02:09:07,760
 If there are any movements, it's because of the bus,

1009
02:09:07,760 --> 02:09:10,760
 and it's moved in the same directions.

1010
02:09:10,760 --> 02:09:15,760
 So this could be another scene.

1011
02:09:25,760 --> 02:09:32,760
 So this multi-verse that 3D is very, very important,

1012
02:09:32,760 --> 02:09:37,760
 and this will be the focus in the next two lectures.

1013
02:09:37,760 --> 02:10:02,760
 And for today, I want to play this video again,

1014
02:10:02,760 --> 02:10:08,760
 because at the time there is some issue with the sound.

1015
02:10:32,760 --> 02:10:48,760
 Some progress, at least within the small confines of the legal community,

1016
02:10:48,760 --> 02:10:50,760
 I think it's real important.

1017
02:10:50,760 --> 02:10:57,760
 President Barack Obama, when you're giving a speech,

1018
02:10:57,760 --> 02:11:01,760
 make sure you use a lot of pauses.

1019
02:11:01,760 --> 02:11:07,760
 America's businesses have created 14.5 million new jobs over 75 straight months.

1020
02:11:07,760 --> 02:11:09,760
 We're developing technology.

1021
02:11:09,760 --> 02:11:12,760
 Every technology can be used in some negative way,

1022
02:11:12,760 --> 02:11:16,760
 and so we all should work towards making sure that it's not going to happen.

1023
02:11:16,760 --> 02:11:22,760
 And one of the interesting directions is that once you know how to create something,

1024
02:11:22,760 --> 02:11:24,760
 you know how to reverse engineer it.

1025
02:11:24,760 --> 02:11:33,760
 And so one could create methods for identifying edited videos versus real videos.

1026
02:11:33,760 --> 02:11:41,760
 So this video was managed already,

1027
02:11:41,760 --> 02:11:49,760
 and at that time, this foundation model for video generation is still not popular yet.

1028
02:11:49,760 --> 02:11:53,760
 And it's popular only in these two years,

1029
02:11:53,760 --> 02:12:03,760
 and the generation of this fake video is not by a single foundation model.

1030
02:12:03,760 --> 02:12:09,760
 It's more based on... I try to mimic how the lips move.

1031
02:12:10,760 --> 02:12:15,760
 So I make sure the sound and the lip movement should be consistent,

1032
02:12:15,760 --> 02:12:24,760
 and make these lips look like the Obama's face.

1033
02:12:24,760 --> 02:12:29,760
 But now the... I think you can...

1034
02:12:29,760 --> 02:12:38,760
 I did see some of the videos in popular media,

1035
02:12:38,760 --> 02:12:45,760
 like TikTok and other places.

1036
02:12:45,760 --> 02:12:50,760
 You can see it's a fake video because the content doesn't make sense.

1037
02:12:50,760 --> 02:12:52,760
 What they say doesn't make sense.

1038
02:12:52,760 --> 02:12:59,760
 But if you don't look carefully, you actually can hardly see that that's the fake video.

1039
02:12:59,760 --> 02:13:07,760
 And the next lecture about the treaty, right?

1040
02:13:07,760 --> 02:13:13,760
 So it's actually connected with the videos and connected with the video generations,

1041
02:13:13,760 --> 02:13:22,760
 because the technology behind it is actually quite similar actually.

1042
02:13:22,760 --> 02:13:25,760
 And when we generate video, right?

1043
02:13:25,760 --> 02:13:31,760
 So we actually should consider the treaty aspect of the data.

1044
02:13:31,760 --> 02:13:38,760
 And now they are... I think in Singapore, they have spent some money to...

1045
02:13:38,760 --> 02:13:41,760
 to... got a deep fake.

1046
02:13:41,760 --> 02:13:50,760
 So at one time, you may have video be generated by AI artists, which could be a fake video.

1047
02:13:50,760 --> 02:13:53,760
 And in order to fight against that, right?

1048
02:13:53,760 --> 02:13:58,760
 So we need to develop technology that detects the fake video.

1049
02:13:58,760 --> 02:14:07,760
 Yeah, so I think that the technology of fake video could be one of the hot topics in the coming years.

1050
02:14:07,760 --> 02:14:12,760
 So if you... some of you may make a pie for PhD,

1051
02:14:12,760 --> 02:14:16,760
 or some of you may go for some study of the...

1052
02:14:16,760 --> 02:14:22,760
 as your research topic, you can look for such opportunities.

1053
02:14:28,760 --> 02:14:39,760
 Okay.

1054
02:14:39,760 --> 02:14:41,760
 There's still some... have some time.

1055
02:14:41,760 --> 02:14:51,760
 I think I may go some for the treaty today.

1056
02:14:51,760 --> 02:14:57,760
 And I don't think the slides haven't been shared on the course side yet, but I will share very soon.

1057
02:14:57,760 --> 02:15:03,760
 And I start a bit of the treaty today so that in the...

1058
02:15:03,760 --> 02:15:08,760
 especially in the last lecture, we can have some time to...

1059
02:15:08,760 --> 02:15:20,760
 to have a review and all the course and to highlight what are the important points in this subject.

1060
02:15:20,760 --> 02:15:26,760
 So in terms of treaty, right, there are many, many approaches for treaty.

1061
02:15:26,760 --> 02:15:30,760
 So one is time of flight.

1062
02:15:30,760 --> 02:15:40,760
 So I see it's like Microsoft Keynet, so they are using this kind of approach for treaty.

1063
02:15:40,760 --> 02:15:42,760
 And one is LIDAR.

1064
02:15:42,760 --> 02:15:46,760
 So LIDAR actually is a special form of time of flight.

1065
02:15:46,760 --> 02:15:54,760
 But the light frequency of LIDAR and the normal time of flight camera is different.

1066
02:15:54,760 --> 02:15:56,760
 Another is structural light.

1067
02:15:56,760 --> 02:16:00,760
 So that light is not a general uniform light.

1068
02:16:00,760 --> 02:16:05,760
 It's a light with structures of special patterns.

1069
02:16:05,760 --> 02:16:13,760
 And another one is called motion from structures and also the sterile.

1070
02:16:13,760 --> 02:16:20,760
 And with this course, right, so I will be more focused on motion from structures and the sterile.

1071
02:16:20,760 --> 02:16:25,760
 And these are more for your information only.

1072
02:16:33,760 --> 02:16:41,760
 So time of flight by the name, right, you can understand this.

1073
02:16:41,760 --> 02:16:43,760
 We have a light source.

1074
02:16:43,760 --> 02:16:51,760
 You check some light and reach an object and get a reflection and come back to the detector.

1075
02:16:51,760 --> 02:17:06,760
 And the time here will be the two times of distance divided by the speed of the light.

1076
02:17:06,760 --> 02:17:12,760
 So this approach, right, so you can imagine, right, so I have a light detector.

1077
02:17:12,760 --> 02:17:23,760
 It says that besides the light from this reflection, it can have light from other reflections or other light sources.

1078
02:17:23,760 --> 02:17:30,760
 So this is actually the major weakness of the light, time of flight cameras.

1079
02:17:30,760 --> 02:17:37,760
 So for example, the sunlight, the outdoor sunlight will affect this.

1080
02:17:37,760 --> 02:17:46,760
 And therefore the time of flight cameras now you can use, right, you cannot walk in outdoor.

1081
02:17:46,760 --> 02:17:50,760
 And even for indoor scenarios, it may fail.

1082
02:17:50,760 --> 02:17:53,760
 Let's say, of course, in this room it's okay.

1083
02:17:53,760 --> 02:18:02,760
 But if we have a window, very large window, right, the sun may come in, right, so it will affect.

1084
02:18:02,760 --> 02:18:11,760
 So when I was in my previous company, which is a robotic company, we developed humanoid robots

1085
02:18:11,760 --> 02:18:19,760
 and do some demos in a place where many guests come, right.

1086
02:18:19,760 --> 02:18:23,760
 And that place got a window, very big window.

1087
02:18:23,760 --> 02:18:32,760
 We do have cases, certainly robots cannot recognize because the camera is fair to walk.

1088
02:18:32,760 --> 02:18:38,760
 Yeah, so this is one of the limitations of the time of flight.

1089
02:18:38,760 --> 02:18:53,760
 Leida in full name is called light station and arranging.

1090
02:18:53,760 --> 02:18:57,760
 And it's a type of time of flight.

1091
02:18:57,760 --> 02:19:03,760
 But normally we don't call it camera, it's just Leida is called Leida.

1092
02:19:03,760 --> 02:19:07,760
 And it has two weakness.

1093
02:19:07,760 --> 02:19:14,760
 One is called Leida ghost, meaning my Leida is the time of flight.

1094
02:19:14,760 --> 02:19:22,760
 And my detector of the light, right, may detect some reflections or some steps, scatterings,

1095
02:19:22,760 --> 02:19:26,760
 and mistake that as an object like here.

1096
02:19:26,760 --> 02:19:28,760
 So you see the video?

1097
02:19:28,760 --> 02:19:32,760
 This actually is due to the reflections.

1098
02:19:32,760 --> 02:19:40,760
 Another case is called Leida blooming, meaning if we have some very strong reflective surface,

1099
02:19:40,760 --> 02:19:51,760
 and it will reflect very strong light, so it will be affecting the accuracy of Leida.

1100
02:19:51,760 --> 02:19:57,760
 And of course Leida also have issues in rain.

1101
02:19:57,760 --> 02:20:01,760
 So now the autonomous driving is quite popular.

1102
02:20:01,760 --> 02:20:05,760
 I think it's approaching commercial use.

1103
02:20:05,760 --> 02:20:15,760
 And I think the very early people are trying to use Leida.

1104
02:20:15,760 --> 02:20:20,760
 And I think the Tesla is trying to use pure camera based.

1105
02:20:20,760 --> 02:20:31,760
 So pure camera to face some issues, they cannot recognize the white vehicles versus the clouds,

1106
02:20:31,760 --> 02:20:34,760
 because all are white, they mistake as the clouds.

1107
02:20:34,760 --> 02:20:40,760
 But this is actually the vision recognition problem.

1108
02:20:40,760 --> 02:20:43,760
 But the Leida got a problem because of the rain.

1109
02:20:43,760 --> 02:20:50,760
 Because the rain will make the Leida light to attend very fast.

1110
02:20:50,760 --> 02:20:55,760
 So with that strong attenuation, it's a, it face an issue.

1111
02:20:55,760 --> 02:21:03,760
 But of course they are, those people work on the Leida, they are also trying to improve the Leida

1112
02:21:03,760 --> 02:21:09,760
 such that they can be robust or walk in rain conditions.

1113
02:21:17,760 --> 02:21:28,760
 And the structure light is a different way for the depth.

1114
02:21:28,760 --> 02:21:33,760
 So you can, I believe this case maybe not that easy to understand.

1115
02:21:33,760 --> 02:21:41,760
 But you just imagine my light inject to a hand, for example, is a special pattern.

1116
02:21:41,760 --> 02:21:47,760
 So we have different frequency or different colors at different place.

1117
02:21:47,760 --> 02:21:55,760
 So normally I have a uniform or different colors.

1118
02:21:55,760 --> 02:22:03,760
 But if I project this one to a surface with 3D surface, right, it will cause some distortion.

1119
02:22:03,760 --> 02:22:06,760
 What we look will be no longer be uniform.

1120
02:22:06,760 --> 02:22:16,760
 And based on the detection of the cameras, you will be able to calculate what's the distance from here to here.

1121
02:22:16,760 --> 02:22:25,760
 So these are the basic principles of these different depth cameras.

1122
02:22:25,760 --> 02:22:31,760
 So you don't need to understand how this is calculated.

1123
02:22:31,760 --> 02:22:35,760
 It's not really required for you.

1124
02:22:35,760 --> 02:22:42,760
 Unless you, in the future, you work on designing a new structure light, then you do work on that.

1125
02:22:42,760 --> 02:22:51,760
 But normally you just understand what's the principle of these different depth cameras and what's their beginnings.

1126
02:22:51,760 --> 02:22:57,760
 So the structure light also cannot work on outdoor because the sunlight is so strong.

1127
02:22:57,760 --> 02:23:02,760
 It's just no matter what color is, right, I have a sunlight, it's all bright.

1128
02:23:02,760 --> 02:23:04,760
 All the color is covered there.

1129
02:23:04,760 --> 02:23:07,760
 So there is all white.

1130
02:23:07,760 --> 02:23:11,760
 So your pattern will be disappearing.

1131
02:23:12,760 --> 02:23:33,760
 I think I will stop here because just now the three different depth sensors is for your information.

1132
02:23:33,760 --> 02:23:38,760
 And from next lecture, I will talk about the structure from motion.

1133
02:23:38,760 --> 02:23:44,760
 And then in the last lecture, I will talk about stereo, stereo matching.

1134
02:23:44,760 --> 02:23:56,760
 And the structure from motion and also the stereo matching, right, so they are quite similar principles.

1135
02:23:56,760 --> 02:24:02,760
 It's based on matching or all you can say is based on tracking.

1136
02:24:02,760 --> 02:24:06,760
 But today we did talk about object detection and tracking, right?

1137
02:24:06,760 --> 02:24:12,760
 And the structure from motion and the stereo matching, they are based on tracking of the features.

1138
02:24:12,760 --> 02:24:19,760
 In nowadays, I would like to use more appropriate words called key point.

1139
02:24:19,760 --> 02:24:29,760
 So, and to me, right, so next two lectures will be more important than today's lecture.

1140
02:24:29,760 --> 02:24:33,760
 And the first lecture I see is also important than today.

1141
02:24:33,760 --> 02:24:37,760
 Because today is seen for video recognition, right?

1142
02:24:37,760 --> 02:24:41,760
 So it's so similar to the object recognition.

1143
02:24:41,760 --> 02:24:46,760
 And in the AI, we have many different areas.

1144
02:24:46,760 --> 02:24:52,760
 And as a video recognition is one of the slowest areas in the development.

1145
02:24:52,760 --> 02:25:00,760
 So a lot of innovation like how a normal structure like transformer, how they are invented,

1146
02:25:00,760 --> 02:25:02,760
 it's not in the video recognition.

1147
02:25:02,760 --> 02:25:06,760
 It's in NLP, it's in image recognition.

1148
02:25:06,760 --> 02:25:15,760
 So that could be a one of the reasons is because the video sampling is one of the issues.

1149
02:25:15,760 --> 02:25:26,760
 It can hardly uniform the videos because the videos are sampling rate or how fast I move is one additional features.

1150
02:25:26,760 --> 02:25:35,760
 And this will make your recognition, changing the network much challenging because you have two dimensions,

1151
02:25:35,760 --> 02:25:38,760
 you have some data required.

1152
02:25:38,760 --> 02:25:41,760
 You have one more additional dimension of the data, right?

1153
02:25:42,760 --> 02:25:47,760
 Your data will be also increasing significantly.

1154
02:25:47,760 --> 02:25:49,760
 Okay, so that's all for today.

1155
02:25:49,760 --> 02:25:51,760
 So if you have any questions, you can approach me.

1156
02:26:11,760 --> 02:26:13,760
 Thank you.

1157
02:26:41,760 --> 02:26:43,760
 Thank you.

1158
02:27:11,760 --> 02:27:13,760
 Thank you.

