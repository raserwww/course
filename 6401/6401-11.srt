1
00:02:30,000 --> 00:02:37,000
 I think the question is, how do you start with the announcement again?

2
00:02:37,000 --> 00:02:44,000
 I will also send an end-to-learn announcement and also to the post.

3
00:02:44,000 --> 00:02:49,000
 So I think the quiz will be here next week.

4
00:02:49,000 --> 00:02:58,000
 Actually, maybe I want to get your feedback whether, because for my other course, 7402,

5
00:02:58,000 --> 00:03:03,000
 it will be this week, week 11.

6
00:03:03,000 --> 00:03:10,000
 So perhaps, do you feel, now it cannot change, but just say in the future,

7
00:03:10,000 --> 00:03:20,000
 I'm thinking about bringing to week 11 maybe better because we also finished the first two chapters.

8
00:03:20,000 --> 00:03:22,000
 There is a time.

9
00:03:22,000 --> 00:03:34,000
 I also want to make it clear if, since this quiz day is being set from the very beginning.

10
00:03:34,000 --> 00:03:45,000
 So if you are going for say job interview or some other reason you should arrange it on another day.

11
00:03:45,000 --> 00:03:52,000
 So don't use that to, and it's very late to change.

12
00:03:52,000 --> 00:03:59,000
 Anyway, week 12. There's no much time left.

13
00:03:59,000 --> 00:04:07,000
 So other than the contents which I already narrowed down somewhat,

14
00:04:07,000 --> 00:04:19,000
 we'll see perhaps end of today or leave some time for consultation for some students who still have some difficulty.

15
00:04:19,000 --> 00:04:28,000
 And then I add two more things which is applied to the other course.

16
00:04:28,000 --> 00:04:34,000
 So there will be the quiz question, not difficult.

17
00:04:34,000 --> 00:04:36,000
 I can show you.

18
00:04:36,000 --> 00:04:38,000
 There's no multiple choice.

19
00:04:38,000 --> 00:04:48,000
 There will be short answer or draw some program which are considered simple or some simple calculation.

20
00:04:49,000 --> 00:05:02,000
 But there will be some simple numerical calculation, not very complicated, but some numerical value.

21
00:05:02,000 --> 00:05:11,000
 So you'll need to bring calculators, probably just summation or those simple ones.

22
00:05:11,000 --> 00:05:17,000
 Anyway, same as you go for the final exam, so you also need to bring this.

23
00:05:17,000 --> 00:05:22,000
 So bring your student matriculation card with you.

24
00:05:22,000 --> 00:05:28,000
 I have a few student helper systems to check.

25
00:05:28,000 --> 00:05:36,000
 They will sit every alternative seat, not next to each other.

26
00:05:36,000 --> 00:05:41,000
 The LTE has enough seats for the whole class.

27
00:05:41,000 --> 00:05:44,000
 Also try to come before 7.50.

28
00:05:44,000 --> 00:05:49,000
 For those already attending the first lecture, there will be no problem.

29
00:05:49,000 --> 00:06:00,000
 And broadcasting for the other students who are not here, then you'll have to make sure we will be one hour sharp.

30
00:06:00,000 --> 00:06:09,000
 So that's about the quiz will be next week.

31
00:06:09,000 --> 00:06:17,000
 So today we will still go for the normal lecture.

32
00:06:17,000 --> 00:06:27,000
 We'll continue with the last chapter which probably similar to chapter 2.

33
00:06:28,000 --> 00:06:35,000
 I will try to make it easier to understand.

34
00:06:35,000 --> 00:06:42,000
 In the lecture now I also provide some spec ground for the part.

35
00:06:42,000 --> 00:06:45,000
 So we'll go into that later.

36
00:06:45,000 --> 00:06:53,000
 So today we cover maybe 2.30 of the chapter 3.

37
00:06:54,000 --> 00:07:11,000
 But before going for that, I want to discuss a little bit on the IIR filter.

38
00:07:11,000 --> 00:07:19,000
 So this is...

39
00:07:19,000 --> 00:07:28,000
 Let me use the 2.1.com because I have some hard copy with me.

40
00:07:28,000 --> 00:07:38,000
 So this one I can show the lecture notes which can explain better.

41
00:07:38,000 --> 00:07:47,000
 Let's turn on this one first.

42
00:07:47,000 --> 00:08:00,000
 Okay, so let's move on to this.

43
00:08:00,000 --> 00:08:09,000
 Also this IIR filter, I am not included in the quiz.

44
00:08:09,000 --> 00:08:18,000
 But I should say this part is probably the most difficult part.

45
00:08:18,000 --> 00:08:29,000
 It combines most of the ingredients in this part 2 into this example.

46
00:08:29,000 --> 00:08:38,000
 So if you try to understand this part better such as weekly, stationary,

47
00:08:38,000 --> 00:08:48,000
 and also the conversion including the IIR filter and impulse response,

48
00:08:48,000 --> 00:08:58,000
 cross correlation, auto correlation, and even in the sense a little bit about power spectrum density.

49
00:08:58,000 --> 00:09:03,000
 Because we did introduce in chapter 1.

50
00:09:03,000 --> 00:09:09,000
 So that's part of the basic but not the estimation.

51
00:09:09,000 --> 00:09:14,000
 So let's see what we can do here.

52
00:09:14,000 --> 00:09:22,000
 Because this part, to be honest, I also spent quite some time to digest this together.

53
00:09:22,000 --> 00:09:27,000
 Go back to the understanding of this one.

54
00:09:27,000 --> 00:09:38,000
 The winner of the equation here is similar to what we derived earlier for the IIR,

55
00:09:38,000 --> 00:09:44,000
 but now we extend it to infinity.

56
00:09:44,000 --> 00:09:49,000
 You see, because IIR has an infinity impulse response.

57
00:09:49,000 --> 00:10:06,000
 If you look at the edge of k here, you will need to have infinity of many of the parameters.

58
00:10:06,000 --> 00:10:15,000
 That was why IIR filters, in general, you will be much more difficult.

59
00:10:15,000 --> 00:10:18,000
 Also in some parts, it's efficient.

60
00:10:18,000 --> 00:10:26,000
 Actually in this case, when IIR filters later, you will see if you restrict it to be causal.

61
00:10:26,000 --> 00:10:31,000
 But here I also clarify the concept of being causal or not causal.

62
00:10:31,000 --> 00:10:37,000
 If being causal, then IIR filter has infinity many tabs,

63
00:10:37,000 --> 00:10:41,000
 but in the end it turns out to be just a little bit better than ever.

64
00:10:41,000 --> 00:10:46,000
 So allowing it to be no causal, which is not included here,

65
00:10:46,000 --> 00:10:52,000
 but if you go to the book, you can find out it will be much better.

66
00:10:52,000 --> 00:10:59,000
 Also, no causal in real life, you cannot do it in real time.

67
00:10:59,000 --> 00:11:06,000
 So you can do it offline, just like you are doing neural network machining,

68
00:11:06,000 --> 00:11:11,000
 you can do all the data that you are doing offline processing.

69
00:11:11,000 --> 00:11:16,000
 Coming back to here, we now extend this.

70
00:11:16,000 --> 00:11:22,000
 The main difference is, once you have infinity many equations, infinity many parameters,

71
00:11:22,000 --> 00:11:28,000
 you cannot use a metric for finite number of equations,

72
00:11:29,000 --> 00:11:32,000
 theory is very powerful.

73
00:11:32,000 --> 00:11:35,000
 That was my next chapter.

74
00:11:35,000 --> 00:11:43,000
 We will talk about some finite number of equations using metrics analysis.

75
00:11:43,000 --> 00:11:47,000
 But here you have to extend to infinity.

76
00:11:47,000 --> 00:11:53,000
 Then the mean square value of the arrow is the same way as the desired value of the one.

77
00:11:54,000 --> 00:12:03,000
 Even if you have infinity IR filter, you still cannot get to the desired level.

78
00:12:03,000 --> 00:12:06,000
 The estimate cannot, so there is always an error.

79
00:12:06,000 --> 00:12:20,000
 So I am here to minimize the so-called mean square error.

80
00:12:20,000 --> 00:12:25,000
 Then it is the same as before.

81
00:12:25,000 --> 00:12:30,000
 So we end up with this set of linear whole equation.

82
00:12:30,000 --> 00:12:37,000
 Then, assuming this is solved, then we can also get the corresponding minimum MSC.

83
00:12:37,000 --> 00:12:43,000
 Because we are dealing with causal, that is the difficulty here.

84
00:12:43,000 --> 00:12:55,000
 They will require the impulse, infinity impulse response is only from zero to the right half.

85
00:12:55,000 --> 00:13:02,000
 If you allow no causal, then you will have the equation here, finite infinity to infinity.

86
00:13:02,000 --> 00:13:05,000
 Then there is a match where the Z transforms.

87
00:13:05,000 --> 00:13:09,000
 So it is much easier to get no causal inner filter.

88
00:13:09,000 --> 00:13:12,000
 You don't need to go through all these difficulties.

89
00:13:13,000 --> 00:13:19,000
 So here, there is a problem here, so we cannot take directly using the Z transform.

90
00:13:19,000 --> 00:13:29,000
 So therefore, this is why, you see, last week I already discussed part of it.

91
00:13:29,000 --> 00:13:36,000
 So you see here, for the inner filter or for even no causal filter, you see we don't need this part.

92
00:13:36,000 --> 00:13:41,000
 From hn is given, the measure data, then this is the desired level one.

93
00:13:41,000 --> 00:13:49,000
 So we can get auto-correlation, function, power spectrum and so on.

94
00:13:49,000 --> 00:13:51,000
 So it's easily solved.

95
00:13:51,000 --> 00:13:54,000
 Cross-correlation can also get.

96
00:13:54,000 --> 00:14:07,000
 But however, the problem here is, as I already mentioned, the equation is only restricted to be causal.

97
00:14:07,000 --> 00:14:14,000
 So you cannot use the FIR filter approach nor the no causal IR filter.

98
00:14:14,000 --> 00:14:16,000
 And that was right here.

99
00:14:16,000 --> 00:14:26,000
 It's also very good because you learn better about why we introduced this innovation representation.

100
00:14:26,000 --> 00:14:28,000
 Because we follow this, you see.

101
00:14:28,000 --> 00:14:31,000
 hn is the one we measure.

102
00:14:31,000 --> 00:14:39,000
 It's a weekly stationary, sometimes we call it white-sink, stationary written process.

103
00:14:39,000 --> 00:14:48,000
 So from here, we introduce this inverse filter because this one is generated by white noise

104
00:14:48,000 --> 00:14:55,000
 go through this, go through a filter.

105
00:14:55,000 --> 00:15:05,000
 Then the inverse is if you look this as input, you will generate this WAN using an inverse filter.

106
00:15:05,000 --> 00:15:17,000
 So this concept turned out to be very useful in injecting this white noise so that you can consider

107
00:15:17,000 --> 00:15:24,000
 you have overall system because in Z domain, you all know your cascade tool subsystem.

108
00:15:24,000 --> 00:15:27,000
 So this is overall one, then overall one.

109
00:15:27,000 --> 00:15:36,000
 You also have the, because we assume the filter here, all the these two filter, they are all causal.

110
00:15:36,000 --> 00:15:43,000
 So this is the corresponding impulse response.

111
00:15:43,000 --> 00:15:57,000
 And then from here, you see, because the D and W, this white noise, W32, you can consider this as input-output relationship.

112
00:15:57,000 --> 00:15:59,000
 So this is input.

113
00:15:59,000 --> 00:16:02,000
 Then goes through this impulse response.

114
00:16:02,000 --> 00:16:05,000
 Just like a filter, you will generate this.

115
00:16:05,000 --> 00:16:16,000
 So therefore, in order to get this, we apply what we learned before, also going to be principle.

116
00:16:16,000 --> 00:16:24,000
 Then you also set, you have the similar equation which satisfies that.

117
00:16:24,000 --> 00:16:26,000
 There's no problem.

118
00:16:26,000 --> 00:16:36,000
 And here, the important one is this one auto correlation sometimes you use 1W, and I use 2W.

119
00:16:36,000 --> 00:16:38,000
 So that will be the same.

120
00:16:38,000 --> 00:16:43,000
 It's a unique impulse function.

121
00:16:43,000 --> 00:16:47,000
 So from here, we already simplified.

122
00:16:47,000 --> 00:16:54,000
 You can work out because there are infinite many terms, but only one of them, not zero, equal to one.

123
00:16:54,000 --> 00:16:56,000
 So you pick up this.

124
00:16:56,000 --> 00:17:04,000
 So that means this QM happened to be equal to this causal relation.

125
00:17:04,000 --> 00:17:12,000
 So therefore, our QZ, you see, is the one, you will be the impulse response.

126
00:17:12,000 --> 00:17:19,000
 Once we assume we know QK, then you can get this.

127
00:17:19,000 --> 00:17:24,000
 And we already know the relationship of this QK and this.

128
00:17:24,000 --> 00:17:30,000
 And then, so this is another very important concept.

129
00:17:30,000 --> 00:17:38,000
 Auto correlation or cross correlation, they are always two-sided.

130
00:17:38,000 --> 00:17:46,000
 Even if you start with sequence, you see, for example, input sequence X of n, the input signal,

131
00:17:46,000 --> 00:17:58,000
 from zero to infinity is equal to zero for negative n, so-called causal signal.

132
00:17:58,000 --> 00:18:07,000
 But then, if you do the auto correlation, the auto correlation function will always be symmetry.

133
00:18:07,000 --> 00:18:11,000
 You will always go to two sides.

134
00:18:11,000 --> 00:18:20,000
 So do a convolution with two causal signals or the signal combo itself.

135
00:18:20,000 --> 00:18:26,000
 You will get the causal signal output.

136
00:18:26,000 --> 00:18:33,000
 That was why, sometimes, as I told you, I'm teaching the undergraduate signaling system,

137
00:18:33,000 --> 00:18:36,000
 so students always confuse these two.

138
00:18:36,000 --> 00:18:46,000
 They look very similar, but the results are quite different, particularly involving causal and no causal.

139
00:18:46,000 --> 00:18:52,000
 So therefore, this one will require the filter to be causal,

140
00:18:52,000 --> 00:19:01,000
 but the cross correlation of these two signals is always no causal.

141
00:19:01,000 --> 00:19:05,000
 It will have two sides.

142
00:19:05,000 --> 00:19:16,000
 So therefore, we will get the Z-transform of this, but only take the causal part.

143
00:19:16,000 --> 00:19:26,000
 So now, the next thing is, we can just similar to the FIAR filter one.

144
00:19:26,000 --> 00:19:30,000
 We can get this cross correlation of D and X.

145
00:19:30,000 --> 00:19:37,000
 That's available, but not this one, because we don't know the...

146
00:19:37,000 --> 00:19:48,000
 You see, we have D, but the Y-noise, we do not have direct information.

147
00:19:48,000 --> 00:19:57,000
 But however, you see here, this is the beauty of the innovation representation.

148
00:19:57,000 --> 00:20:00,000
 We know this X-n.

149
00:20:00,000 --> 00:20:06,000
 From X-n, we do the power spectrum factorization.

150
00:20:06,000 --> 00:20:08,000
 We can get the GZ.

151
00:20:08,000 --> 00:20:16,000
 So that's why this one we can derive from X-n through this inverse filter.

152
00:20:16,000 --> 00:20:18,000
 We know GZ.

153
00:20:18,000 --> 00:20:21,000
 Then one of the GZ will get this.

154
00:20:21,000 --> 00:20:31,000
 So at least in the Z domain, we can do it very easily.

155
00:20:31,000 --> 00:20:34,000
 So why here the lecture note, we do not go into detail.

156
00:20:34,000 --> 00:20:40,000
 We just say because this part again involves a few more difficult derivations.

157
00:20:40,000 --> 00:20:51,000
 So this one in the end, it turns out to be related to this DX through this GZ-n.

158
00:20:51,000 --> 00:20:55,000
 So very briefly, you may think about...

159
00:20:55,000 --> 00:20:57,000
 Also, it's not exactly the same.

160
00:20:57,000 --> 00:21:04,000
 You may think about this is we want to know the causal relation between these two,

161
00:21:04,000 --> 00:21:06,000
 but we already know this part.

162
00:21:06,000 --> 00:21:11,000
 So you may think about this one from here to here,

163
00:21:11,000 --> 00:21:16,000
 it could be just something like the product of this one,

164
00:21:16,000 --> 00:21:22,000
 not about this one, so that you can divide in the same this part.

165
00:21:22,000 --> 00:21:25,000
 But it turns out to be very close to that,

166
00:21:25,000 --> 00:21:30,000
 but you divide G to the negative power.

167
00:21:30,000 --> 00:21:34,000
 Your inverse filter also changes the argument.

168
00:21:34,000 --> 00:21:39,000
 So let's see this part how we are going to derive.

169
00:21:39,000 --> 00:21:44,000
 So I can show you here.

170
00:21:44,000 --> 00:21:47,000
 Okay, so because it may take quite some time to write,

171
00:21:47,000 --> 00:21:57,000
 so I prepare this one here.

172
00:21:57,000 --> 00:22:00,000
 So this is the part where...

173
00:22:00,000 --> 00:22:05,000
 You can see it clearly or not.

174
00:22:05,000 --> 00:22:09,000
 So this is a continuing from this page.

175
00:22:09,000 --> 00:22:13,000
 One...

176
00:22:13,000 --> 00:22:15,000
 Do I get it right?

177
00:22:15,000 --> 00:22:18,000
 Yeah, one should be 126.

178
00:22:18,000 --> 00:22:21,000
 Maybe using a different...

179
00:22:21,000 --> 00:22:23,000
 I'm using a different version.

180
00:22:23,000 --> 00:22:25,000
 So anyway, it was...

181
00:22:25,000 --> 00:22:27,000
 Okay, should be right.

182
00:22:27,000 --> 00:22:30,000
 So 126 is this one.

183
00:22:30,000 --> 00:22:35,000
 126 is equation one for five years.

184
00:22:35,000 --> 00:22:37,000
 Okay.

185
00:22:37,000 --> 00:22:39,000
 So how do we derive that?

186
00:22:39,000 --> 00:22:44,000
 We can divide here.

187
00:22:44,000 --> 00:22:47,000
 You see this is the one over here,

188
00:22:47,000 --> 00:22:51,000
 the inverse filter or y turning filter.

189
00:22:51,000 --> 00:22:55,000
 So we call that as V of Z.

190
00:22:55,000 --> 00:22:57,000
 Maybe I...

191
00:22:57,000 --> 00:22:59,000
 I think here.

192
00:22:59,000 --> 00:23:01,000
 Yeah, okay, you see better.

193
00:23:01,000 --> 00:23:03,000
 Yeah, V of Z equal to one over there.

194
00:23:03,000 --> 00:23:06,000
 Then this is also a filter, you see.

195
00:23:06,000 --> 00:23:10,000
 We assume this is a minimum phase.

196
00:23:10,000 --> 00:23:12,000
 Then you can also...

197
00:23:12,000 --> 00:23:13,000
 It's a causal filter.

198
00:23:13,000 --> 00:23:15,000
 You can explain to that.

199
00:23:15,000 --> 00:23:16,000
 Right?

200
00:23:16,000 --> 00:23:20,000
 So therefore, from the...

201
00:23:20,000 --> 00:23:24,000
 to the white noise related to this,

202
00:23:24,000 --> 00:23:28,000
 because here we consider X,

203
00:23:28,000 --> 00:23:30,000
 if you look at the diagram,

204
00:23:30,000 --> 00:23:33,000
 the X of N is the input signal.

205
00:23:33,000 --> 00:23:36,000
 We generate this WN filter

206
00:23:36,000 --> 00:23:38,000
 through this transfer function, you see.

207
00:23:38,000 --> 00:23:39,000
 It's inverse.

208
00:23:39,000 --> 00:23:43,000
 So therefore, this is the convolution,

209
00:23:43,000 --> 00:23:45,000
 filter convolution.

210
00:23:45,000 --> 00:23:48,000
 And then based on the cross correlation definition,

211
00:23:48,000 --> 00:23:52,000
 you see, this is the one we are going to get.

212
00:23:52,000 --> 00:23:54,000
 D, we got cross correlation though.

213
00:23:54,000 --> 00:23:56,000
 All the will be different.

214
00:23:56,000 --> 00:23:59,000
 If you start with D and W trade though,

215
00:23:59,000 --> 00:24:01,000
 you will be 50 N.

216
00:24:01,000 --> 00:24:03,000
 And then this one, assume it could be complex.

217
00:24:03,000 --> 00:24:05,000
 So you take the conjugate

218
00:24:05,000 --> 00:24:09,000
 and the delay will be N minus K here.

219
00:24:09,000 --> 00:24:10,000
 Okay.

220
00:24:10,000 --> 00:24:14,000
 So therefore, from here, this is the expectation,

221
00:24:14,000 --> 00:24:16,000
 leaving a random signal.

222
00:24:16,000 --> 00:24:18,000
 And then you substitute this.

223
00:24:18,000 --> 00:24:21,000
 You see our W trade though, you see.

224
00:24:21,000 --> 00:24:23,000
 This is a convolution.

225
00:24:23,000 --> 00:24:26,000
 From here, you put in N.

226
00:24:26,000 --> 00:24:28,000
 And then also remember,

227
00:24:28,000 --> 00:24:31,000
 you need to minus K here.

228
00:24:31,000 --> 00:24:37,000
 So and the index will change to...

229
00:24:37,000 --> 00:24:41,000
 Yeah, this index will change to M

230
00:24:41,000 --> 00:24:43,000
 to not confuse with K.

231
00:24:43,000 --> 00:24:44,000
 So this...

232
00:24:44,000 --> 00:24:45,000
 Okay.

233
00:24:45,000 --> 00:24:50,000
 And then after that, we can see

234
00:24:50,000 --> 00:24:57,000
 now this is the cross correlation between D and X,

235
00:24:57,000 --> 00:24:59,000
 because we already have X.

236
00:24:59,000 --> 00:25:03,000
 And then now, but the argument is K plus N

237
00:25:03,000 --> 00:25:07,000
 because you are N minus K plus N.

238
00:25:07,000 --> 00:25:10,000
 So from here,

239
00:25:10,000 --> 00:25:12,000
 we know this is the...

240
00:25:12,000 --> 00:25:16,000
 still in the time domain, the sequence.

241
00:25:16,000 --> 00:25:18,000
 And as I say, this one is...

242
00:25:18,000 --> 00:25:22,000
 the cross correlation is from mining 50 to infinity.

243
00:25:22,000 --> 00:25:26,000
 So you can take two sides, Z transform of that.

244
00:25:26,000 --> 00:25:27,000
 Okay.

245
00:25:27,000 --> 00:25:28,000
 All right.

246
00:25:28,000 --> 00:25:29,000
 You'll be doing that.

247
00:25:29,000 --> 00:25:32,000
 Let me see whether my...

248
00:25:32,000 --> 00:25:40,000
 can use this to...

249
00:25:40,000 --> 00:25:44,000
 So this one I shift continuing.

250
00:25:44,000 --> 00:25:45,000
 The Z transform.

251
00:25:45,000 --> 00:25:49,000
 It's a rather long...

252
00:25:49,000 --> 00:25:50,000
 Okay.

253
00:25:50,000 --> 00:25:53,000
 I think that...

254
00:25:53,000 --> 00:25:54,000
 Yeah, that's the work.

255
00:25:54,000 --> 00:25:58,000
 And then...

256
00:25:58,000 --> 00:26:03,000
 Now from here, you see?

257
00:26:03,000 --> 00:26:05,000
 So the Z transform, you put...

258
00:26:05,000 --> 00:26:09,000
 This is the cross correlation.

259
00:26:09,000 --> 00:26:10,000
 Okay.

260
00:26:10,000 --> 00:26:12,000
 You'll put the D and W,

261
00:26:12,000 --> 00:26:14,000
 and then you put the Z.

262
00:26:14,000 --> 00:26:15,000
 Parking in.

263
00:26:15,000 --> 00:26:16,000
 You...

264
00:26:16,000 --> 00:26:17,000
 Yeah.

265
00:26:17,000 --> 00:26:20,000
 You do this, the Z transform.

266
00:26:20,000 --> 00:26:22,000
 And this is in the...

267
00:26:22,000 --> 00:26:24,000
 in Z domain, you see?

268
00:26:24,000 --> 00:26:28,000
 Because that's the definition of two-side Z transform.

269
00:26:28,000 --> 00:26:29,000
 And after that,

270
00:26:29,000 --> 00:26:30,000
 now you have to be careful

271
00:26:30,000 --> 00:26:33,000
 because there are two summations.

272
00:26:33,000 --> 00:26:35,000
 I can...

273
00:26:35,000 --> 00:26:40,000
 I can switch the double summation.

274
00:26:40,000 --> 00:26:45,000
 Now I make this M, the summation M, outside.

275
00:26:45,000 --> 00:26:48,000
 But because this part is in both M, you see?

276
00:26:48,000 --> 00:26:52,000
 So you cannot very easily break into two.

277
00:26:52,000 --> 00:26:54,000
 Then you will have some problem.

278
00:26:54,000 --> 00:26:59,000
 So as long as you have this argument of this...

279
00:26:59,000 --> 00:27:02,000
 It's depending on the index, you have to put break.

280
00:27:02,000 --> 00:27:04,000
 So I emphasize this is the whole thing.

281
00:27:04,000 --> 00:27:05,000
 Okay.

282
00:27:05,000 --> 00:27:08,000
 And then I do a variable change, you see?

283
00:27:08,000 --> 00:27:11,000
 Because we want to make this K plus M,

284
00:27:11,000 --> 00:27:13,000
 I call it K prime.

285
00:27:13,000 --> 00:27:14,000
 Okay.

286
00:27:14,000 --> 00:27:17,000
 Then if your case change this,

287
00:27:17,000 --> 00:27:18,000
 it will not affect the sum

288
00:27:18,000 --> 00:27:20,000
 because infinity to infinity,

289
00:27:20,000 --> 00:27:24,000
 whether you add or subtract, you know,

290
00:27:24,000 --> 00:27:26,000
 find a number, it will not change.

291
00:27:26,000 --> 00:27:29,000
 But however this K change, you see?

292
00:27:29,000 --> 00:27:30,000
 Okay.

293
00:27:30,000 --> 00:27:32,000
 Now I want to change K to K prime.

294
00:27:32,000 --> 00:27:33,000
 So that you have this.

295
00:27:33,000 --> 00:27:35,000
 Now this is very important.

296
00:27:35,000 --> 00:27:39,000
 This one, I want to get the proper J transform of that.

297
00:27:39,000 --> 00:27:45,000
 You have to remove, I mean, in the exponent, the summation,

298
00:27:45,000 --> 00:27:47,000
 you can make it a product.

299
00:27:47,000 --> 00:27:51,000
 So minus and minus becomes Z to the power K.

300
00:27:51,000 --> 00:27:54,000
 So this one I can take out of this

301
00:27:54,000 --> 00:27:57,000
 because this part is independent of the K prime.

302
00:27:57,000 --> 00:28:02,000
 So whenever you do the summation manipulation, always check.

303
00:28:02,000 --> 00:28:07,000
 That was in the 7402, the assignment sum,

304
00:28:07,000 --> 00:28:10,000
 student make this kind of mistake.

305
00:28:10,000 --> 00:28:13,000
 So therefore if you do that,

306
00:28:13,000 --> 00:28:17,000
 now properly JM, you bring outside.

307
00:28:17,000 --> 00:28:20,000
 So what led this is a proper J transform, you know?

308
00:28:20,000 --> 00:28:24,000
 And this one now, this whole thing is independent of M, you see?

309
00:28:24,000 --> 00:28:26,000
 You already managed.

310
00:28:26,000 --> 00:28:28,000
 You cannot bring the M from here

311
00:28:28,000 --> 00:28:30,000
 because that's inside argument.

312
00:28:30,000 --> 00:28:35,000
 So you need to change the argument and then J of M is a multiplication

313
00:28:35,000 --> 00:28:36,000
 you can bring out.

314
00:28:36,000 --> 00:28:38,000
 J of M is independent of K, you bring out.

315
00:28:38,000 --> 00:28:43,000
 So now once you bring out this, depending on M, this depending on K.

316
00:28:43,000 --> 00:28:46,000
 So it becomes a product of the two.

317
00:28:46,000 --> 00:28:48,000
 And it's just having to be nice.

318
00:28:48,000 --> 00:28:53,000
 This is the J transform of this, but the J is to,

319
00:28:53,000 --> 00:28:59,000
 not to the minor negative power, but positive power.

320
00:28:59,000 --> 00:29:03,000
 So you will have to change argument to J to the power minus one.

321
00:29:03,000 --> 00:29:10,000
 Because our definition is your argument J corresponding to J to the power minus one, minus two.

322
00:29:10,000 --> 00:29:13,000
 So it's out of the round.

323
00:29:13,000 --> 00:29:16,000
 So therefore this is one part.

324
00:29:16,000 --> 00:29:18,000
 And this one is just nice.

325
00:29:18,000 --> 00:29:23,000
 It will be what we already, we can get this.

326
00:29:23,000 --> 00:29:24,000
 There's no problem.

327
00:29:24,000 --> 00:29:26,000
 So therefore we get this.

328
00:29:26,000 --> 00:29:29,000
 And so therefore finally this is one we are going to have.

329
00:29:29,000 --> 00:29:35,000
 And it will be related to G by one of the J.

330
00:29:35,000 --> 00:29:40,000
 But now J is the argument is changed to J to the power minus one.

331
00:29:40,000 --> 00:29:43,000
 So therefore this one you know, this one you also know.

332
00:29:43,000 --> 00:29:46,000
 So from here you can get this.

333
00:29:46,000 --> 00:29:51,000
 So you can see this whole derivation involved.

334
00:29:51,000 --> 00:30:01,000
 So almost all the ingredients that we have learned across correlation, spectrum factorization,

335
00:30:01,000 --> 00:30:07,000
 and minimum phase, causal filter, and so on.

336
00:30:07,000 --> 00:30:10,000
 So this is finished this part.

337
00:30:10,000 --> 00:30:14,000
 So I hope you can follow.

338
00:30:14,000 --> 00:30:19,000
 And then you can see also the example we already showed.

339
00:30:19,000 --> 00:30:24,000
 But actually one student asked this question.

340
00:30:24,000 --> 00:30:33,000
 I think it's interesting, but it's important to highlight here because we say in this case,

341
00:30:33,000 --> 00:30:36,000
 I think we involve J and J to the power minus one.

342
00:30:36,000 --> 00:30:40,000
 You have to manage to separate into some of two.

343
00:30:40,000 --> 00:30:42,000
 One is the causal factor.

344
00:30:42,000 --> 00:30:46,000
 One is involving totally J is the anti-causal.

345
00:30:46,000 --> 00:30:52,000
 Usually it will be very hard if you are in the signal processing operation,

346
00:30:52,000 --> 00:30:57,000
 you either do the causal filtering or anti-causal.

347
00:30:57,000 --> 00:30:59,000
 It's totally non-causal.

348
00:30:59,000 --> 00:31:03,000
 So therefore these two parts are different.

349
00:31:03,000 --> 00:31:05,000
 You have to do it separately.

350
00:31:05,000 --> 00:31:12,000
 But one student question is mathematically by multiplying this by J to the power minus one.

351
00:31:12,000 --> 00:31:15,000
 That was asked by a student.

352
00:31:15,000 --> 00:31:19,000
 Then this one becomes, you see here.

353
00:31:19,000 --> 00:31:27,000
 That's why sometimes when you try to get both in zero, you are not doing processing.

354
00:31:27,000 --> 00:31:29,000
 Then it's quite good.

355
00:31:29,000 --> 00:31:34,000
 You always change the J to the positive power and you solve the equation.

356
00:31:34,000 --> 00:31:39,000
 But it will be confused if you change the J to the power minus one.

357
00:31:39,000 --> 00:31:42,000
 Then this one also becomes a causal factor.

358
00:31:42,000 --> 00:31:50,000
 That's why I prepare another two slides to show this, to see the difference.

359
00:31:50,000 --> 00:31:56,000
 From here you also probably will get a good understanding of the causal, no causal factor

360
00:31:56,000 --> 00:32:02,000
 because that's part of our requirement here.

361
00:32:02,000 --> 00:32:09,000
 So this is the question I think.

362
00:32:09,000 --> 00:32:14,000
 Can I just do the simple multiplication numerator and denominator

363
00:32:14,000 --> 00:32:21,000
 then change into this new filter?

364
00:32:21,000 --> 00:32:27,000
 I simplify because this one involves this coefficient and this is J.

365
00:32:27,000 --> 00:32:30,000
 I make the example very simple.

366
00:32:30,000 --> 00:32:39,000
 So we look at this case to see why we cannot do that.

367
00:32:39,000 --> 00:32:44,000
 So this is the other part here.

368
00:32:44,000 --> 00:32:55,000
 If you consider that as input-output relationship, you see.

369
00:32:55,000 --> 00:32:56,000
 So you see here.

370
00:32:56,000 --> 00:32:58,000
 J to the power minus one is a delay.

371
00:32:58,000 --> 00:33:04,000
 But if you add J to the positive power, it will be the forward operator.

372
00:33:04,000 --> 00:33:17,000
 That means the corresponding difference equation related to input is WN.

373
00:33:17,000 --> 00:33:20,000
 Not necessarily not it can be anyone.

374
00:33:20,000 --> 00:33:22,000
 So the output will be XN.

375
00:33:22,000 --> 00:33:28,000
 So this is a simple recursive filter.

376
00:33:28,000 --> 00:33:35,000
 So normally to verify is converged and stable you can see here.

377
00:33:35,000 --> 00:33:41,000
 Say I make the input to be a delta function.

378
00:33:41,000 --> 00:33:49,000
 This is a zero equal to zero and then equal to one equal to zero.

379
00:33:49,000 --> 00:33:52,000
 Otherwise up to date equal to zero.

380
00:33:52,000 --> 00:33:58,000
 So therefore we also assume the initial condition because this we are dealing with an anti-colder.

381
00:33:58,000 --> 00:34:01,000
 So we are moving from zero to the left-hand side.

382
00:34:01,000 --> 00:34:10,000
 Therefore if you start the recursion which is typically in signal system you verify by doing.

383
00:34:10,000 --> 00:34:12,000
 It value a few values.

384
00:34:12,000 --> 00:34:19,000
 So in this case the operation the filter link is from zero to the left-hand side.

385
00:34:19,000 --> 00:34:25,000
 And then you can see the result is converging.

386
00:34:25,000 --> 00:34:29,000
 You see here.

387
00:34:29,000 --> 00:34:30,000
 I continue.

388
00:34:30,000 --> 00:34:35,000
 Okay.

389
00:34:35,000 --> 00:34:44,000
 So say see here is it will be in the end you are related to the initial value it will be equal to this one.

390
00:34:44,000 --> 00:34:52,000
 And remember the power with the negative end so it's minus end become positive or you take absolute value.

391
00:34:52,000 --> 00:34:59,000
 So therefore there is no problem you converge in that direction.

392
00:34:59,000 --> 00:35:12,000
 But however what happened now if we if we you also think knowing this case the poles is exactly equal to three.

393
00:35:12,000 --> 00:35:15,000
 And for anti-colder filter is opposite.

394
00:35:15,000 --> 00:35:19,000
 For colder filter all the poles must be within the unicycle.

395
00:35:19,000 --> 00:35:21,000
 Anti-colder filter is opposite.

396
00:35:21,000 --> 00:35:23,000
 All the poles must be outside.

397
00:35:23,000 --> 00:35:25,000
 Maybe two greater than one.

398
00:35:25,000 --> 00:35:28,000
 So therefore this is corresponding to a stable one.

399
00:35:28,000 --> 00:35:35,000
 But now if you do by multiply z to the power minus one from numerator to denominator.

400
00:35:35,000 --> 00:35:37,000
 So what do we get?

401
00:35:37,000 --> 00:35:39,000
 The poles will not change.

402
00:35:39,000 --> 00:35:47,000
 So I say when you get the poles you don't do that you can do this but it will be easier.

403
00:35:47,000 --> 00:35:49,000
 So the pole location will not change.

404
00:35:49,000 --> 00:35:52,000
 But now this filter is a colder filter.

405
00:35:52,000 --> 00:35:59,000
 You all know if z equal to three you will have unstable filter.

406
00:35:59,000 --> 00:36:11,000
 And to show why you can again change the recursive equation and then look at the input output.

407
00:36:11,000 --> 00:36:21,000
 So here the now is for colder filter you start from zero and then move to that direction to future value based on past value.

408
00:36:21,000 --> 00:36:26,000
 And then of course you see here every time you multiply by three it will grow up.

409
00:36:26,000 --> 00:36:30,000
 So this becomes unstable.

410
00:36:30,000 --> 00:36:39,000
 And to conclude the difference between colder and non-colder or to be more accurate it's anti-colder.

411
00:36:39,000 --> 00:36:42,000
 It will be one in that direction.

412
00:36:42,000 --> 00:36:45,000
 The zero here is a reference point.

413
00:36:45,000 --> 00:36:47,000
 It's like the starting point.

414
00:36:47,000 --> 00:36:49,000
 For colder you start from here to there.

415
00:36:49,000 --> 00:36:53,000
 And for anti-colder no colder you start from there.

416
00:36:53,000 --> 00:36:59,000
 And that will be the way you're doing operation.

417
00:36:59,000 --> 00:37:02,000
 And you cannot say in this case I multiply.

418
00:37:02,000 --> 00:37:06,000
 I change this no colder part into colder one.

419
00:37:06,000 --> 00:37:16,000
 You do that you introduce a unstable one and also confuse because this is the truly stable and colder part.

420
00:37:16,000 --> 00:37:26,000
 And this is stable and no colder part but we don't need here for our IRR filter.

421
00:37:26,000 --> 00:37:28,000
 So we chop this.

422
00:37:28,000 --> 00:37:29,000
 Okay.

423
00:37:29,000 --> 00:37:45,000
 So that's somehow I hope it clarifies and make the concepts also career to understand.

424
00:37:45,000 --> 00:38:04,000
 That could be considered as a nice summary of the Pemidar pass-through chapter before we start the new chapter.

425
00:38:04,000 --> 00:38:12,000
 Any questions so far about the first two chapters?

426
00:38:12,000 --> 00:38:29,000
 This is more or less the contents for the quiz and also for the final exam which by the way the final exam paper for course also start very early.

427
00:38:29,000 --> 00:38:34,000
 I think the first Saturday exam start on Friday.

428
00:38:34,000 --> 00:38:39,000
 So the second day for the for the exam.

429
00:38:39,000 --> 00:38:40,000
 Okay.

430
00:38:40,000 --> 00:38:56,000
 So now this power spectrum estimation is considered is not totally new because I believe in DSP or DSP cause you're even in signaling system.

431
00:38:56,000 --> 00:39:01,000
 We already know how to get the frequency response.

432
00:39:01,000 --> 00:39:08,000
 You see of a given filter then you can draw the magnitude response and phase.

433
00:39:08,000 --> 00:39:09,000
 Yeah.

434
00:39:09,000 --> 00:39:36,000
 So the power spectrum estimation here is roughly corresponding to that but for the digital spectrum analysis normally we refer to the deterministic signal and the filter we desire those high pass low pass those you use for handling sideways or deterministic signal.

435
00:39:36,000 --> 00:39:40,000
 Not involving much you know the random signal.

436
00:39:40,000 --> 00:39:41,000
 Of course noise is okay.

437
00:39:41,000 --> 00:39:47,000
 No is assuming your noise is somewhat separate in the frequency.

438
00:39:47,000 --> 00:39:56,000
 Frequency don't make like the signal is a low frequency noise is high noise high frequency noise then you can apply that.

439
00:39:56,000 --> 00:40:02,000
 But now here we will be also applying to random signal.

440
00:40:02,000 --> 00:40:22,000
 So that's why we need to relook at the problem to see what is the limitation of the traditional methods and what can be done here to improve or at least hinder this problem.

441
00:40:22,000 --> 00:40:35,000
 And in fact you can see our assumption here is also dealing with so called sign signers.

442
00:40:35,000 --> 00:40:51,000
 So you see is consists of those harmonics like sign function cosine cosine functions in the sense about but then waiting this sign cosine as we already discussed early.

443
00:40:51,000 --> 00:40:57,000
 It could be some of the parameters they related to random signal.

444
00:40:57,000 --> 00:41:06,000
 No or maybe either phase or magnitude of the frequency here.

445
00:41:06,000 --> 00:41:16,000
 But in any case the main problem here is the noise and if the noise is white noise and dominant.

446
00:41:16,000 --> 00:41:25,000
 So you will see this will cause problem particularly if you have a finite number of data samples.

447
00:41:25,000 --> 00:41:44,000
 So that's why in this context we will not directly use the Fourier transform of the major data instead you do the power spectrum estimation here.

448
00:41:44,000 --> 00:41:48,000
 Okay so that's the WN here.

449
00:41:48,000 --> 00:41:54,000
 Yeah it's noise and usually it's the statistical independent of this.

450
00:41:54,000 --> 00:42:01,000
 Our signal could be random signal also in general.

451
00:42:01,000 --> 00:42:05,000
 Okay so how are we going to do?

452
00:42:05,000 --> 00:42:22,000
 We want to estimate some frequency and there are some questions we can ask like how many frequencies underlying this major data.

453
00:42:22,000 --> 00:42:25,000
 It could be one, it could be several.

454
00:42:25,000 --> 00:42:43,000
 And then the main concern is we want to see how many frequencies from here and then the value of this such as the high frequency or low frequency.

455
00:42:43,000 --> 00:42:48,000
 And sometimes even the amplitude here or the phase.

456
00:42:48,000 --> 00:42:53,000
 So the more important one is frequency and the value.

457
00:42:53,000 --> 00:42:55,000
 What's the frequency?

458
00:42:55,000 --> 00:42:57,000
 The value.

459
00:42:57,000 --> 00:43:06,000
 So of course the application you can as long as you are handling harmonic, sine wave, cosine and so on.

460
00:43:06,000 --> 00:43:12,000
 Such as space, multimedia and telecommunication and so on.

461
00:43:12,000 --> 00:43:16,000
 You can find those applications.

462
00:43:16,000 --> 00:43:20,000
 So let's look at the way we start ways.

463
00:43:20,000 --> 00:43:34,000
 We are familiar with the DFT or DTFT which you already know to handle.

464
00:43:34,000 --> 00:43:37,000
 We still assume discrete time signal.

465
00:43:37,000 --> 00:43:40,000
 Not continue your Fourier transform.

466
00:43:40,000 --> 00:43:43,000
 So B mean discrete time.

467
00:43:43,000 --> 00:43:46,000
 DFT or DTFT.

468
00:43:46,000 --> 00:43:52,000
 And then for DTFT which assume you have infinity many sample.

469
00:43:52,000 --> 00:43:58,000
 Then you take DTFT you will get this in the frequency domain.

470
00:43:58,000 --> 00:44:06,000
 It will be just two very nice impulse which happen to be the frequency.

471
00:44:06,000 --> 00:44:17,000
 For frequency we always talk in the real life it is positive but in mass in Fourier analysis we will get the negative frequencies.

472
00:44:17,000 --> 00:44:19,000
 It's positive, negative.

473
00:44:19,000 --> 00:44:22,000
 So that will be very nice.

474
00:44:22,000 --> 00:44:30,000
 If you are the signal is just cosine signal you do very simple to Fourier transform your DTFT.

475
00:44:30,000 --> 00:44:32,000
 You will get these two infinity.

476
00:44:32,000 --> 00:44:37,000
 And here this is continue in the continue domain to add.

477
00:44:37,000 --> 00:44:40,000
 So you see the two infinity.

478
00:44:40,000 --> 00:44:43,000
 Very high peak.

479
00:44:43,000 --> 00:44:47,000
 But there are some practical problem.

480
00:44:47,000 --> 00:44:56,000
 The first limitation is if we are only have finite duration.

481
00:44:56,000 --> 00:44:59,000
 For example you have two n, two k-p-n samples.

482
00:44:59,000 --> 00:45:04,000
 So you use this is like a window function.

483
00:45:04,000 --> 00:45:07,000
 And here if we don't care about causality.

484
00:45:07,000 --> 00:45:17,000
 So you have from minus negative n to positive n and of course it should be have one in the middle zero.

485
00:45:17,000 --> 00:45:19,000
 So it should be two n plus one.

486
00:45:19,000 --> 00:45:22,000
 This is just estimate.

487
00:45:23,000 --> 00:45:30,000
 But then the problem is if we have very long duration n is very big is fine.

488
00:45:30,000 --> 00:45:33,000
 But if n is very small.

489
00:45:33,000 --> 00:45:41,000
 For example two to the power four 16 data sample you will see the big difference.

490
00:45:41,000 --> 00:45:45,000
 This is very big n and this is finite n.

491
00:45:46,000 --> 00:45:53,000
 So you will see not the very sharp peak but you have also some other peak.

492
00:45:53,000 --> 00:46:01,000
 Also those peak are not very high but sometimes you may get confused.

493
00:46:01,000 --> 00:46:06,000
 Particularly if you are adding some noise later we will show.

494
00:46:07,000 --> 00:46:17,000
 And there is another problem is if now in real life you may not just sing one frequency component.

495
00:46:17,000 --> 00:46:21,000
 You may have two frequency components.

496
00:46:21,000 --> 00:46:25,000
 They are different but the difference are very small.

497
00:46:25,000 --> 00:46:31,000
 So that means if you plug it out in the spectrum you will be the two of them very close.

498
00:46:31,000 --> 00:46:38,000
 But again if you have infinity or very large number of data sample you can still resolve these two.

499
00:46:38,000 --> 00:46:47,000
 However now if the sample is very small only the example here is two to the power four.

500
00:46:47,000 --> 00:46:50,000
 Then the two peaks you will just the resolution.

501
00:46:50,000 --> 00:46:55,000
 As we say if you have a poor resolution you will see just one.

502
00:46:55,000 --> 00:47:00,000
 That is a more of a problem.

503
00:47:05,000 --> 00:47:13,000
 And then there is the one we mentioned is finite number of data.

504
00:47:13,000 --> 00:47:15,000
 I call this problem.

505
00:47:15,000 --> 00:47:26,000
 And then adding another problem is if you now add some white noise other than just again a simple cosine plus noise.

506
00:47:26,000 --> 00:47:40,000
 Then coupling together with finite data then this is very hard to differentiate whether this peak and those peak.

507
00:47:40,000 --> 00:47:49,000
 So this is still a bit higher than other but you will not be sure whether these are the low peaks.

508
00:47:49,000 --> 00:47:53,000
 They are lower than that but it may be signal, may be noise.

509
00:47:53,000 --> 00:47:58,000
 So that is something very uncertain now.

510
00:47:58,000 --> 00:48:06,000
 And that was why we cannot directly use the traditional method to do it.

511
00:48:07,000 --> 00:48:14,000
 So one way to do is since after now we have learned the autocorrelation.

512
00:48:14,000 --> 00:48:18,000
 And then since we have noising for here.

513
00:48:18,000 --> 00:48:24,000
 Here we assume with the cosine.

514
00:48:24,000 --> 00:48:36,000
 Actually for this cosine signal we already show even if the phase is random but uniformly distributed phase.

515
00:48:36,000 --> 00:48:45,000
 When you take the autocorrelation it will become a proper cosine signal that you will remove this randomness.

516
00:48:45,000 --> 00:48:51,000
 And the same is if the phase is a fixed one then that is even better.

517
00:48:51,000 --> 00:48:59,000
 So in any case we assume the autocorrelation of taking this cosine.

518
00:48:59,000 --> 00:49:11,000
 It will give you this cosine function which depending on the lag of the delay of the L.

519
00:49:11,000 --> 00:49:18,000
 This is L. It's like the N. It will be the time delay.

520
00:49:18,000 --> 00:49:25,000
 And I think this one, this type of error, this will be also L because we are changing it to N is the time delay.

521
00:49:25,000 --> 00:49:29,000
 L is in the take autocorrelation.

522
00:49:29,000 --> 00:49:41,000
 They refer to the like along the way I try to correct some like typo errors even some of the early part.

523
00:49:41,000 --> 00:49:46,000
 So always use the most uptake one. I may not announce every time.

524
00:49:46,000 --> 00:49:57,000
 So particularly between now and next week the quiz you try to get the latest version.

525
00:49:57,000 --> 00:50:06,000
 This one I will change but it will affect only the final exams not for the quiz.

526
00:50:06,000 --> 00:50:17,000
 So therefore now if the nice thing is you know why noise you take autocorrelation it will become a delta function.

527
00:50:17,000 --> 00:50:27,000
 That means the only when L equal to G low and the value is no infinity last because we are dealing with discretizing them.

528
00:50:27,000 --> 00:50:31,000
 It will be just equal to one and the noise power is always finite.

529
00:50:31,000 --> 00:50:42,000
 So it will be mean you only have in terms of autocorrelation take the no zero value here otherwise become G low.

530
00:50:42,000 --> 00:50:45,000
 So you will have this part.

531
00:50:45,000 --> 00:50:58,000
 And then even better is now if you take the Fourier transform apply or DTFT into this autocorrelation.

532
00:50:58,000 --> 00:51:05,000
 Not to the major data directly. So what do we see because this is still cosine signal.

533
00:51:05,000 --> 00:51:16,000
 So once you take DTFT you will get the two delta function and this delta function infinity high peak value theoretically.

534
00:51:16,000 --> 00:51:21,000
 And furthermore this is a delta L delta function.

535
00:51:21,000 --> 00:51:28,000
 Once you take DTFT you will be just being a constant independent of the frequency.

536
00:51:28,000 --> 00:51:36,000
 That means you have these two peaks there and you add on this DC value.

537
00:51:36,000 --> 00:51:39,000
 So you only raise the floor.

538
00:51:39,000 --> 00:51:46,000
 It will not affect the you will not create some pseudo peak as we see early.

539
00:51:46,000 --> 00:51:59,000
 So that works much better by applying the DTFT into the autocorrelation rather than the major data except.

540
00:51:59,000 --> 00:52:09,000
 So that's the motivation of introducing this going through autocorrelation and then doing the DTFT.

541
00:52:09,000 --> 00:52:16,000
 So that's what we call power spectrum estimation.

542
00:52:16,000 --> 00:52:25,000
 We are doing the power density but then since we are dealing with finite data so we need to estimate.

543
00:52:25,000 --> 00:52:38,000
 So that's why N double is the power spectrum estimation and estimate of the true power spectrum density.

544
00:52:38,000 --> 00:52:47,000
 This is the one assuming infinity many value where this one is finite data.

545
00:52:47,000 --> 00:52:56,000
 So in general here there are two different approaches to this PSC.

546
00:52:56,000 --> 00:53:01,000
 So one is no parametric.

547
00:53:01,000 --> 00:53:07,000
 That means you do not model just similar to neural network machine learning.

548
00:53:07,000 --> 00:53:19,000
 You are using data driven just based on the data you don't assume a RMA model or some linear model.

549
00:53:19,000 --> 00:53:29,000
 So then directly you estimate the autocorrelation function then compute this DTFT.

550
00:53:29,000 --> 00:53:37,000
 Parametric one is you try to model the signal using some model.

551
00:53:37,000 --> 00:53:53,000
 Typically here is the rational function like what we learned earlier, the rational spectrum.

552
00:53:53,000 --> 00:54:10,000
 So based on the IRR filters for example RMA or AR and then we estimate the model parameter such as those coefficient A or B.

553
00:54:10,000 --> 00:54:16,000
 Then once you got to do that you also need to base on the major data.

554
00:54:16,000 --> 00:54:32,000
 Then from there you can from the model you can compute the DTFT or the estimate power spectrum density based on that.

555
00:54:32,000 --> 00:54:37,000
 So that's the two approach we will be discussing.

556
00:54:37,000 --> 00:54:42,000
 So we start with this no parametric method.

557
00:54:42,000 --> 00:54:53,000
 It's easy to understand also the result is later you will see not very satisfactory.

558
00:54:53,000 --> 00:55:01,000
 So that's why this is not used very often.

559
00:55:01,000 --> 00:55:07,000
 Particularly it will require higher resolution.

560
00:55:07,000 --> 00:55:13,000
 So let's just go through this quickly.

561
00:55:13,000 --> 00:55:29,000
 In this topic there are mostly the very traditional method because very limited scope to do research along this direction.

562
00:55:29,000 --> 00:55:46,000
 So for example this Jenkins and WOS estimator is being there for 60 to 70 years because it was developed in the 1950 or 60.

563
00:55:46,000 --> 00:55:50,000
 So that's more than half a century ago.

564
00:55:50,000 --> 00:56:04,000
 But the idea here is also based on the autocorrelation but assuming now you only have finite data sample here.

565
00:56:04,000 --> 00:56:25,000
 And then because assume we have a total of NG sample then for the autocorrelation we need to get a delay time.

566
00:56:25,000 --> 00:56:37,000
 So the way to do for even theoretically or mathematically is the same is you fix one then you can take conjugate either this one or that one.

567
00:56:37,000 --> 00:56:47,000
 It will not affect because they all belong to the same X input signal.

568
00:56:48,000 --> 00:56:54,000
 And then one of them is your fix because that's the summation index N.

569
00:56:54,000 --> 00:57:09,000
 Where the other one you how much the N is determining the other signal, the finite signal you're going to shift and then multiply and then sum together.

570
00:57:09,000 --> 00:57:23,000
 But when you shift away then since we only have capital N sample the overlap number of points will keep getting smaller when N increase.

571
00:57:23,000 --> 00:57:28,000
 So therefore you need to normalize.

572
00:57:28,000 --> 00:57:37,000
 For example you are summing up instead of capital N sample you only summing up capital N minus small m.

573
00:57:37,000 --> 00:57:43,000
 So you to normalize you divide the number of terms you are summing.

574
00:57:43,000 --> 00:57:47,000
 So that's how this this method it also makes sense.

575
00:57:47,000 --> 00:57:49,000
 I sum how many terms?

576
00:57:49,000 --> 00:57:53,000
 Say 10, 10 terms then you divide by 10.

577
00:57:53,000 --> 00:57:57,000
 If you are summing up 5 terms you divide by 5.

578
00:57:57,000 --> 00:58:12,000
 And then the estimate we also assume is symmetry if it's complex if you're dealing with complex signal then you will take conjugate also.

579
00:58:12,000 --> 00:58:23,000
 Then outside this window you cannot do anything because you don't have beta sample shift so far away.

580
00:58:23,000 --> 00:58:26,000
 So we just assume this is zero.

581
00:58:26,000 --> 00:58:32,000
 So a little bit like you are applying a window function to take this part.

582
00:58:32,000 --> 00:58:38,000
 And then to do the performance analysis we're not going here but just show the result.

583
00:58:38,000 --> 00:58:42,000
 There is expectation equal to the true one.

584
00:58:42,000 --> 00:58:45,000
 So that's unbiased.

585
00:58:45,000 --> 00:59:02,000
 And the variant which the formula is here is a little bit complicated but it shows the formula is somewhat related to the true one and the shift product and so on.

586
00:59:02,000 --> 00:59:19,000
 So we see with n if you have the number of sample going with it then the variant would become zero assuming this m is a finite one and also is an energy sequence.

587
00:59:19,000 --> 00:59:32,000
 So that part will not go into detail but then the estimate will have a large variant.

588
00:59:32,000 --> 00:59:41,000
 If you have finite data sample and the leg parameter is large so that's called some problem.

589
00:59:41,000 --> 00:59:49,000
 That's why this Schuller's estimator is also very long time ago about the same variant.

590
00:59:49,000 --> 01:00:02,000
 It somehow tries to the formula is similar but just instead of dividing the denominator the previous formula it will get smaller and smaller.

591
01:00:02,000 --> 01:00:05,000
 It just doesn't matter.

592
01:00:05,000 --> 01:00:11,000
 Independent of how many times you sum I divide into the capital N.

593
01:00:11,000 --> 01:00:18,000
 Because this n usually is bigger than n minus small m.

594
01:00:18,000 --> 01:00:31,000
 So in this case you can also see you can use a vector to represent because you are dividing to the same n.

595
01:00:31,000 --> 01:00:50,000
 So you see here if I pack zero on left and right then you can rely this as like an inner product of this one with shift the other without shift.

596
01:00:50,000 --> 01:01:01,000
 But we have a problem here because so by what you know if you divide this factor is unbiased.

597
01:01:01,000 --> 01:01:16,000
 Now you divide n of course it will make a difference so it's very easy just based on the previous one you will see the estimate will be biased and bias term is equal to that.

598
01:01:16,000 --> 01:01:31,000
 So in the case of n very big and the small m is not big then you can see this bias term will be getting smaller or close to zero and go to infinity large.

599
01:01:31,000 --> 01:01:34,000
 That's quite okay.

600
01:01:34,000 --> 01:01:44,000
 But however if the capital N is finite and small n approaching n then you can see the bias will be very big.

601
01:01:44,000 --> 01:01:55,000
 The good thing for this estimator is the value will be smaller because it divides by large n always.

602
01:01:55,000 --> 01:02:01,000
 So you get the smaller value in this case.

603
01:02:01,000 --> 01:02:12,000
 And then you can also analyze we n goes to infinity and bias and the value goes to zero.

604
01:02:12,000 --> 01:02:24,000
 And yeah so also both of them you can see here they they here consistent estimate of this.

605
01:02:24,000 --> 01:02:31,000
 That means as long as n go become very large you will approximate this one very well.

606
01:02:31,000 --> 01:02:38,000
 Based on that we can get estimate of this.

607
01:02:38,000 --> 01:02:59,000
 This is the one the power density power spectral density the one we are going to theoretically this is the autocorrelation with infinity long data but since now we have finite data and it's also estimate.

608
01:02:59,000 --> 01:03:08,000
 So what we have is we do the estimation of that based on finite sample and this is the estimate.

609
01:03:08,000 --> 01:03:27,000
 So yeah this is what we have but surprisingly it can be proved the estimate of this is not a consistent estimate of the true one even if you have longer data.

610
01:03:27,000 --> 01:03:32,000
 So that's yeah that's causing some problem.

611
01:03:32,000 --> 01:03:40,000
 I think the main reason is you're not doing the averaging everything enough.

612
01:03:40,000 --> 01:03:47,000
 So that's why some method proposed to chop down into a few data segments and then do the average.

613
01:03:47,000 --> 01:03:53,000
 So I think this topic we will not go into into detail.

614
01:03:53,000 --> 01:04:01,000
 We are showing the limitation if you take sample and this is a true power spectrum.

615
01:04:01,000 --> 01:04:06,000
 The AR2 is not as smooth only one.

616
01:04:06,000 --> 01:04:08,000
 Then this is AR4.

617
01:04:08,000 --> 01:04:22,000
 There will be two peaks here and then if you use these two methods we introduced early what you get the estimate quite quite noisy.

618
01:04:22,000 --> 01:04:30,000
 The true one is smooth but what do we get is some very rough approximation.

619
01:04:30,000 --> 01:04:41,000
 There are some other methods which we will not discuss here because it's yeah.

620
01:04:41,000 --> 01:04:57,000
 So for no parametric method we just get a very brief idea without going into detail.

621
01:04:57,000 --> 01:05:10,000
 And for that reason usually this in the past years and also should be the same as I normally I just exclude this no parametric.

622
01:05:10,000 --> 01:05:27,000
 I exclude it for the final exam paper and that's why if you look at past year paper there were no questions on those no parametric method.

623
01:05:27,000 --> 01:05:37,000
 Although if you explore there are some topics but they were to limited time to be more focused.

624
01:05:37,000 --> 01:05:46,000
 We will spend more time on the parametric method.

625
01:05:46,000 --> 01:06:08,000
 But the no parametric one we not to discuss the two methods but the power spectrum estimation for the MA or AR or AMA model that either is FIR corresponding to FIR filter,

626
01:06:08,000 --> 01:06:15,000
 polynomial only or pole only corresponding to AR or a proper rational function.

627
01:06:15,000 --> 01:06:28,000
 That power will be doing the you know the spectrum computation and so on that will be still considered within the scope.

628
01:06:28,000 --> 01:06:36,000
 Anyway for this chapter 12 we will discuss more after next week's quiz.

629
01:06:36,000 --> 01:06:47,000
 We still have next week's 12 so we still have the final week 13 which yeah.

630
01:06:47,000 --> 01:06:55,000
 So let me let us take a break short break now so that now is 7.36.

631
01:06:55,000 --> 01:07:04,000
 We come back at 7.15 according to the clock to continue the parametric method.

632
01:07:04,000 --> 01:07:05,000
 Okay.

633
01:07:05,000 --> 01:07:07,000
 See you shortly.

634
01:07:07,000 --> 01:07:13,000
 Any questions you can come.

635
01:07:17,000 --> 01:07:19,000
 Thank you.

636
01:07:47,000 --> 01:07:50,000
 Thank you.

637
01:08:17,000 --> 01:08:20,000
 Thank you.

638
01:08:47,000 --> 01:08:50,000
 Thank you.

639
01:09:17,000 --> 01:09:20,000
 Thank you.

640
01:09:47,000 --> 01:09:50,000
 Thank you.

641
01:10:17,000 --> 01:10:19,000
 Thank you.

642
01:10:47,000 --> 01:10:50,000
 Thank you.

643
01:11:17,000 --> 01:11:19,000
 Thank you.

644
01:11:47,000 --> 01:11:49,000
 Thank you.

645
01:12:17,000 --> 01:12:19,000
 Thank you.

646
01:12:47,000 --> 01:12:49,000
 Thank you.

647
01:13:17,000 --> 01:13:19,000
 Thank you.

648
01:13:47,000 --> 01:13:49,000
 Thank you.

649
01:14:17,000 --> 01:14:19,000
 Thank you.

650
01:14:47,000 --> 01:14:49,000
 Thank you.

651
01:15:17,000 --> 01:15:19,000
 Thank you.

652
01:15:47,000 --> 01:15:49,000
 Thank you.

653
01:16:17,000 --> 01:16:19,000
 Thank you.

654
01:16:47,000 --> 01:16:49,000
 Thank you.

655
01:17:17,000 --> 01:17:19,000
 Thank you.

656
01:17:47,000 --> 01:17:49,000
 Thank you.

657
01:18:17,000 --> 01:18:19,000
 Thank you.

658
01:18:47,000 --> 01:18:49,000
 Thank you.

659
01:19:17,000 --> 01:19:19,000
 Thank you.

660
01:19:47,000 --> 01:19:49,000
 Thank you.

661
01:20:17,000 --> 01:20:19,000
 Thank you.

662
01:20:47,000 --> 01:20:49,000
 Thank you.

663
01:21:17,000 --> 01:21:19,000
 Thank you.

664
01:21:47,000 --> 01:21:49,000
 Thank you.

665
01:22:17,000 --> 01:22:19,000
 Thank you.

666
01:22:47,000 --> 01:22:49,000
 Thank you.

667
01:23:17,000 --> 01:23:19,000
 Thank you.

668
01:23:47,000 --> 01:23:49,000
 Thank you.

669
01:24:17,000 --> 01:24:21,000
 Thank you.

670
01:24:21,000 --> 01:24:23,000
 Thank you.

671
01:24:23,000 --> 01:24:25,000
 Thank you.

672
01:24:25,000 --> 01:24:27,000
 Thank you.

673
01:24:31,000 --> 01:24:33,000
 Okay.

674
01:24:33,000 --> 01:24:43,000
 So let's continue into another method which we call parametric method.

675
01:24:43,000 --> 01:24:53,520
 we consider the PSD, one is a function of the frequency variable F, this is the one,

676
01:24:53,520 --> 01:25:04,920
 the frequency, the main one. And then we try to represent that as a parameter vector theta,

677
01:25:04,920 --> 01:25:11,840
 it could be, you know, the numerator coefficient, denominator coefficient if you are using a

678
01:25:11,840 --> 01:25:25,800
 rational function. So that therefore in this case the parameter vector may take different

679
01:25:25,800 --> 01:25:37,000
 values. So we are trying to determine the optimal theta, called theta optimal based

680
01:25:37,000 --> 01:25:46,120
 on our major finite major data here, such that in this case the estimate one will be

681
01:25:46,120 --> 01:25:53,600
 closer to the true one as much as possible in something, usually is least squares and

682
01:25:53,600 --> 01:26:06,720
 so on. So that's how this part is again is quite closely related to what we learn in

683
01:26:06,720 --> 01:26:14,160
 chapter one and chapter two by considering this white saying, stationary process, yeah,

684
01:26:14,160 --> 01:26:21,440
 discussing chapter one and then some of the techniques such as how to get the autocorrelation

685
01:26:21,440 --> 01:26:32,680
 coefficient and so on, we discuss also in chapter two. So we want to see how we can

686
01:26:32,680 --> 01:26:44,720
 be applied here. So remember if we consider the more general model, AMA model where you

687
01:26:44,720 --> 01:26:56,120
 have the MA is the numerator part, the one corresponding to this queue, the order is

688
01:26:56,120 --> 01:27:04,840
 queue, where AI is the one corresponding to the denominator. So we consider the P and

689
01:27:04,840 --> 01:27:13,200
 queue may be the same, may be different. So in general we use P for the denominator,

690
01:27:13,200 --> 01:27:20,880
 the AR part, where queue for the numerator and then these are rational functions which

691
01:27:20,880 --> 01:27:27,680
 will be easier because rational function you have a finite number of coefficient or

692
01:27:27,680 --> 01:27:35,480
 parameter so we can put them together as a factor. And if you do not know the noise

693
01:27:35,480 --> 01:27:43,640
 value because here in this model we assume it's generally from the white noise so that

694
01:27:43,640 --> 01:27:54,760
 we call the W. And here by the way some students ask the process we are discussing here WSS

695
01:27:54,760 --> 01:28:04,600
 is for white noise is always assumed to zero mean. And zero means process you go through

696
01:28:04,600 --> 01:28:21,640
 filter the WSS process you generate, you also have zero means. So if I do not specifically

697
01:28:21,640 --> 01:28:29,800
 mention the means of the random process it will be zero means. Okay, that's by assumption.

698
01:28:29,800 --> 01:28:41,840
 And yeah, okay. So I take this opportunity to also discuss here. So you can also derive

699
01:28:41,840 --> 01:28:54,920
 from input output relationship by just similar to if you are going through filters and so

700
01:28:54,920 --> 01:29:05,520
 on. Okay, so in this context let's see what we can do here. So you can see if you are

701
01:29:05,520 --> 01:29:17,440
 using system base or model base power spectrum estimation or star is stage one which is to

702
01:29:17,440 --> 01:29:28,639
 select models. For example you can consider different model structure such as typically

703
01:29:28,639 --> 01:29:39,799
 here we have AR, MA or AMA and then also the orders if you are limited to rational functions.

704
01:29:39,799 --> 01:29:47,400
 And then we do the model estimation because what is model is finite number of parameters

705
01:29:47,400 --> 01:29:58,240
 to estimate such as what we just show early. And then after that you need to check whether

706
01:29:58,240 --> 01:30:06,839
 the candidate model is suitable based on the performance. You may need some data to do

707
01:30:06,839 --> 01:30:15,000
 the verification. So in this saying this is quite similar to machine learning that you

708
01:30:15,000 --> 01:30:24,200
 do the validation and also the model you choose may not be the same as the model which

709
01:30:24,200 --> 01:30:34,560
 generate the random signal because you are based on the major data but you do not really

710
01:30:34,560 --> 01:30:43,680
 know the process from the white noise how the white noise generate. For example the

711
01:30:43,680 --> 01:30:53,200
 white noise stationally process. So you may that's why later we also discuss how to choose

712
01:30:53,200 --> 01:31:04,240
 the proper order. If the order is not accurate you may need to redo it again and that's why

713
01:31:04,240 --> 01:31:10,760
 the model is satisfactory or not if not then you will go to another cycle to either choose

714
01:31:10,800 --> 01:31:20,800
 another structure or change all the and here the model is suitable for your application.

715
01:31:20,800 --> 01:31:36,400
 So that's how it is. Okay so now we next discuss how we can based on the different models we

716
01:31:37,360 --> 01:31:49,440
 how to do the model estimation and PST estimation. So the very popular one and common one is the

717
01:31:49,440 --> 01:31:59,360
 AR model and actually among the three models AR model is somewhere in the middle is MA is more

718
01:31:59,360 --> 01:32:06,200
 like the FIA filter is simple but not the modeling power is a right not a limit because

719
01:32:06,200 --> 01:32:14,320
 particularly you cannot model those are sharp like high-picking so because if you are estimate

720
01:32:14,320 --> 01:32:26,120
 sideways harmonic you tend to see some peak and MA model you will need very high order. So AI is

721
01:32:26,120 --> 01:32:36,880
 the compromise because you can do a good estimation and furthermore as you see in the chapter 2 you

722
01:32:36,880 --> 01:32:52,360
 see formula you have some analytical nice method to do it to do the magic you know computation

723
01:32:52,519 --> 01:33:04,160
 which is quite convenient also. So we'll spend more time on this AR parameter estimation. So

724
01:33:04,160 --> 01:33:14,080
 that's why here you only involve those AK estimate and also if the noise variance you do not know

725
01:33:14,240 --> 01:33:23,519
 your estimate is also. So in this case you know the optimal parameter assume we get the optimal one

726
01:33:23,519 --> 01:33:38,880
 then this is the vector parameter we need here and there are several methods to do that we will

727
01:33:39,200 --> 01:33:51,840
 briefly discuss. So one of them this Euroworker method this one is very critical but it's quite

728
01:33:51,840 --> 01:34:03,600
 well known and also for AR parameters it's very convenient you see if you go back to chapter 2

729
01:34:03,680 --> 01:34:20,280
 where already introduced this this method and here if you know the auto correlation coefficient or

730
01:34:20,280 --> 01:34:29,680
 if you estimate this one here first then you'll get you use the estimate value you will be able to

731
01:34:30,000 --> 01:34:43,680
 estimate the AR parameters A1 auto update and using this matrix equation okay so that's that's

732
01:34:43,680 --> 01:34:56,960
 you're just solving the linear matrix equations here okay so that's the way yeah you can do

733
01:34:57,520 --> 01:35:09,280
 and then once you estimate this you can also estimate the noise variance by because this is the

734
01:35:09,280 --> 01:35:19,640
 AR model you again use the equation and this one is achieved you know or the estimate value so you'll

735
01:35:19,640 --> 01:35:29,000
 do the using this formula you can also do it so in this way you are doing it in two steps estimate

736
01:35:29,000 --> 01:35:37,760
 the AR coefficient and then after that you estimate the noise variance or you can put together into

737
01:35:37,760 --> 01:35:52,120
 one larger matrix equation you can but yeah it should be able to solve yeah we discussed that early

738
01:35:52,120 --> 01:36:07,840
 okay so because we here we we do not know the true auto correlation so we use some of the early

739
01:36:08,440 --> 01:36:26,720
 estimator measure to do it but you can try to use other other methods also and then the estimate of

740
01:36:26,720 --> 01:36:37,160
 this auto correlation matrix in this case will be positive definite so therefore our AR model

741
01:36:37,280 --> 01:36:47,080
 will be a stable one and using this method the matrix is also satisfy the top of this form top of

742
01:36:47,080 --> 01:36:55,559
 this form is the one along the diagonal element it will be taking the same same value and then you

743
01:36:55,560 --> 01:37:07,160
 can we can also use the levion soon to bring a rhythm to solve that but as I as I mentioned early we

744
01:37:07,160 --> 01:37:19,080
 were not focusing on these recursive methods yeah so yeah and then there is another method if you are

745
01:37:19,080 --> 01:37:30,200
 using the lattice filter we discussed early then you can use the following cell all the recursive

746
01:37:30,200 --> 01:37:38,040
 equation to do so the way to do your start from the initial value which is given given signal and

747
01:37:38,040 --> 01:37:46,680
 out of that your recursively get from lower the go to higher one and at the same time in terms of the

748
01:37:46,680 --> 01:37:56,120
 time you also use the immediate previous value and the current value and depending on the previous

749
01:37:56,120 --> 01:38:05,640
 yeah the current order previous order but the but the value it could be at this at the same

750
01:38:05,640 --> 01:38:16,320
 index or previous value so so based on that you're doing recursively in terms of beta and also in

751
01:38:16,400 --> 01:38:28,880
 terms of the order and then as we discussed early to do that you'll need to know this KM which are

752
01:38:28,880 --> 01:38:38,840
 called reflection or partial coefficient and that's related to the filter coefficient and our filter

753
01:38:38,960 --> 01:38:51,400
 here is our our our mar coefficient here so you you can pay some this equation to get that then

754
01:38:52,240 --> 01:39:08,599
 and then you here in order to minimize the mean mean mean square arrows we can also choose the

755
01:39:09,200 --> 01:39:23,280
 optimal coefficient yeah one by one by by minimize this and then you'll see you can get

756
01:39:23,280 --> 01:39:35,760
 coefficient from because the KL they also stays by stays so you need to do get one and then

757
01:39:35,920 --> 01:39:45,720
 up a day you'll get you'll get a second one based on the recursive equations early okay so yeah

758
01:39:45,720 --> 01:39:56,960
 they're doing I to one two three and so on where this noise here is estimate using this

759
01:39:56,960 --> 01:40:13,040
 the last one is it the last last stage will be P so you're using that okay so from there once we

760
01:40:13,040 --> 01:40:23,040
 get this you can get the power spectrum density using the formula 160 and this

761
01:40:23,040 --> 01:40:37,000
 at the bottom of this burger measure to estimate this AR parameter is equal to high frequency

762
01:40:37,000 --> 01:40:48,360
 resolution because the power density spectrum here based on the lattice is less sensitive to the

763
01:40:48,360 --> 01:41:00,160
 error in this then if you use the AL the estimate coefficient directly that's being already being

764
01:41:00,160 --> 01:41:09,960
 showed by lattice filter is less sensitive and then furthermore because here AR model

765
01:41:09,960 --> 01:41:19,680
 corresponding to IR filter so we need to ensure stability but if you are using the lattice filter as

766
01:41:19,680 --> 01:41:26,640
 long as you the constability condition very easy to check even if you're a high order because every

767
01:41:26,640 --> 01:41:33,720
 time you're you'll make sure the coefficient magnitude if it's complex or yeah the absolute

768
01:41:33,720 --> 01:41:43,800
 value is smaller than one then you will do and it's computationally efficient so this is one of

769
01:41:43,800 --> 01:41:54,680
 the measures quite often used in practice also and then you can also use unconstrained least

770
01:41:54,920 --> 01:42:08,960
 square measure because least square method is also very popular and easy to easy to use so yeah so

771
01:42:08,960 --> 01:42:22,960
 so the way to do is you you can consider model that as unconstrained least square algorithm to

772
01:42:23,720 --> 01:42:37,200
 determine the AR AR parameter and then for the last stage of the lattice filter we can we can

773
01:42:37,200 --> 01:42:49,640
 mainly just estimate is finer optimal value rather than if you are doing that state by state

774
01:42:50,400 --> 01:42:59,640
 previously which will give you a suboptimal because you need to assume the previously is not so but

775
01:42:59,640 --> 01:43:10,000
 if the previous one creates some some some error they will accumulate so here is we just directly go

776
01:43:10,160 --> 01:43:20,240
 to the final stage and then using least the square to do the optimization there so that's

777
01:43:20,240 --> 01:43:34,320
 yeah so whatever you do once you get this so-called optimal parameter value which

778
01:43:34,519 --> 01:43:42,160
 corresponding to the I get here where still in the AR AR model then you're substitute into the

779
01:43:42,160 --> 01:43:57,599
 rational function and from there you can get the estimate PSD here and yeah normally as I

780
01:43:57,600 --> 01:44:08,800
 mentioned earlier using AR model is you it's quite good to model those peaks in the power spectrum

781
01:44:08,800 --> 01:44:23,400
 so that from the peaks you you can also try to estimate the frequency for example if the you see if

782
01:44:23,400 --> 01:44:37,040
 the the peaks if they are very close to the unit circle you see if you go to the jet jet domain

783
01:44:37,040 --> 01:44:49,440
 then you can get the poles of the AR model since these are just you know the polynomial in the

784
01:44:49,639 --> 01:44:58,240
 denominator okay and then to to be stable you have to ensure this lose must be within the

785
01:44:58,240 --> 01:45:10,519
 unit unit circle but if the poles is very close to you know the the magnitude of poles very close

786
01:45:10,600 --> 01:45:19,360
 to one that means very near the unit circle then you will see the power spectrum have a peak at

787
01:45:19,360 --> 01:45:28,280
 that at that frequency which is very close to this you see to this frequency because if you

788
01:45:28,280 --> 01:45:38,600
 all draw the in the complex plane you'll draw the unit circle there and to get the frequency

789
01:45:38,600 --> 01:45:47,240
 respond to get the true one you will need to evaluate that jet by substituting e to the power j

790
01:45:47,240 --> 01:45:57,920
 and phi and the phi here is corresponding to the frequency by 2 pi f phi is the digital frequency

791
01:45:57,920 --> 01:46:07,800
 you see here you go by one circle it will be it will be 2 pi but typically we only keep we use

792
01:46:08,000 --> 01:46:21,360
 the the first first quadrant and then once you get this radiant frequency you can you can divide

793
01:46:21,360 --> 01:46:35,920
 by 2 pi to get to get a frequency this is what we yeah we are we are looking for so so of course

794
01:46:36,040 --> 01:46:45,400
 if the estimate is not good the pole very far from the unit circle then you may not see the see the

795
01:46:45,400 --> 01:46:56,040
 very good peak yeah that's that's right that depends on you know you are a model and the

796
01:46:56,040 --> 01:47:05,960
 parameters you will be you'll be choosing so another very important important step is because

797
01:47:05,960 --> 01:47:21,920
 you all know the AR model order you got determining how how sharp the the peak you will see then so

798
01:47:21,920 --> 01:47:33,600
 we need to to do the selection of the order order p this is another important steps we need to do and

799
01:47:33,600 --> 01:47:48,280
 in general days days days a guy like if you choose the model is a very low order then you you can see

800
01:47:48,960 --> 01:47:56,519
 the spectrum looks very very smooth so you may not see the proper peak and that that defeated the

801
01:47:56,519 --> 01:48:10,200
 purpose of doing the frequency estimation but yeah on other end if you select the p the order very

802
01:48:10,440 --> 01:48:21,160
 very high then in general you will get to produce a more like a higher resolution but you know like

803
01:48:21,160 --> 01:48:29,920
 just like machine learnings if you use the model to to complex and then do not do it properly or

804
01:48:29,920 --> 01:48:38,400
 the data you use to learn is very limited then you may lead to this overfitting and in this

805
01:48:38,839 --> 01:48:49,799
 spectrum estimation you may introduce spurious low level peaks I mean you may see many peaks rather

806
01:48:49,799 --> 01:48:59,400
 than the true one you may just have a few so so that could lead to another extreme so so therefore

807
01:49:00,400 --> 01:49:13,679
 to given some data find a number of sample it's very important to to select the AR models

808
01:49:13,679 --> 01:49:26,320
 order property and that that's again is being done by some researchers many years back so so

809
01:49:26,320 --> 01:49:36,040
 there are several criterion you can use so that's one of them is called finite prediction error

810
01:49:36,040 --> 01:49:48,120
 criteria so the way to do is in order to select the proper order then you minimize this index the

811
01:49:48,120 --> 01:49:58,080
 index is defined in this way so this one you will be because by choosing different order you

812
01:49:58,080 --> 01:50:08,040
 will the estimate why noise it will also also change okay so typically the higher order you may

813
01:50:08,640 --> 01:50:19,480
 get a smaller noise here then you'll now you look at this look at this ratio you see here and

814
01:50:19,480 --> 01:50:30,920
 gang is a given data so that one is a fix so so if for example if you increase p so this so this

815
01:50:30,920 --> 01:50:42,360
 ratio will be will be bigger am I right increase p the denominator increase then the denominator

816
01:50:42,360 --> 01:50:51,240
 decrease denominator is the one below so p get bigger this one small the numerator increase so

817
01:50:51,240 --> 01:50:58,720
 therefore the ratio the ratio will will increase but then at the same time this noise variant

818
01:50:59,480 --> 01:51:11,680
 reduce so you'll need to compromise as a product to see which p will give you the smallest this overall

819
01:51:11,680 --> 01:51:21,440
 as a product so this is one way to compromise you may start with lower order and then increase to

820
01:51:21,440 --> 01:51:32,000
 see until when then then you you're raising minimum and then again get larger so that's that's a

821
01:51:32,000 --> 01:51:42,000
 the point where you can stop another way to do is this this is also very famous are kiker

822
01:51:42,960 --> 01:51:53,040
 kiker information criteria so again you'll select choose this p then minimize the following

823
01:51:53,760 --> 01:52:01,120
 following index here so you'll see here it's always the compromise between this you see

824
01:52:02,080 --> 01:52:10,320
 because depending on p you will you will have this estimate noise term and this term so you want to see

825
01:52:10,400 --> 01:52:21,440
 the compromise if p here if p increase so this part will increase where again similar to the other

826
01:52:21,440 --> 01:52:29,360
 one this one were were were chopped so you have this one gets smaller this one gets larger so therefore

827
01:52:32,160 --> 01:52:39,440
 again you can select by starting with a lower third say two or three and then see how

828
01:52:40,639 --> 01:52:48,240
 this index change so normally when you reach certain numbers say p equal to five or six

829
01:52:49,040 --> 01:52:56,160
 you know depending on the application now then you will get the the optimal one for example in

830
01:52:57,200 --> 01:53:05,519
 in speech typically it's the p because I I taught the speech signal processing some years back and

831
01:53:05,520 --> 01:53:14,880
 now the course was not offered so we so we get some experience about p usually equal to 10 it will be a

832
01:53:14,880 --> 01:53:27,760
 good estimation okay then we move on to change to another process which is the MA process is

833
01:53:28,560 --> 01:53:43,120
 so MA is very similar to like the FIA filter because in this case the our impulse will be

834
01:53:44,720 --> 01:53:48,000
 finite number

835
01:53:48,880 --> 01:54:04,560
 so in this case what do we have here you'll see if you only have this pk coefficient

836
01:54:04,560 --> 01:54:11,440
 while the ak are all equal to zero so we only have the denominator because auto correlation is the

837
01:54:12,000 --> 01:54:16,480
 second order statistic so basically it's doing the

838
01:54:19,200 --> 01:54:28,240
 you know the shift and then multiplication and since our HK here is a finite time then you can do that

839
01:54:28,240 --> 01:54:35,040
 very easily for AR normally you don't do this because for AR model the

840
01:54:35,760 --> 01:54:42,320
 impulse response is infinity long so you can't exist unless you work out the analytic

841
01:54:44,160 --> 01:54:51,040
 solution otherwise you cannot sum infinity many term numerically so that that's the main

842
01:54:52,480 --> 01:55:04,240
 difference so so so assumed we starting from the estimate you see the auto correlation coefficient

843
01:55:04,240 --> 01:55:11,519
 which only need a finite number of them you only have a finite number of equation also this

844
01:55:11,519 --> 01:55:16,960
 two parameter here is not not the linear not like AR there is a cross term here

845
01:55:18,480 --> 01:55:27,360
 so assume by some way you can get it then the corresponding estimate MA power density spectrum

846
01:55:28,080 --> 01:55:36,799
 you can compute by so you see here once you have a model you substitute this then you'll get

847
01:55:38,000 --> 01:55:45,440
 something like the frequency response the magnitude but in this case you will you'll have this

848
01:55:47,440 --> 01:55:52,799
 multiplication so equal n-tag is just you know taking the

849
01:55:53,120 --> 01:55:59,600
 things our model is FIR filter you just take up through value raise the power up to and

850
01:56:00,720 --> 01:56:11,360
 and then multiply by the noise value but if you do a simple calculation substitute back you will see

851
01:56:12,320 --> 01:56:26,240
 here you see because for this MA model you see then this part actually is already the estimate

852
01:56:26,719 --> 01:56:36,960
 you see the auto correlation coefficient so for MA models we do not really need to estimate

853
01:56:37,040 --> 01:56:43,440
 this coefficient you can if you are using assume this MA process you can just directly using the

854
01:56:44,400 --> 01:56:53,280
 estimate auto correlation function to the compute which is much much easier but you cannot do this

855
01:56:53,280 --> 01:57:03,360
 for AR model and the AMA model because for that the even in power response is in infinity many

856
01:57:04,160 --> 01:57:04,880
 many values

857
01:57:09,120 --> 01:57:18,400
 okay so how about AR MA process which is the combination because it has

858
01:57:19,679 --> 01:57:30,559
 numerator and denominator so for this AR MA process we can consider that as

859
01:57:31,520 --> 01:57:41,360
 cascade of the MA process which corresponding to the numerator and out of that you'll get the

860
01:57:41,360 --> 01:57:49,200
 output from here then go through another AR process so you can consider decomposing into

861
01:57:49,920 --> 01:57:58,000
 two and then multiply together or in terms of the time domain sequence you will need to do the

862
01:57:58,080 --> 01:58:04,240
 convolution in the frequency domain is multiplication okay so therefore in this case

863
01:58:05,440 --> 01:58:14,480
 you can yeah yeah you can consider there is a white process and then

864
01:58:17,520 --> 01:58:25,840
 consider that saying as AR AR is p order because we assume the order of aj equal to p

865
01:58:26,560 --> 01:58:36,480
 and then we get estimate of this using this IXM so once we get that then

866
01:58:40,400 --> 01:58:51,840
 this being here generally is output of the system aj because here you see so you need to be careful

867
01:58:51,840 --> 01:59:02,640
 because so again here we are we are considering this reverse reverse process yeah you see if you

868
01:59:03,360 --> 01:59:15,440
 yeah if you try to try to estimate this you can follow what we say we generally we from a white

869
01:59:15,440 --> 01:59:27,280
 noise go through this ARP process then with this the auto correlation then we will generally this

870
01:59:27,919 --> 01:59:38,799
 be a this the other way yeah and then therefore in this case the sequence here the estimate one

871
01:59:39,280 --> 01:59:46,880
 yeah excite by this so it's going the other direction will be the estimate of the

872
01:59:46,880 --> 01:59:51,920
 being because we we only measure this you see we have this available so I want to

873
01:59:52,560 --> 02:00:01,120
 want to go back in that that direction and after that you will need still need to go the

874
02:00:01,120 --> 02:00:08,880
 MA part because we already estimate this so we we are considering this as our major

875
02:00:10,880 --> 02:00:22,800
 data or the estimate auto correlation to to to estimate this part approximate yeah okay using this

876
02:00:22,960 --> 02:00:30,640
 yeah so therefore the estimate the amount model for the power spectrum is

877
02:00:31,360 --> 02:00:39,200
 will be in this way you you're doing doing two steps because otherwise the model parameter if

878
02:00:39,200 --> 02:00:48,240
 you are trying to solve the equation directly it will be highly no linear so you or you can get it by

879
02:00:48,240 --> 02:00:58,719
 numerical measure or do the iterations so that's how this is one of the approach to do it

880
02:01:01,519 --> 02:01:07,840
 okay so with all this discussion we can look at some

881
02:01:08,640 --> 02:01:21,120
 simulation results to see how this estimation measure works and later I think next next week

882
02:01:21,120 --> 02:01:31,120
 we will continue into the eigen analysis approach to to see to see the difference so

883
02:01:32,000 --> 02:01:44,320
 so the in this new simulation experiment we we will create some data the

884
02:01:46,240 --> 02:01:57,040
 yeah so so the data we have is one or two sideways and then some additive Gaussian noise

885
02:01:57,920 --> 02:02:08,000
 and the two sideways are spaced by delta f apart we will work controls how far away this delta f

886
02:02:08,800 --> 02:02:19,760
 and h n r is defined as you see here we have the m is amplitude of the of the sideways

887
02:02:19,920 --> 02:02:29,200
 raise power of two because to measure power we use amplitude power of two to do it and for the

888
02:02:29,840 --> 02:02:35,280
 of course this one is the the noise yes this is the variant of the additive noise

889
02:02:37,360 --> 02:02:43,680
 yeah and in the case of two sideways then the amplitude are set the same we consider

890
02:02:44,320 --> 02:02:53,600
 the two of them are the same not not say one is larger than the other so we consider several

891
02:02:53,600 --> 02:03:02,560
 case case one here the result for just you know very limited data and go to 20 data points

892
02:03:03,280 --> 02:03:13,520
 and based on an ar4 I mean ar model is 4 and then the h n r is 20 dv which is reasonably okay

893
02:03:14,240 --> 02:03:24,720
 the digital frequency difference because our app is just zero to half corresponding to zero to pi

894
02:03:26,560 --> 02:03:38,000
 pi over two they equal to that and so here I hope you can see from the north so you there are several

895
02:03:38,800 --> 02:03:49,920
 several measures the truth is a Euler Walker's measure also from the equation looks looks quite nice but

896
02:03:50,640 --> 02:03:58,240
 experimental result not very not very good here the two peak the two peak here but other measures

897
02:03:58,240 --> 02:04:07,440
 both is and least square are very close so but this measure not not yeah not very good because

898
02:04:07,440 --> 02:04:16,719
 it's a very very broad broad spectrum and small peak so it did the correct number of frequency but

899
02:04:16,720 --> 02:04:22,880
 accuracy rather poor where the other two measures are much better than this

900
02:04:24,640 --> 02:04:33,120
 yeah the LS seems to be even a little bit better compared to the Berg's measure

901
02:04:34,720 --> 02:04:42,720
 and if you further reduce this the spacing of the two frequency to reduce that and then the

902
02:04:43,680 --> 02:04:52,720
 Euler Walker's measure it can't solve at all resolve these two frequencies now the frequency I think the

903
02:04:52,720 --> 02:05:00,880
 scaling may be different here so you see it's one it's similar to the no parametric measure

904
02:05:01,520 --> 02:05:08,160
 become very broad you you even don't see the two peak so yeah so for short data this

905
02:05:09,120 --> 02:05:16,720
 Euler Walker's measure is not good because it based on the true the accurate auto coordination

906
02:05:17,360 --> 02:05:24,400
 function but if you have finite data the error may be already large there

907
02:05:25,920 --> 02:05:35,280
 so now we look at this case two here we only have one frequency component to underline the

908
02:05:35,280 --> 02:05:41,920
 rank them process and the frequency the digital frequency here we're looking at all these narrow

909
02:05:41,920 --> 02:05:52,240
 range 0.26 which is here and then in this case we will be considered the effect of additive noise

910
02:05:53,519 --> 02:06:00,719
 on the estimate and then we illustrate just use the least least square measure because this

911
02:06:00,720 --> 02:06:11,600
 measure tend to be better than the than the other one so from this you will see here if the hni is

912
02:06:13,040 --> 02:06:24,880
 large like 20 dB then again this is 20 20 poise and has and at two poles so so you'll see a very sharp peak

913
02:06:24,960 --> 02:06:35,920
 if it reduced you will get smaller peak and then now if snr 5 dB you the the peak is more

914
02:06:35,920 --> 02:06:47,360
 instead but it's a little bit off already in this one this one still okay so yeah so you'll see the

915
02:06:48,320 --> 02:06:52,000
 it's quite sensitive to the snr here

916
02:06:55,280 --> 02:07:04,240
 and then the effect of field order yeah now we look at field order because just now we fix on

917
02:07:04,240 --> 02:07:14,880
 one order and we already say early if you change field order then you may have a different result

918
02:07:14,880 --> 02:07:26,400
 so here we see how it will affect the bug and the least square method here so the left hand side

919
02:07:26,400 --> 02:07:39,760
 here is the bug method the right hand side is least square one so yeah you can see here let's look at

920
02:07:40,720 --> 02:07:54,400
 the different case if you're here is six poles eight poles then is it's quite good but poles

921
02:07:55,840 --> 02:08:06,160
 increase so you'll see it's yeah although we only have one one one peak so you'll see it changes

922
02:08:06,160 --> 02:08:19,280
 you'll add some some other peak here for the least square thing to be more stable you you

923
02:08:20,320 --> 02:08:27,360
 it works for six four eight poles twelve poles so it all looks looks

924
02:08:27,759 --> 02:08:38,639
 the two method looks quite quite similar in this case where this one is a sharper

925
02:08:39,759 --> 02:08:52,240
 sharper peak this is broader and the case three here we show the spectrum estimate for the two

926
02:08:52,240 --> 02:09:03,200
 sideways in noise using ls method and here the now we change the arm arm auto which is

927
02:09:03,200 --> 02:09:15,040
 numerator denominator ma and the ar port and then here even for low snr you can see the

928
02:09:15,200 --> 02:09:28,400
 the quality looks looks quite good for this ls method so i think the figure is a very small

929
02:09:30,480 --> 02:09:37,280
 number here snr you will compare this to this one is a larger snr 10 db so you'll see

930
02:09:38,160 --> 02:09:45,759
 this one there is a very low only zero db but it's still the performance looks still quite good

931
02:09:45,759 --> 02:09:56,960
 the data sample is 100 so it's not it's larger than previous one but it's not very big big number so

932
02:09:57,920 --> 02:10:09,440
 that's yeah so that's so far we are just illustrating you know some method using simulation

933
02:10:09,440 --> 02:10:15,840
 which about of course if you really want to explore further you have to

934
02:10:17,360 --> 02:10:26,240
 considering like writing some program as in my other course statistical signal processing for the

935
02:10:26,240 --> 02:10:32,800
 Simon I.R. student to try out some of the implement some of the some of the methods but

936
02:10:33,360 --> 02:10:41,280
 since in my part here i only have the quiz so yeah so that's up to individual if you are

937
02:10:41,920 --> 02:10:49,440
 at time you are king you can explore that particularly if you you need that in your

938
02:10:50,080 --> 02:11:00,639
 project to do power estimation power spectrum estimation for example if you are doing like

939
02:11:00,639 --> 02:11:08,400
 speech signal processing where as i mentioned i taught the course on msc course here several

940
02:11:08,400 --> 02:11:20,799
 years ago so it's quite relevant this AR base is using speech signal processing because it

941
02:11:20,799 --> 02:11:30,320
 it happened to be this AR model work quite well to estimate some of the speech parameters so so

942
02:11:30,320 --> 02:11:44,160
 let's see how this is being done in this speech signal processing here you start with some major

943
02:11:44,160 --> 02:11:56,960
 data then you can do some pre-processing by pre-emphasis by yeah so this is the you know the very simple

944
02:11:57,600 --> 02:12:07,280
 simple digital filter here to try to threaten the the spectrum and after that you'll

945
02:12:08,400 --> 02:12:16,160
 you'll do the frame blocking which is because speech signal you can model is

946
02:12:17,040 --> 02:12:25,599
 why saying stationally only over very short duration so you need to

947
02:12:26,480 --> 02:12:33,760
 cutting to frame by frame otherwise is the to result your pie to a very long data you will not

948
02:12:33,760 --> 02:12:42,320
 walk so that's that's one of the the case you'll need to consider like frame blocking

949
02:12:47,360 --> 02:12:53,920
 and then to make good use of the data you can do the overlapping so in this case by

950
02:12:54,880 --> 02:13:02,640
 by overlap by by one so that means every frame you overlap is the next one with with one so

951
02:13:03,760 --> 02:13:11,520
 after that you'll do wing doing you see may try to reduce because you are cutting some frame so you

952
02:13:11,600 --> 02:13:26,560
 want to reduce the so-called you know the pseudo peak or or whatever so you do applying some

953
02:13:28,400 --> 02:13:35,440
 window function and after that you'll do the auto correlation so that's that's the part where we

954
02:13:36,400 --> 02:13:42,799
 we have done we have considered and then you can do it recursive using labing soon to being or

955
02:13:43,599 --> 02:13:53,599
 sure as algorithm so based on that you'll get the AR model coefficient either a k or k m which

956
02:13:53,599 --> 02:14:02,400
 this is relative filter now after that you'll get the APC parameter conversion to correspond to the

957
02:14:03,360 --> 02:14:13,519
 your speed signal that is resonant so so you're applying to that and yeah that's that's how these

958
02:14:13,519 --> 02:14:22,559
 are the practical post because speed signal is very easy to measure you will have microphones you can

959
02:14:22,559 --> 02:14:31,360
 do it simply in the lab so that's speech portion of speech signal and the psd thing using different

960
02:14:32,160 --> 02:14:40,080
 algorithm show here so this is a segment of speech signal so you can see here it's

961
02:14:40,080 --> 02:14:51,200
 very strange over time so you need to take a short segment then do the analysis and then here you'll

962
02:14:51,200 --> 02:15:04,880
 see the different different method we try you know the AP AP that's one of the

963
02:15:07,360 --> 02:15:15,920
 all poles AP mean because the notation AP will corresponding to the AR model pj is the

964
02:15:15,920 --> 02:15:22,640
 am I pole and jillo so that's and the other p and keel and p

965
02:15:25,040 --> 02:15:35,840
 could be different so this is only for the poles so so therefore if you use a PRRG which is the

966
02:15:35,840 --> 02:15:42,160
 low parametric measure and you'll see it's not very good I use the model base you will see

967
02:15:43,120 --> 02:15:49,040
 a more accurate estimation but as I say the in practice usually you'll require

968
02:15:49,760 --> 02:15:58,240
 higher the not just like in the simple example you have AR to AR4 so you may need like up to 10 or

969
02:15:58,240 --> 02:16:09,200
 even higher so yeah I think that's probably the the main part we've done then the next thing we will

970
02:16:10,000 --> 02:16:20,800
 discuss is more the icon analysis methods which maybe I just give some introduction on the

971
02:16:21,519 --> 02:16:31,760
 mass background the relative mass because we still have some time before yeah so I hope I think at

972
02:16:31,760 --> 02:16:40,080
 the big beginning I introduce a little bit but not not too much because here is we rely heavily on

973
02:16:40,080 --> 02:16:46,960
 the icon analysis so it will start with a square matrix here it could be complex so in general

974
02:16:46,960 --> 02:16:55,040
 see it's complex then I hope you all know how to get the eigenvalue and eigenvector of this square

975
02:16:55,040 --> 02:17:05,200
 matrix by multiplied by a identity matrix of the same there so it must be square and this is also

976
02:17:05,200 --> 02:17:12,480
 identity matrix also of course square matrix start going to equal to 1 and the size n n by n

977
02:17:13,200 --> 02:17:24,240
 and then if some of the value it could be complex it make this equation equal to 0 this is

978
02:17:24,240 --> 02:17:31,840
 the matrix this v is a vector and assume this v vector is not equal to 0 because if this vector is

979
02:17:31,840 --> 02:17:42,559
 0 vector of course any you are always equal to 0 so therefore if you apply a no 0 no 0 vector which

980
02:17:43,920 --> 02:17:52,799
 corresponding get a value lambda satisfy this they will call this eigenvalue and eigenvector

981
02:17:52,799 --> 02:18:02,000
 so in general think this is n by n if you make the determinant equal to 0 you will always have

982
02:18:02,000 --> 02:18:09,199
 n eigenvalue but this eigenvalue they could be the same some of them may be the same some

983
02:18:09,199 --> 02:18:20,959
 could be complex also yeah not not not unique in general yeah so if you if you see this is

984
02:18:23,759 --> 02:18:32,080
 an example eigenvector whatever you get the eigenvector you multiply by another coefficient

985
02:18:32,080 --> 02:18:41,599
 it will also no zero coefficients scalar your n dot with also the eigen eigenvector but eigenvalue

986
02:18:41,599 --> 02:18:50,719
 may be unique may yeah it could you could have a repeat same eigenvalue but yeah if you have a

987
02:18:50,719 --> 02:19:01,119
 distinct distinct say eigen eigenvalue they they are all different then you will surely have

988
02:19:01,840 --> 02:19:09,679
 have the unique one so so that's the simple example how how you're getting you will need to

989
02:19:10,639 --> 02:19:22,960
 expand this determinant so how you're able to work out that it can do it up to three by three

990
02:19:22,960 --> 02:19:34,080
 if you have a three by three by three matrix you'll need to expand into the sum of three

991
02:19:34,400 --> 02:19:41,920
 three determining of three uh two by two but in this case one of them is a zero so you only have

992
02:19:41,920 --> 02:19:53,920
 two and then after that you you see uh expand and then simplifying to a polynomial polynomial

993
02:19:54,640 --> 02:20:04,640
 equation in terms of lambda and sometimes you may end up with you know those rules which are not

994
02:20:04,640 --> 02:20:13,760
 reasonable number and in some case you can have complex complex rules but if the matrix is

995
02:20:14,720 --> 02:20:21,680
 symmetric and real coefficient you will not get the complex rules so these are the basic

996
02:20:22,400 --> 02:20:29,600
 yeah so and then after that the eigenvector is a little bit more difficult to calculate

997
02:20:29,600 --> 02:20:37,120
 particularly for higher dimension for at least for three by three i think is still manageable

998
02:20:37,120 --> 02:20:47,600
 what you'll do is once you get the eigenvalue then to get this you'll put this in then of course

999
02:20:47,600 --> 02:20:54,720
 being eigenvalue this matrix will lose the ring you can initially three by three you can

1000
02:20:57,040 --> 02:21:04,160
 so that means the among these three equations only and most are two of them are independent so you

1001
02:21:05,280 --> 02:21:15,040
 you only need to solve two equations with three three unknown so so that's why you say the

1002
02:21:15,040 --> 02:21:23,120
 say the solution is not unique you once you get one one vector you can add many many vectors by doing

1003
02:21:24,240 --> 02:21:34,080
 yeah doing scaling so here one of them is by solving that you can let this be one one here to be

1004
02:21:34,800 --> 02:21:43,120
 any no zero number so one zero minus one this vector is satisfied and then say you multiply by two

1005
02:21:43,680 --> 02:21:53,840
 two zero minus two also satisfied so that's that's how this is done and then you can get the second

1006
02:21:53,840 --> 02:22:01,360
 eigenvalue which is this then your your gang you will solve but a little bit more complicated

1007
02:22:01,360 --> 02:22:09,440
 because you have this square root of two then you you will get this again this parameter is a scalar

1008
02:22:10,000 --> 02:22:20,720
 and for this one it's the same way you do it and then how to deal with this no unique one way to do is I

1009
02:22:20,720 --> 02:22:28,560
 think that's in data science machine learning very common you'll normalize to normalize this

1010
02:22:28,560 --> 02:22:37,520
 that means you'll make the norm equal to one you see so how to get the norm is very easy each of that

1011
02:22:37,520 --> 02:22:47,120
 if complex take the the magnitude raise power to some of them then take your square root just like

1012
02:22:47,120 --> 02:22:57,120
 our you know in vectors so you do it and once you get this one you you divide each of all the elements

1013
02:22:57,840 --> 02:23:07,360
 so in this in this case this normalized one your angle is equal to one so the norm of the

1014
02:23:08,400 --> 02:23:16,800
 and that's why this is a normalized vector and then you can also illustrate here so this one you

1015
02:23:16,800 --> 02:23:22,480
 take different value your angle with different vector they're all eigenvector but once you're

1016
02:23:22,480 --> 02:23:30,160
 normalized your the beyond one can only take this value v2 can take this of course you can

1017
02:23:31,119 --> 02:23:38,560
 you can still multiply by minus one if you you see if you change the side you

1018
02:23:39,279 --> 02:23:45,920
 steer the norm of the multiple minus one still give you the same same norm but here we

1019
02:23:46,880 --> 02:23:54,880
 we assume you take one of them so so therefore this is what the normalized one would be more or less

1020
02:23:56,960 --> 02:24:05,200
 unique and then there is this orthogonal vector let me out orthogonal is more like the

1021
02:24:05,200 --> 02:24:14,240
 inner product if you are talking about rare vector but in in general in this part we're

1022
02:24:14,240 --> 02:24:23,039
 may involve complex so for complex the the inner product one of them you have to change the conjugate

1023
02:24:23,039 --> 02:24:31,760
 you see for example the row vector edge if complex you take the complex conjugate of each of the

1024
02:24:31,760 --> 02:24:41,360
 elements then do a inner product and then if the inner product becomes zero we say that these two

1025
02:24:41,360 --> 02:24:51,040
 vector are orthogonal just like in the 2d plane you have the 90 degree x and y okay the whole set the

1026
02:24:51,040 --> 02:25:00,000
 vector set is called also normal if they are normalized and orthogonal so compile both

1027
02:25:02,560 --> 02:25:08,880
 and then look at this example here you can verify so they are all the

1028
02:25:09,599 --> 02:25:12,640
 also going to vector set that is satisfied this

1029
02:25:14,800 --> 02:25:20,080
 and yeah also also normal because they are already normalized

1030
02:25:22,240 --> 02:25:25,039
 and then there is this unitary

1031
02:25:25,440 --> 02:25:33,840
 matrix which satisfies this you see and multiple yeah so remember this edge is the

1032
02:25:35,200 --> 02:25:44,480
 you take transpose and change the element to conjugate so it's it's a if for real for

1033
02:25:45,439 --> 02:25:53,680
 matrix you only need to take the transpose so that's so this edge is mean her mission

1034
02:25:55,039 --> 02:26:06,080
 yeah for real if complex you will need to consider both symmetry and it satisfies the complex conjugate

1035
02:26:06,080 --> 02:26:17,280
 also equal so it satisfies this that means the her mission matrix of this become the inverse of this

1036
02:26:17,920 --> 02:26:28,560
 edge so there will be very special matrix unitary unitary matrix okay so therefore in this case

1037
02:26:28,560 --> 02:26:36,880
 the column or row vector they all form also also normal set also also going to and normalize

1038
02:26:38,160 --> 02:26:41,840
 and then if this is a real we call it as orthogonal

1039
02:26:43,680 --> 02:26:50,320
 matrix and that's a definition of her mission matrix and so and then the any matrix you can

1040
02:26:50,880 --> 02:26:58,080
 always create the her mission version just as we do it for symmetry anti-symmetry by

1041
02:26:58,960 --> 02:27:05,760
 add the her mission but if this is not m is not the her mission you can add the her mission

1042
02:27:06,480 --> 02:27:15,680
 part and then divide by two or the nt1 is nt her mission it's subtract okay so therefore it satisfies

1043
02:27:15,680 --> 02:27:29,520
 this yeah and then the if this satisfies her mission and then you'll get eigen decomposition

1044
02:27:30,320 --> 02:27:37,600
 and this is normalized then you have all these varying shooting property lab multiplying this by

1045
02:27:37,600 --> 02:27:49,360
 both sides your your nt2 is this property and then for this satisfy this you can see

1046
02:27:51,200 --> 02:27:59,200
 your yeah you already the eigen value you take the her mission in this case just conjugate because

1047
02:27:59,200 --> 02:28:06,800
 eigen value is the number and in this case you see all the eigen value of her mission matrix

1048
02:28:06,800 --> 02:28:13,519
 they are all real even if the matrix itself is complex so yeah and then they are yeah

1049
02:28:14,480 --> 02:28:24,160
 they satisfy this if you are doing that and then if you put all these as long as the eigen

1050
02:28:24,160 --> 02:28:34,560
 value are all different you you can easily put this eigen vector then this will form this unitary

1051
02:28:34,960 --> 02:28:44,080
 matrix and you can do the eigen decomposition in in this way yeah very special and then you have the

1052
02:28:44,080 --> 02:28:54,240
 positive definite matrix you define define this way using any no zero vector which could be complex

1053
02:28:54,240 --> 02:29:01,840
 for complex you always talk always talk about her mission not just the transpose but also take the

1054
02:29:01,840 --> 02:29:10,720
 complex conjugate okay if real then we do not need to take conjugate it will be just the transpose

1055
02:29:11,840 --> 02:29:15,440
 yeah and then there's some interesting property here

1056
02:29:18,240 --> 02:29:26,400
 yeah you can always yeah you can always convert this we are in quadratic form you can always

1057
02:29:27,199 --> 02:29:37,600
 convert into this commission matrix so yeah so therefore m is positive definite if only if q is

1058
02:29:39,359 --> 02:29:50,240
 eigen value all positive so these are somewhat related yeah I think we will stop here then

1059
02:29:50,880 --> 02:30:00,960
 we can yeah those are involving more into subspace there single value decomposition then we will

1060
02:30:00,960 --> 02:30:09,199
 need to continue into the subspace decomposition and so on so so for that part I think we

1061
02:30:09,440 --> 02:30:20,080
 we are playing to finish this chapter in the first half of next week and then after that next week we

1062
02:30:20,080 --> 02:30:31,040
 will have from eight to nine will be the quiz so I yeah already give the give give the scope

1063
02:30:31,040 --> 02:30:40,960
 you know last week I made a little quite some part for chapter one which is the basic those

1064
02:30:40,960 --> 02:30:53,920
 fundamental match and chapter two mostly I select more to the first half for the later part I win

1065
02:30:53,920 --> 02:31:01,760
 or the orthogonal and so on there were and some of the recursive equation like burgers and the

1066
02:31:02,880 --> 02:31:09,920
 to being the one you can also yeah leave out so the further quiz I will say the

1067
02:31:12,560 --> 02:31:18,240
 the the scope quite narrow and the questions are

1068
02:31:18,320 --> 02:31:30,880
 simple I should say but you'll try to memorize a few equations normally not not very complicated

1069
02:31:31,440 --> 02:31:44,320
 and yeah so the very basic one for for the chapter one you'll at least you'll get familiar with

1070
02:31:44,400 --> 02:31:56,080
 like Gaussian random variable and given available how to get the like means and variant moment these are

1071
02:31:56,080 --> 02:32:06,400
 the very very basic and some of the so-called simple factor you know like previous year I see

1072
02:32:06,480 --> 02:32:15,520
 the basic of the VS or simple error like yeah for example variant will always be positive so if you

1073
02:32:15,520 --> 02:32:22,640
 will get a negative variant then of course must be something wrong so the simple factor like that

1074
02:32:22,640 --> 02:32:29,440
 and also if a random variable you raise power two you know then it will still be a new random

1075
02:32:29,440 --> 02:32:37,840
 variable and that must be always take no zero no negative value because the power two even though

1076
02:32:37,840 --> 02:32:48,160
 the ring them so you'll see these are the so-called common knowledge you should be familiar with okay

1077
02:32:48,160 --> 02:32:56,640
 yeah so yeah so I I will stop a little bit early I think not only nine o'clock there I can

1078
02:32:56,960 --> 02:33:07,359
 stay on here if you have a question you want to clarify and so on you can you can stay back

1079
02:33:08,240 --> 02:33:19,199
 yeah otherwise it's okay you do the proper preparation and I also remember maybe I again I

1080
02:33:19,920 --> 02:33:30,800
 highlight here just yeah just just in case some of you came late or those are not here watching the

1081
02:33:31,680 --> 02:33:38,960
 video recording so these are the important one okay and then of course the two chapter already

1082
02:33:38,960 --> 02:33:47,920
 narrowed down quite quite quite some part and make sure you bring the student matriculation

1083
02:33:47,920 --> 02:33:59,200
 card because I have some undergraduate TA to help to do the invigilation and calculators yeah so and

1084
02:34:00,480 --> 02:34:07,680
 don't use mobile phone because yeah mobile phone you need to turn off or at least silence and yeah

1085
02:34:08,000 --> 02:34:18,960
 yeah so but you can have the separate calculator don't use a telephone the telephone set the

1086
02:34:18,960 --> 02:34:26,000
 calculator inside you bring a separate because anyway for the need for the final exam they're always

1087
02:34:26,720 --> 02:34:34,720
 yeah not allowing you in allowing you to take the mobile phone inside but you can bring a calculator

1088
02:34:34,720 --> 02:34:42,320
 I believe you should already verify in the in in the school the calculator those you

1089
02:34:43,519 --> 02:34:49,599
 put the stick but I'll show you the calculation will be simple just some numerical calculation

1090
02:34:49,599 --> 02:34:59,279
 okay and try yeah to be here yeah 10 minutes because we need to do the seating properly and yeah

1091
02:34:59,280 --> 02:35:15,840
 all the best and okay if no question we'll stop here see you next week yeah okay thank you

1092
02:35:29,280 --> 02:35:29,840
 you

1093
02:35:59,280 --> 02:35:59,840
 you

1094
02:36:29,280 --> 02:36:29,840
 you

1095
02:36:59,280 --> 02:36:59,840
 you

1096
02:37:29,280 --> 02:37:30,400
 you

1097
02:37:59,280 --> 02:38:00,800
 you

1098
02:38:29,280 --> 02:38:30,000
 you

1099
02:59:59,280 --> 03:00:01,340
 you

